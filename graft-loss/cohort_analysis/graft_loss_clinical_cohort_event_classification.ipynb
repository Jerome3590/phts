{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clinical Cohort Event Classification with Monte Carlo Cross-Validation\n",
    "\n",
    "**Study Replication:** Publication-quality cohort-specific binary classification analysis with Monte Carlo cross-validation (configurable 50â€“100 splits)  \n",
    "**Updated:** December 12, 2025  \n",
    "**Hardware:** Optimized for 32-core EC2 instance (1TB RAM)  \n",
    "**Validation:** Proper evaluation on unseen test data\n",
    "\n",
    "## Key Features\n",
    "\n",
    "âœ… **Clinical Cohort Analysis** â€“ CHD vs MyoCardio cohorts with modifiable clinical features  \n",
    "âœ… **Event Classification** â€“ Binary classification at 1 year with AUC evaluation  \n",
    "âœ… **Monte Carlo Cross-Validation** â€“ 50â€“100 random 80/20 train/test splits for cohort-level analysis  \n",
    "âœ… **Stratified Sampling** - Maintains event distribution  \n",
    "âœ… **Parallel Processing** - Fast execution with furrr/future (â‰ˆ30 workers)  \n",
    "âœ… **95% Confidence Intervals** - Narrow, precise estimates (tighter with more splits)  \n",
    "âœ… **Realistic AUCs** - Expected range 0.70-0.90\n",
    "\n",
    "## Methodology\n",
    "\n",
    "This notebook implements binary classification for 1-year graft loss prediction:\n",
    "\n",
    "1. Load data for pediatric heart transplant outcomes\n",
    "2. Create binary outcome: event by 1 year vs. no event with â‰¥1 year follow-up\n",
    "3. For each cohort and method:\n",
    "   - Create 100â€“1000 stratified train/test splits (75/25)\n",
    "   - Train classification model on training set\n",
    "   - Evaluate on unseen test set\n",
    "   - Aggregate results across splits\n",
    "4. Calculate AUC, Brier Score, Accuracy, Precision, Recall, F1 with 95% CI\n",
    "5. Extract top features\n",
    "\n",
    "## Expected Runtime (per cohort Ã— 4-method run)\n",
    "\n",
    "- **100 splits (current default):**\n",
    "  - Local (4 cores): ~1â€“2 hours (NOT RECOMMENDED)\n",
    "  - Workstation (16 cores): ~30â€“60 minutes\n",
    "  - EC2 (32 cores, 1TB RAM): ~30â€“60 minutes âœ… **RECOMMENDED FOR DEVELOPMENT**\n",
    "- **1000 splits (extended / publication-level):**\n",
    "  - Local (4 cores): 8â€“12+ hours (NOT RECOMMENDED)\n",
    "  - Workstation (16 cores): ~4â€“8 hours\n",
    "  - EC2 (32 cores, 1TB RAM): ~4â€“8 hours âœ… **RECOMMENDED FOR FINAL RESULTS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration\n",
    "\n",
    "Load required packages and configure parallel processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check R version\n",
    "R.version.string\n",
    "\n",
    "# Load required packages\n",
    "library(here)\n",
    "library(dplyr)\n",
    "library(readr)\n",
    "library(survival)\n",
    "library(catboost)\n",
    "library(tidyr)\n",
    "library(purrr)\n",
    "library(tibble)\n",
    "library(janitor)\n",
    "library(haven)\n",
    "library(rsample)    # For MC-CV\n",
    "library(furrr)      # For parallel processing\n",
    "library(future)     # For parallel backend\n",
    "library(progressr)  # For progress bars\n",
    "\n",
    "# Load classification packages\n",
    "library(glmnet)      # For LASSO\n",
    "library(randomForest) # For Traditional RF\n",
    "library(pROC)         # For AUC calculation\n",
    "library(cutpointr)    # For threshold optimization\n",
    "\n",
    "cat(\"âœ“ All packages loaded successfully\\n\")\n",
    "\n",
    "# Source classification helper functions\n",
    "source(here(\"scripts\", \"R\", \"classification_helpers.R\"))\n",
    "cat(\"âœ“ Classification helper functions loaded\\n\")\n",
    "\n",
    "# Create output directory\n",
    "output_dir <- here(\"cohort_analysis\", \"outputs\", \"classification\")\n",
    "\n",
    "# IDEMPOTENCY: Skip existing outputs if enabled\n",
    "# Set SKIP_EXISTING_OUTPUTS = TRUE to resume from where you left off\n",
    "# Set SKIP_EXISTING_OUTPUTS = FALSE to start fresh (will clean existing outputs)\n",
    "SKIP_EXISTING_OUTPUTS <- TRUE  # Change to FALSE to force a fresh start\n",
    "\n",
    "if (SKIP_EXISTING_OUTPUTS) {\n",
    "  cat(\"\\n\")\n",
    "  cat(\"â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\\n\")\n",
    "  cat(\"â•‘          ðŸ”„ RESUME MODE: Skipping existing outputs            â•‘\\n\")\n",
    "  cat(\"â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\")\n",
    "  cat(\"Set SKIP_EXISTING_OUTPUTS = FALSE to force a fresh start\\n\\n\")\n",
    "} else {\n",
    "  cat(\"\\n\")\n",
    "  cat(\"â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\\n\")\n",
    "  cat(\"â•‘          ðŸ§¹ FRESH START MODE: Cleaning existing outputs       â•‘\\n\")\n",
    "  cat(\"â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\\n\")\n",
    "  \n",
    "  # Clean existing outputs directory to ensure fresh/clean results\n",
    "  if (dir.exists(output_dir)) {\n",
    "    # Remove all files in outputs directory\n",
    "    output_files <- list.files(output_dir, full.names = TRUE, recursive = TRUE, include.dirs = FALSE)\n",
    "    if (length(output_files) > 0) {\n",
    "      cat(sprintf(\"Cleaning %d existing output files...\\n\", length(output_files)))\n",
    "      file.remove(output_files)\n",
    "    }\n",
    "    # Remove empty subdirectories\n",
    "    output_dirs <- list.dirs(output_dir, recursive = TRUE, full.names = TRUE)\n",
    "    output_dirs <- output_dirs[output_dirs != output_dir]  # Don't remove main directory\n",
    "    for (dir in rev(output_dirs)) {  # Reverse order to remove nested dirs first\n",
    "      if (length(list.files(dir)) == 0) {\n",
    "        unlink(dir, recursive = TRUE)\n",
    "      }\n",
    "    }\n",
    "    cat(\"âœ“ Output directory cleaned\\n\")\n",
    "  }\n",
    "}\n",
    "\n",
    "# Create output directory (if it doesn't exist)\n",
    "dir.create(output_dir, showWarnings = FALSE, recursive = TRUE)\n",
    "\n",
    "cat(\"Output directory:\", output_dir, \"\\n\")\n",
    "cat(\"MC-CV configuration will be displayed after setup is complete.\\n\")\n",
    "flush.console()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DEBUG/TEST MODE - Quick testing before full 100-split run\n",
    "# ============================================================\n",
    "# Set DEBUG_MODE = TRUE for quick testing (5 splits, ~2-5 min)\n",
    "# Set DEBUG_MODE = FALSE for full analysis (100 splits, ~1-2 hours on EC2)\n",
    "DEBUG_MODE <- FALSE  # Change to TRUE for quick test\n",
    "\n",
    "# Analysis Mode: Event Classification (binary outcome at 1 year)\n",
    "if (DEBUG_MODE) {  cat(\"\\n\")  cat(\"â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\\n\")  cat(\"â•‘                    ðŸ” DEBUG MODE ENABLED                       â•‘\\n\")  cat(\"â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\")  cat(\"\\n\")  cat(\"Quick test configuration:\\n\")  cat(\"  â€¢ MC-CV Splits: 5 (instead of 100)\\n\")  cat(\"  â€¢ Period: Original only (2010-2019)\\n\")  cat(\"  â€¢ Trees: Reduced (RSF: 100, AORSF: 50)\\n\")  cat(\"  â€¢ Expected time: 2-5 minutes\\n\")  cat(\"  â€¢ Purpose: Verify everything works before full run\\n\")  cat(\"\\n\")  cat(\"To run full analysis, set DEBUG_MODE = FALSE\\n\")  cat(\"\\n\")}# Configurationn_predictors <- 20                                        # Top 20 featuresn_trees_rsf <- if (DEBUG_MODE) 100 else 500              # RSF trees (reduced in debug)n_trees_aorsf <- if (DEBUG_MODE) 50 else 100             # AORSF trees (reduced in debug)horizon <- 1                                              # 1-year predictionn_mc_splits <- if (DEBUG_MODE) 5 else 100                # MC-CV splits (5 for debug, 100 for full)train_prop <- 0.75                                        # 75% training, 25% testing# Set up parallel processing - EC2 Optimized (32 cores, 1TB RAM)# Use 30 out of 32 cores (leave 2 for system)n_workers <- as.integer(Sys.getenv(\"N_WORKERS\", \"0\"))if (n_workers < 1) {  total_cores <- parallel::detectCores()  n_workers <- max(1, total_cores - 2)  cat(sprintf(\"Auto-detected %d cores, using %d workers\\n\", total_cores, n_workers))}cat(sprintf(\"Setting up parallel processing with %d workers...\\n\", n_workers))cat(sprintf(\"Expected speedup: %dx faster than single core\\n\", round(n_workers * 0.8)))# Increase future.globals.maxSize for large MC-CV splits object# With 1TB RAM on EC2, we can handle large transfersoptions(future.globals.maxSize = 20 * 1024^3)  # 20 GB limit (plenty for 100 splits)cat(\"Set future.globals.maxSize to 20 GB\\n\")plan(multisession, workers = n_workers)\n",
    "\n",
    "# Output directory is already created in Cell 2 with idempotency logic\n",
    "# Just ensure it exists (don't clean it here - that's handled by SKIP_EXISTING_OUTPUTS in Cell 2)\n",
    "output_dir <- here(\"cohort_analysis\", \"outputs\", \"classification\")\n",
    "dir.create(output_dir, showWarnings = FALSE, recursive = TRUE)\n",
    "\n",
    "cat(\"Output directory:\", output_dir, \"\\n\")\n",
    "cat(sprintf(\"MC-CV Configuration: %d splits, %.0f/%.0f train/test split\\n\", \n",
    "            n_mc_splits, train_prop * 100, (1 - train_prop) * 100))\n",
    "flush.console()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Helper Functions\n",
    "\n",
    "Define functions for data preparation, C-index calculation, and prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare modeling data with leakage prevention# Supports both survival and classification modesprepare_modeling_data <- function(data, mode = \"survival\") {  if (mode == \"survival\") {    # Survival mode: Find time and status columns    time_col <- intersect(c(\"time\", \"outcome_int_graft_loss\", \"int_graft_loss\"), names(data))[1]    status_col <- intersect(c(\"status\", \"outcome_graft_loss\", \"graft_loss\"), names(data))[1]        if (is.na(time_col) || is.na(status_col)) {      stop(\"Cannot find time/status columns for survival mode\")    }        # Rename to standard names    if (time_col != \"time\") data <- data %>% rename(time = !!time_col)    if (status_col != \"status\") data <- data %>% rename(status = !!status_col)  } else if (mode == \"classification\") {    # Classification mode: Find outcome column    outcome_col <- intersect(c(\"outcome\", \"outcome_1yr\", \"event_1yr\"), names(data))[1]        if (is.na(outcome_col)) {      # Try to create outcome from time/status if available      if (\"ev_time\" %in% names(data) && \"ev_type\" %in% names(data)) {        data <- data %>%          mutate(            outcome = case_when(              ev_type == 1 & ev_time < 1 ~ 1L,  # Event by 1 year              ev_type == 0 & ev_time >= 1 ~ 0L,  # No event, follow-up >= 1 year              TRUE ~ NA_integer_  # Censored before 1 year - drop            )          ) %>%          filter(!is.na(outcome))  # Drop censored before 1 year        cat(\"â†’ Created outcome variable from ev_time and ev_type\\n\")      } else {        stop(\"Cannot find outcome column or ev_time/ev_type for classification mode\")      }    } else if (outcome_col != \"outcome\") {      data <- data %>% rename(outcome = !!outcome_col)    }  } else {    stop(\"Invalid ANALYSIS_MODE. Must be 'survival' or 'classification'\")  }    # Exclude leakage variables and identifier columns  exclude_exact <- c(    \"ID\", \"ptid_e\", \"int_dead\", \"int_death\", \"graft_loss\", \"txgloss\", \"death\", \"event\",    \"dpricaus\", \"deathspc\", \"concod\", \"age_death\", \"dlist\", \"txpl_year\",    \"rrace_b\", \"rrace_a\", \"rrace_ai\", \"rrace_pi\", \"rrace_o\", \"rrace_un\", \"race\",    \"patsupp\", \"pmorexam\", \"papooth\", \"pacuref\", \"pishltgr\",    \"pathero\", \"pcadrec\", \"pcadrem\", \"pdiffib\", \"cpathneg\",    \"dcardiac\", \"dneuro\", \"dreject\", \"dsecaccs\", \"dpriaccs\",    \"dconmbld\", \"dconmal\", \"dconcard\", \"dconneur\", \"dconrej\",    \"dmajbld\", \"dmalcanc\"  )    exclude_prefixes <- c(\"dtx_\", \"cc_\", \"dcon\", \"dpri\", \"dsec\", \"dmaj\", \"sd\")    exclude_by_prefix <- character(0)  for (prefix in exclude_prefixes) {    exclude_by_prefix <- c(exclude_by_prefix,                            names(data)[startsWith(names(data), prefix)])  }    exclude_all <- unique(c(exclude_exact, exclude_by_prefix))  data <- data %>% select(-any_of(exclude_all))    # Median imputation for numeric variables  numeric_vars <- names(data)[sapply(data, is.numeric) & names(data) != \"time\" & names(data) != \"status\"]  for (var in numeric_vars) {    if (any(is.na(data[[var]]))) {      median_val <- median(data[[var]], na.rm = TRUE)      data[[var]][is.na(data[[var]])] <- median_val    }  }    # Mode imputation for categorical variables  categorical_vars <- names(data)[sapply(data, function(x) is.factor(x) | is.character(x))]  for (var in categorical_vars) {    if (any(is.na(data[[var]]))) {      mode_val <- names(sort(table(data[[var]]), decreasing = TRUE))[1]      data[[var]][is.na(data[[var]])] <- mode_val    }  }    # Remove constant columns  constant_cols <- names(data)[sapply(data, function(x) length(unique(na.omit(x))) <= 1)]  if (length(constant_cols) > 0) {    data <- data %>% select(-any_of(constant_cols))  }    # Convert character to factor  data <- data %>% mutate(across(where(is.character), as.factor))    return(data)}cat(\"âœ“ prepare_modeling_data() defined\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C-index calculation\n",
    "calculate_cindex <- function(time, status, risk_scores, horizon = NULL) {\n",
    "  valid_idx <- !is.na(time) & !is.na(status) & !is.na(risk_scores) &\n",
    "               is.finite(time) & is.finite(risk_scores) & time > 0\n",
    "  \n",
    "  time   <- as.numeric(time[valid_idx])\n",
    "  status <- as.numeric(status[valid_idx])\n",
    "  risk   <- as.numeric(risk_scores[valid_idx])\n",
    "  \n",
    "  n <- length(time)\n",
    "  events <- sum(status == 1)\n",
    "  \n",
    "  if (n < 10 || events < 1 || length(unique(risk)) == 1) {\n",
    "    return(list(cindex_td = NA_real_, cindex_ti = NA_real_))\n",
    "  }\n",
    "  \n",
    "  # Time-independent C-index (Harrell's)\n",
    "  num_conc_ti <- 0\n",
    "  num_disc_ti <- 0\n",
    "  num_ties_ti <- 0\n",
    "  \n",
    "  for (i in seq_len(n)) {\n",
    "    if (status[i] != 1) next\n",
    "    for (j in seq_len(n)) {\n",
    "      if (i == j) next\n",
    "      if (time[i] < time[j]) {\n",
    "        if (risk[i] > risk[j]) {\n",
    "          num_conc_ti <- num_conc_ti + 1\n",
    "        } else if (risk[i] < risk[j]) {\n",
    "          num_disc_ti <- num_disc_ti + 1\n",
    "        } else {\n",
    "          num_ties_ti <- num_ties_ti + 1\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  denom_ti <- num_conc_ti + num_disc_ti + num_ties_ti\n",
    "  cindex_ti <- if (denom_ti > 0) (num_conc_ti + 0.5 * num_ties_ti) / denom_ti else NA_real_\n",
    "  \n",
    "  # Time-dependent C-index\n",
    "  cindex_td <- tryCatch({\n",
    "    score_data <- data.frame(time = time, status = status)\n",
    "    pred_matrix <- matrix(risk, ncol = 1)\n",
    "    \n",
    "    evaluation <- riskRegression::Score(\n",
    "      object = list(Model = pred_matrix),\n",
    "      formula = Surv(time, status) ~ 1,\n",
    "      data = score_data,\n",
    "      times = if (!is.null(horizon)) horizon else median(time[status == 1]),\n",
    "      summary = \"risks\",\n",
    "      metrics = \"auc\",\n",
    "      se.fit = FALSE\n",
    "    )\n",
    "    \n",
    "    as.numeric(evaluation$AUC$score$AUC[1])\n",
    "  }, error = function(e) cindex_ti)\n",
    "  \n",
    "  return(list(cindex_td = cindex_td, cindex_ti = cindex_ti))\n",
    "}\n",
    "\n",
    "# ranger_predictrisk function\n",
    "ranger_predictrisk <- function(object, newdata, times) {\n",
    "  preds <- predict(object, data = newdata, type = \"response\")\n",
    "  if (is.null(preds$survival)) {\n",
    "    stop(\"ranger prediction did not return survival probabilities\")\n",
    "  }\n",
    "  \n",
    "  surv_matrix <- preds$survival\n",
    "  time_points <- preds$unique.death.times\n",
    "  closest_idx <- which.min(abs(time_points - times))\n",
    "  risk_scores <- 1 - surv_matrix[, closest_idx]\n",
    "  \n",
    "  return(as.numeric(risk_scores))\n",
    "}\n",
    "\n",
    "cat(\"âœ“ calculate_cindex() and ranger_predictrisk() defined\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Monte Carlo Cross-Validation Function\n",
    "\n",
    "Main function that runs MC-CV for a single method and period.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run MC-CV for a single method and time period\n",
    "run_mc_cv_method <- function(data, method, period_name, mc_splits) {\n",
    "  \n",
    "  cat(sprintf(\"\\n=== Running MC-CV for %s (%s) ===\\n\", method, period_name))\n",
    "  cat(sprintf(\"Splits: %d | Train: %.0f%% | Test: %.0f%%\\n\", \n",
    "              n_mc_splits, train_prop * 100, (1 - train_prop) * 100))\n",
    "  flush.console()\n",
    "  \n",
    "  split_ids <- seq_len(n_mc_splits)\n",
    "  \n",
    "  # Run splits in parallel with progress bar\n",
    "  with_progress({\n",
    "    p <- progressor(steps = n_mc_splits)\n",
    "    \n",
    "    results <- future_map(split_ids, function(split_id) {\n",
    "      p()  # Update progress\n",
    "      \n",
    "      # Get train/test data from split\n",
    "      split <- mc_splits$splits[[split_id]]\n",
    "      train_data <- rsample::analysis(split)\n",
    "      test_data <- rsample::assessment(split)\n",
    "      \n",
    "      # Train and evaluate\n",
    "      model <- NULL\n",
    "      predictions <- NULL\n",
    "      feature_importance <- NULL\n",
    "      \n",
    "      tryCatch({\n",
    "        if (method == \"RSF\") {\n",
    "          model <- ranger(\n",
    "            Surv(time, status) ~ .,\n",
    "            data = train_data,\n",
    "            num.trees = n_trees_rsf,\n",
    "            importance = \"permutation\",\n",
    "            min.node.size = 20,\n",
    "            splitrule = \"extratrees\",\n",
    "            num.random.splits = 10\n",
    "          )\n",
    "          \n",
    "          predictions <- ranger_predictrisk(model, test_data, horizon)\n",
    "          feature_importance <- model$variable.importance\n",
    "          \n",
    "        } else if (method == \"AORSF\") {\n",
    "          # Remove constant columns from training data (can occur after train/test split)\n",
    "          constant_cols <- names(train_data)[sapply(train_data, function(x) {\n",
    "            if (is.numeric(x)) {\n",
    "              length(unique(na.omit(x))) <= 1\n",
    "            } else {\n",
    "              length(unique(na.omit(x))) <= 1\n",
    "            }\n",
    "          })]\n",
    "          constant_cols <- setdiff(constant_cols, c(\"time\", \"status\"))\n",
    "          if (length(constant_cols) > 0) {\n",
    "            train_data <- train_data %>% select(-any_of(constant_cols))\n",
    "            test_data <- test_data %>% select(-any_of(constant_cols))\n",
    "          }\n",
    "          \n",
    "          model <- aorsf::orsf(\n",
    "            data = train_data,\n",
    "            formula = Surv(time, status) ~ .,\n",
    "            n_tree = n_trees_aorsf,\n",
    "            na_action = 'impute_meanmode'\n",
    "          )\n",
    "          \n",
    "          pred_obj <- predict(model, new_data = test_data, \n",
    "                              pred_type = 'risk', pred_horizon = horizon)\n",
    "          predictions <- if (is.matrix(pred_obj)) as.numeric(pred_obj[, 1]) else as.numeric(pred_obj)\n",
    "          feature_importance <- aorsf::orsf_vi_permute(model)\n",
    "          \n",
    "        } else if (method == \"CatBoost\") {\n",
    "          # Remove constant columns from training data (can occur after train/test split)\n",
    "          constant_cols <- names(train_data)[sapply(train_data, function(x) {\n",
    "            if (is.numeric(x)) {\n",
    "              length(unique(na.omit(x))) <= 1\n",
    "            } else {\n",
    "              length(unique(na.omit(x))) <= 1\n",
    "            }\n",
    "          })]\n",
    "          constant_cols <- setdiff(constant_cols, c(\"time\", \"status\"))\n",
    "          if (length(constant_cols) > 0) {\n",
    "            train_data <- train_data %>% select(-any_of(constant_cols))\n",
    "            test_data <- test_data %>% select(-any_of(constant_cols))\n",
    "          }\n",
    "          \n",
    "          train_pool <- catboost.load_pool(\n",
    "            data = train_data %>% select(-time, -status),\n",
    "            label = train_data$time\n",
    "          )\n",
    "          \n",
    "          test_pool <- catboost.load_pool(\n",
    "            data = test_data %>% select(-time, -status)\n",
    "          )\n",
    "          \n",
    "          # CatBoost configuration: single-threaded inside each R worker to avoid\n",
    "          # logger/thread-safety issues, and quiet logging in parallel runs.\n",
    "          params <- list(\n",
    "            loss_function  = 'Cox',\n",
    "            iterations     = 100,\n",
    "            learning_rate  = 0.1,\n",
    "            depth          = 6,\n",
    "            thread_count   = 1,\n",
    "            logging_level  = 'Silent',\n",
    "            verbose        = 0L\n",
    "          )\n",
    "          \n",
    "          model <- catboost.train(train_pool, params = params)\n",
    "          predictions <- catboost.predict(model, test_pool)\n",
    "          \n",
    "          # Get feature importance - CatBoost returns a matrix with rownames as feature names\n",
    "          # IMPORTANT: catboost.get_feature_importance() returns a matrix (not a named vector)\n",
    "          # - Values are in the first column: importance_matrix[, 1]\n",
    "          # - Feature names are in rownames: rownames(importance_matrix)\n",
    "          # Convert to named vector for consistency with RSF and AORSF (which return named vectors directly)\n",
    "          importance_matrix <- catboost.get_feature_importance(model)\n",
    "          feature_importance <- as.numeric(importance_matrix[, 1])\n",
    "          names(feature_importance) <- rownames(importance_matrix)\n",
    "        }\n",
    "        \n",
    "        # Calculate C-index on TEST data\n",
    "        cindex_result <- calculate_cindex(\n",
    "          time = test_data$time,\n",
    "          status = test_data$status,\n",
    "          risk_scores = predictions,\n",
    "          horizon = horizon\n",
    "        )\n",
    "        \n",
    "        return(list(\n",
    "          split_id = split_id,\n",
    "          cindex_td = cindex_result$cindex_td,\n",
    "          cindex_ti = cindex_result$cindex_ti,\n",
    "          feature_importance = feature_importance,\n",
    "          n_train = nrow(train_data),\n",
    "          n_test = nrow(test_data),\n",
    "          success = TRUE\n",
    "        ))\n",
    "        \n",
    "      }, error = function(e) {\n",
    "        return(list(\n",
    "          split_id = split_id,\n",
    "          cindex_td = NA_real_,\n",
    "          cindex_ti = NA_real_,\n",
    "          feature_importance = NULL,\n",
    "          n_train = nrow(train_data),\n",
    "          n_test = nrow(test_data),\n",
    "          success = FALSE,\n",
    "          error = e$message\n",
    "        ))\n",
    "      })\n",
    "    }, .options = furrr_options(\n",
    "      seed = TRUE,\n",
    "      packages = c(\n",
    "        \"dplyr\", \"purrr\", \"tibble\", \"rsample\",\n",
    "        \"ranger\", \"aorsf\", \"catboost\",\n",
    "        \"riskRegression\", \"prodlim\"\n",
    "      )\n",
    "    ))\n",
    "  })\n",
    "  \n",
    "  # Aggregate results\n",
    "  successful_splits <- Filter(function(x) x$success, results)\n",
    "  n_successful <- length(successful_splits)\n",
    "  \n",
    "  cat(sprintf(\"Successful splits: %d / %d\\n\", n_successful, n_mc_splits))\n",
    "  flush.console()\n",
    "  \n",
    "  # If all splits failed (e.g., CatBoost configuration/data issue),\n",
    "  # do not stop the whole analysis. Instead, log a warning and return\n",
    "  # an empty/NA summary so that other methods and periods can continue.\n",
    "  if (n_successful == 0) {\n",
    "    error_splits <- Filter(function(x) !is.null(x$error), results)\n",
    "    if (length(error_splits) > 0) {\n",
    "      first_error <- error_splits[[1]]$error\n",
    "      cat(sprintf(\"WARNING: example error for %s (%s): %s\\n\",\n",
    "                  method, period_name, first_error))\n",
    "    }\n",
    "    cat(sprintf(\"WARNING: All MC-CV splits failed for %s (%s). Skipping this method.\\n\",\n",
    "                method, period_name))\n",
    "    flush.console()\n",
    "    \n",
    "    return(list(\n",
    "      method = method,\n",
    "      period = period_name,\n",
    "      n_splits = n_mc_splits,\n",
    "      n_successful = 0,\n",
    "      cindex_td_mean = NA_real_,\n",
    "      cindex_td_sd = NA_real_,\n",
    "      cindex_td_ci_lower = NA_real_,\n",
    "      cindex_td_ci_upper = NA_real_,\n",
    "      cindex_ti_mean = NA_real_,\n",
    "      cindex_ti_sd = NA_real_,\n",
    "      cindex_ti_ci_lower = NA_real_,\n",
    "      cindex_ti_ci_upper = NA_real_,\n",
    "      top_features = numeric(0)\n",
    "    ))\n",
    "  }\n",
    "  \n",
    "  # Extract C-indexes\n",
    "  cindex_td_values <- sapply(successful_splits, function(x) x$cindex_td)\n",
    "  cindex_ti_values <- sapply(successful_splits, function(x) x$cindex_ti)\n",
    "  \n",
    "  cindex_td_values <- cindex_td_values[!is.na(cindex_td_values)]\n",
    "  cindex_ti_values <- cindex_ti_values[!is.na(cindex_ti_values)]\n",
    "  \n",
    "  # Aggregate feature importance\n",
    "  # All methods (RSF, AORSF, CatBoost) return named numeric vectors\n",
    "  all_feature_names <- unique(unlist(lapply(successful_splits, function(x) {\n",
    "    if (is.null(x$feature_importance)) return(NULL)\n",
    "    names(x$feature_importance)\n",
    "  })))\n",
    "  \n",
    "  aggregated_importance <- sapply(all_feature_names, function(feature) {\n",
    "    importances <- sapply(successful_splits, function(x) {\n",
    "      if (is.null(x$feature_importance)) return(NA_real_)\n",
    "      if (feature %in% names(x$feature_importance)) {\n",
    "        return(as.numeric(x$feature_importance[feature]))\n",
    "      }\n",
    "      return(NA_real_)\n",
    "    })\n",
    "    mean(importances, na.rm = TRUE)\n",
    "  })\n",
    "  \n",
    "  # Ensure aggregated_importance is a numeric vector\n",
    "  aggregated_importance <- as.numeric(aggregated_importance)\n",
    "  names(aggregated_importance) <- all_feature_names\n",
    "  \n",
    "  top_features <- sort(aggregated_importance, decreasing = TRUE)[1:min(n_predictors, length(aggregated_importance))]\n",
    "  \n",
    "  # Calculate statistics\n",
    "  results_summary <- list(\n",
    "    method = method,\n",
    "    period = period_name,\n",
    "    n_splits = n_mc_splits,\n",
    "    n_successful = n_successful,\n",
    "    cindex_td_mean = mean(cindex_td_values, na.rm = TRUE),\n",
    "    cindex_td_sd = sd(cindex_td_values, na.rm = TRUE),\n",
    "    cindex_td_ci_lower = quantile(cindex_td_values, 0.025, na.rm = TRUE),\n",
    "    cindex_td_ci_upper = quantile(cindex_td_values, 0.975, na.rm = TRUE),\n",
    "    cindex_ti_mean = mean(cindex_ti_values, na.rm = TRUE),\n",
    "    cindex_ti_sd = sd(cindex_ti_values, na.rm = TRUE),\n",
    "    cindex_ti_ci_lower = quantile(cindex_ti_values, 0.025, na.rm = TRUE),\n",
    "    cindex_ti_ci_upper = quantile(cindex_ti_values, 0.975, na.rm = TRUE),\n",
    "    top_features = top_features\n",
    "  )\n",
    "  \n",
    "  # Print summary\n",
    "  cat(sprintf(\"\\n--- Results for %s (%s) ---\\n\", method, period_name))\n",
    "  cat(sprintf(\"Time-Dependent C-Index: %.4f Â± %.4f (95%% CI: %.4f - %.4f)\\n\",\n",
    "              results_summary$cindex_td_mean,\n",
    "              results_summary$cindex_td_sd,\n",
    "              results_summary$cindex_td_ci_lower,\n",
    "              results_summary$cindex_td_ci_upper))\n",
    "  cat(sprintf(\"Time-Independent C-Index: %.4f Â± %.4f (95%% CI: %.4f - %.4f)\\n\",\n",
    "              results_summary$cindex_ti_mean,\n",
    "              results_summary$cindex_ti_sd,\n",
    "              results_summary$cindex_ti_ci_lower,\n",
    "              results_summary$cindex_ti_ci_upper))\n",
    "  # Display top 10 features sorted alphabetically for easier comparison\n",
    "  top10_features <- names(top_features)[1:min(10, length(top_features))]\n",
    "  top10_features_sorted <- sort(top10_features)\n",
    "  cat(sprintf(\"Top 10 features (alphabetical): %s\\n\", paste(top10_features_sorted, collapse = \", \")))\n",
    "  flush.console()\n",
    "  \n",
    "  return(results_summary)\n",
    "}\n",
    "\n",
    "cat(\"âœ“ run_mc_cv_method() defined\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and load SAS file\n",
    "sas_path_local <- here(\"data\", \"phts_txpl_ml.sas7bdat\")\n",
    "sas_path_external <- here(\"graft-loss-parallel-processing\", \"data\", \"phts_txpl_ml.sas7bdat\")\n",
    "sas_path_graft_loss <- here(\"graft-loss\", \"data\", \"phts_txpl_ml.sas7bdat\")\n",
    "\n",
    "sas_path <- NULL\n",
    "for (path in c(sas_path_local, sas_path_external, sas_path_graft_loss)) {\n",
    "  if (file.exists(path)) {\n",
    "    sas_path <- path\n",
    "    break\n",
    "  }\n",
    "}\n",
    "\n",
    "if (is.null(sas_path)) {\n",
    "  stop(\"Cannot find phts_txpl_ml.sas7bdat in any location\")\n",
    "}\n",
    "\n",
    "cat(\"Loading data from:\", sas_path, \"\\n\")\n",
    "\n",
    "# Load data\n",
    "phts_base <- haven::read_sas(sas_path) %>%\n",
    "  filter(TXPL_YEAR >= 2010) %>%\n",
    "  janitor::clean_names() %>%\n",
    "  rename(\n",
    "    outcome_int_graft_loss = int_graft_loss,\n",
    "    outcome_graft_loss = graft_loss\n",
    "  ) %>%\n",
    "  mutate(\n",
    "    ID = 1:n(),\n",
    "    across(.cols = where(is.character), ~ ifelse(.x %in% c(\"\", \"unknown\", \"missing\"), NA_character_, .x)),\n",
    "    across(.cols = where(is.character), as.factor),\n",
    "    tx_mcsd = if ('txnomcsd' %in% names(.)) {\n",
    "      if_else(txnomcsd == 'yes', 0, 1)\n",
    "    } else if ('txmcsd' %in% names(.)) {\n",
    "      txmcsd\n",
    "    } else {\n",
    "      NA_real_\n",
    "    }\n",
    "  )\n",
    "\n",
    "cat(sprintf(\"âœ“ Loaded data: %d rows, %d columns\\n\", nrow(phts_base), ncol(phts_base)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define time periods\n",
    "periods <- list()\n",
    "periods$original <- phts_base %>% filter(txpl_year >= 2010 & txpl_year <= 2019)\n",
    "periods$full <- phts_base %>% filter(txpl_year >= 2010)\n",
    "periods$full_no_covid <- phts_base %>% filter(txpl_year >= 2010 & !(txpl_year >= 2020 & txpl_year <= 2023))\n",
    "\n",
    "# Print summary\n",
    "for (period_name in names(periods)) {\n",
    "  period_data <- periods[[period_name]]\n",
    "  n_events <- sum(period_data$outcome_graft_loss, na.rm = TRUE)\n",
    "  event_rate <- 100 * n_events / nrow(period_data)\n",
    "  \n",
    "  cat(sprintf(\"Period: %s | N: %d | Events: %d (%.2f%%)\\n\", \n",
    "              period_name, nrow(period_data), n_events, event_rate))\n",
    "}\n",
    "\n",
    "cat(\"\\nâœ“ Time periods defined\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run Analysis\n",
    "\n",
    "Execute MC-CV for all methods and periods.\n",
    "\n",
    "- **100 splits (default full run):** Typically ~1â€“2 hours on a 32-core EC2 instance, longer on smaller machines.\n",
    "- **1000 splits (extended run):** Linearly more expensive; expect roughly 8â€“10Ã— the 100-split time.\n",
    "\n",
    "**Note:** You can run each period separately by uncommenting only one `period_name` at a time, or reduce the number of methods/periods to shorten runtime further.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select periods and methods to run\n",
    "# In DEBUG_MODE, only run original period for speed\n",
    "period_names <- if (DEBUG_MODE) {\n",
    "  c(\"original\")  # Debug: just one period (~2-5 min)\n",
    "} else {\n",
    "  c(\"original\", \"full\", \"full_no_covid\")  # Full: all periods (~30-45 min)\n",
    "}\n",
    "\n",
    "# Methods to run. Include CatBoost (with single-threaded, quiet config)\n",
    "# alongside RSF and AORSF.\n",
    "method_names <- c(\"RSF\", \"CatBoost\", \"AORSF\")\n",
    "\n",
    "# Store all results\n",
    "all_results <- list()\n",
    "\n",
    "# Run analysis\n",
    "for (period_name in period_names) {\n",
    "  cat(sprintf(\"\\n========================================\\n\"))\n",
    "  cat(sprintf(\"Processing Period: %s\\n\", period_name))\n",
    "  cat(sprintf(\"========================================\\n\"))\n",
    "  flush.console()\n",
    "  \n",
    "  # Prepare data\n",
    "  period_data <- prepare_modeling_data(periods[[period_name]])\n",
    "  \n",
    "  cat(sprintf(\"Period data: %d rows, %d columns\\n\", nrow(period_data), ncol(period_data)))\n",
    "  cat(sprintf(\"Events: %d (%.2f%%)\\n\", sum(period_data$status), \n",
    "              100 * sum(period_data$status) / nrow(period_data)))\n",
    "  \n",
    "  # Create MC-CV splits (stratified by outcome)\n",
    "  cat(sprintf(\"Creating %d MC-CV splits (stratified)...\\n\", n_mc_splits))\n",
    "  flush.console()\n",
    "  mc_splits <- mc_cv(\n",
    "    data = period_data,\n",
    "    prop = train_prop,\n",
    "    times = n_mc_splits,\n",
    "    strata = status\n",
    "  )\n",
    "  \n",
    "  # Run each method\n",
    "  period_results <- list()\n",
    "  \n",
    "  for (method in method_names) {\n",
    "    result <- run_mc_cv_method(period_data, method, period_name, mc_splits)\n",
    "    period_results[[method]] <- result\n",
    "    \n",
    "    # Save top features (sorted alphabetically for easier comparison)\n",
    "    top_features_df <- tibble(\n",
    "      feature = names(result$top_features),\n",
    "      importance = as.numeric(result$top_features),\n",
    "      cindex_td = result$cindex_td_mean,\n",
    "      cindex_ti = result$cindex_ti_mean\n",
    "    ) %>%\n",
    "      arrange(feature)  # Sort alphabetically for easier visual comparison\n",
    "    \n",
    "    output_file <- file.path(output_dir, sprintf(\"%s_%s_top20.csv\", \n",
    "                                                  period_name, tolower(method)))\n",
    "    write_csv(top_features_df, output_file)\n",
    "    cat(sprintf(\"âœ“ Saved: %s\\n\", basename(output_file)))\n",
    "  }\n",
    "  \n",
    "  all_results[[period_name]] <- period_results\n",
    "}\n",
    "\n",
    "cat(\"\\nâœ“ Analysis complete for all periods!\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Summary Results\n",
    "\n",
    "Create summary tables with C-index comparisons and statistics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create C-index comparison table\n",
    "cindex_comparison <- map_df(period_names, function(period) {\n",
    "  map_df(method_names, function(method) {\n",
    "    result <- all_results[[period]][[method]]\n",
    "    tibble(\n",
    "      period = period,\n",
    "      method = method,\n",
    "      cindex_td_mean = result$cindex_td_mean,\n",
    "      cindex_td_sd = result$cindex_td_sd,\n",
    "      cindex_td_ci_lower = result$cindex_td_ci_lower,\n",
    "      cindex_td_ci_upper = result$cindex_td_ci_upper,\n",
    "      cindex_ti_mean = result$cindex_ti_mean,\n",
    "      cindex_ti_sd = result$cindex_ti_sd,\n",
    "      cindex_ti_ci_lower = result$cindex_ti_ci_lower,\n",
    "      cindex_ti_ci_upper = result$cindex_ti_ci_upper,\n",
    "      n_splits = result$n_successful\n",
    "    )\n",
    "  })\n",
    "})\n",
    "\n",
    "write_csv(cindex_comparison, file.path(output_dir, \"cindex_comparison_mc_cv.csv\"))\n",
    "cat(\"âœ“ Saved: cindex_comparison_mc_cv.csv\\n\")\n",
    "\n",
    "# Display the table\n",
    "print(cindex_comparison)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary statistics\n",
    "summary_stats <- map_df(period_names, function(period) {\n",
    "  period_data <- periods[[period]]\n",
    "  tibble(\n",
    "    period = period,\n",
    "    n_patients = nrow(period_data),\n",
    "    n_events = sum(period_data$outcome_graft_loss, na.rm = TRUE),\n",
    "    event_rate = 100 * sum(period_data$outcome_graft_loss, na.rm = TRUE) / nrow(period_data)\n",
    "  )\n",
    "})\n",
    "\n",
    "write_csv(summary_stats, file.path(output_dir, \"summary_statistics_mc_cv.csv\"))\n",
    "cat(\"âœ“ Saved: summary_statistics_mc_cv.csv\\n\")\n",
    "\n",
    "# Display the table\n",
    "print(summary_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close parallel processing\n",
    "plan(sequential)\n",
    "\n",
    "cat(\"\\n========================================\\n\")\n",
    "cat(\"Analysis Complete!\\n\")\n",
    "cat(\"========================================\\n\")\n",
    "cat(sprintf(\"Output directory: %s\\n\", output_dir))\n",
    "cat(sprintf(\"MC-CV splits: %d\\n\", n_mc_splits))\n",
    "cat(sprintf(\"Train/Test ratio: %.0f/%.0f\\n\", train_prop * 100, (1 - train_prop) * 100))\n",
    "cat(\"\\nResults show C-indexes with 95% confidence intervals\\n\")\n",
    "cat(\"based on\", n_mc_splits, \"independent train/test splits.\\n\\n\")\n",
    "cat(\"âœ“ All files saved successfully!\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization plots for feature importance and C-index analysis\n",
    "# Uses the updated create_visualizations.R script with improved normalization procedure\n",
    "# Creates: Feature importance heatmap, C-index heatmap, scaled bar chart, and C-index table\n",
    "\n",
    "library(here)\n",
    "\n",
    "# Source the visualization script from scripts/R/\n",
    "# Scripts are consolidated in scripts/R/ to match EC2 structure\n",
    "if (!file.exists(here(\"scripts\", \"R\", \"create_visualizations_cohort.R\"))) {\n",
    "  stop(\"Cannot find scripts/R/create_visualizations_cohort.R. Ensure scripts are in scripts/R/ directory.\")\n",
    "}\n",
    "source(here(\"scripts\", \"R\", \"create_visualizations_cohort.R\"))\n",
    "\n",
    "# Run visualizations\n",
    "# Pass the output directory to ensure visualizations are saved to the correct location\n",
    "run_visualizations(output_dir = output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Sync Results and Code to S3\n",
    "\n",
    "Sync output files and code (notebook + R script) to S3 bucket after all analyses and visualizations are complete.\n",
    "- Outputs: CSV results files, plots, and visualizations\n",
    "- Code: Notebook and R script for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sync outputs and code to S3\n",
    "# On EC2, we're in the cohort_analysis directory\n",
    "s3_bucket <- \"s3://uva-private-data-lake/graft-loss/cohort_analysis/classification/\"\n",
    "\n",
    "# Ensure output_dir_base is defined (should already exist from Section 6.6, but define if needed)\n",
    "if (!exists(\"output_dir_base\")) {\n",
    "  output_dir_base <- here(\"cohort_analysis\", \"outputs\", \"classification\")\n",
    "}\n",
    "\n",
    "# Find AWS CLI (check common locations - EC2 typically has it in /usr/local/bin or /usr/bin)\n",
    "aws_cmd <- Sys.which(\"aws\")\n",
    "if (aws_cmd == \"\") {\n",
    "  # Try common EC2 installation paths\n",
    "  aws_paths <- c(\n",
    "    \"/usr/local/bin/aws\",\n",
    "    \"/usr/bin/aws\",\n",
    "    \"/home/ec2-user/.local/bin/aws\"\n",
    "  )\n",
    "  aws_cmd <- NULL\n",
    "  for (path in aws_paths) {\n",
    "    if (file.exists(path)) {\n",
    "      aws_cmd <- path\n",
    "      break\n",
    "    }\n",
    "  }\n",
    "  if (is.null(aws_cmd)) {\n",
    "    stop(\"AWS CLI not found. Please install AWS CLI or ensure it's in your PATH.\")\n",
    "  }\n",
    "}\n",
    "\n",
    "cat(\"Syncing outputs and code to S3...\\n\")\n",
    "cat(\"Source: cohort_analysis/ directory\\n\")\n",
    "cat(\"Destination:\", s3_bucket, \"\\n\")\n",
    "cat(\"AWS CLI:\", aws_cmd, \"\\n\\n\")\n",
    "\n",
    "# Get current directory (should be cohort_analysis)\n",
    "current_dir <- getwd()\n",
    "if (!grepl(\"cohort_analysis\", current_dir)) {\n",
    "  warning(\"Current directory doesn't appear to be cohort_analysis. Double-check sync destination.\")\n",
    "}\n",
    "\n",
    "# Sync classification outputs and code to S3\n",
    "# Sync the outputs/classification directory specifically to avoid overwriting survival outputs\n",
    "# Explicitly include notebook, R scripts, README files, and outputs/classification directory\n",
    "# Exclude temporary files, checkpoints, and unnecessary directories\n",
    "# Note: --delete flag removed for safety (won't delete files in S3 that don't exist locally)\n",
    "sync_cmd <- sprintf(\n",
    "  '\"%s\" s3 sync \"%s\" %s --include \"*.ipynb\" --include \"*.R\" --include \"README*.md\" --include \"outputs/classification/**\" --exclude \"*checkpoint*\" --exclude \"*.tmp\" --exclude \"*.ipynb_checkpoints/*\" --exclude \"*.RData\" --exclude \"*.Rhistory\" --exclude \".Rproj.user/*\" --exclude \"catboost_info/*\" --exclude \"*.log\" --exclude \"*\"',\n",
    "  aws_cmd,\n",
    "  current_dir,\n",
    "  s3_bucket\n",
    ")\n",
    "\n",
    "cat(\"Running:\", sync_cmd, \"\\n\\n\")\n",
    "result <- system(sync_cmd)\n",
    "\n",
    "if (result == 0) {\n",
    "  cat(\"âœ“ Successfully synced outputs and code to S3\\n\")\n",
    "  cat(\"  - Outputs:\", file.path(output_dir_base), \"\\n\")\n",
    "  cat(\"  - Code: *.ipynb, *.R, README*.md\\n\")\n",
    "} else {\n",
    "  warning(sprintf(\"S3 sync returned exit code %d. Check AWS credentials and permissions.\", result))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Shutdown EC2\n",
    "\n",
    "Shutdown EC2 instance after all analyses, visualizations, and S3 sync are complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Shutdown EC2 instance after analysis completes\n",
    "# Set SHUTDOWN_EC2 = TRUE to enable, FALSE to disable\n",
    "SHUTDOWN_EC2 <- TRUE  # Change to TRUE to enable auto-shutdown\n",
    "\n",
    "if (SHUTDOWN_EC2) {\n",
    "  cat(\"\\n========================================\\n\")\n",
    "  cat(\"Shutting down EC2 instance...\\n\")\n",
    "  cat(\"========================================\\n\")\n",
    "  \n",
    "  # Get instance ID from EC2 metadata service\n",
    "  instance_id <- tryCatch({\n",
    "    system(\"curl -s http://169.254.169.254/latest/meta-data/instance-id\", intern = TRUE)\n",
    "  }, error = function(e) {\n",
    "    cat(\"Warning: Could not retrieve instance ID from metadata service.\\n\")\n",
    "    cat(\"If running on EC2, check that metadata service is accessible.\\n\")\n",
    "    return(NULL)\n",
    "  })\n",
    "  \n",
    "  if (!is.null(instance_id) && length(instance_id) > 0 && nchar(instance_id[1]) > 0) {\n",
    "    instance_id <- instance_id[1]\n",
    "    cat(sprintf(\"Instance ID: %s\\n\", instance_id))\n",
    "    \n",
    "    # Find AWS CLI\n",
    "    aws_cmd <- Sys.which(\"aws\")\n",
    "    if (aws_cmd == \"\") {\n",
    "      aws_paths <- c(\n",
    "        \"/usr/local/bin/aws\",\n",
    "        \"/usr/bin/aws\",\n",
    "        \"/home/ec2-user/.local/bin/aws\"\n",
    "      )\n",
    "      aws_cmd <- NULL\n",
    "      for (path in aws_paths) {\n",
    "        if (file.exists(path)) {\n",
    "          aws_cmd <- path\n",
    "          break\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    \n",
    "    if (!is.null(aws_cmd) && aws_cmd != \"\") {\n",
    "      # Stop the instance (use terminate-instances for permanent deletion)\n",
    "      shutdown_cmd <- sprintf(\n",
    "        '\"%s\" ec2 stop-instances --instance-ids %s',\n",
    "        aws_cmd,\n",
    "        instance_id\n",
    "      )\n",
    "      \n",
    "      cat(\"Running:\", shutdown_cmd, \"\\n\")\n",
    "      result <- system(shutdown_cmd)\n",
    "      \n",
    "      if (result == 0) {\n",
    "        cat(\"âœ“ EC2 instance stop command sent successfully\\n\")\n",
    "        cat(\"Instance will stop in a few moments.\\n\")\n",
    "        cat(\"Note: This is a STOP (not terminate), so you can restart it later.\\n\")\n",
    "      } else {\n",
    "        warning(sprintf(\"EC2 stop command returned exit code %d. Check AWS credentials and permissions.\", result))\n",
    "      }\n",
    "    } else {\n",
    "      cat(\"Warning: AWS CLI not found. Cannot shutdown instance.\\n\")\n",
    "      cat(\"Install AWS CLI or ensure it's in your PATH.\\n\")\n",
    "    }\n",
    "  } else {\n",
    "    cat(\"Warning: Could not determine instance ID. Skipping shutdown.\\n\")\n",
    "    cat(\"If you want to shutdown manually, use:\\n\")\n",
    "    cat(\"  aws ec2 stop-instances --instance-ids <your-instance-id>\\n\")\n",
    "  }\n",
    "} else {\n",
    "  cat(\"\\n========================================\\n\")\n",
    "  cat(\"EC2 Auto-Shutdown: DISABLED\\n\")\n",
    "  cat(\"========================================\\n\")\n",
    "  cat(\"To enable auto-shutdown, set SHUTDOWN_EC2 = TRUE in this cell.\\n\")\n",
    "  cat(\"Instance will continue running.\\n\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Clinical Feature Importance by Cohort (Modifiable Features)\n",
    "\n",
    "This section implements binary classification models for 1-year event prediction.\n",
    "\n",
    "**Models:**\n",
    "- LASSO (logistic regression)\n",
    "- CatBoost (classification)\n",
    "- CatBoost RF (classification)\n",
    "- Traditional RF (classification)\n",
    "\n",
    "**Metrics:** AUC, Brier Score, Accuracy, Precision, Recall, F1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "cat(\"â†’ Starting Classification Analysis Mode\\n\\n\")\n",
    "\n",
    "# 6.1 Define classification lagging keywords (variables to exclude)\n",
    "classification_lagging_keywords <- c(\n",
    "  # Identifiers and outcomes\n",
    "  \"transplant_year\", \"primary_etiology\",\n",
    "  \n",
    "  # Time variables (not needed for classification)\n",
    "  \"ev_\", \"days_to_last_followup\", \"time\", \"status\",\n",
    "  \n",
    "  # Donor-specific variables\n",
    "  \"graft_loss\", \"int_graft_loss\", \"dtx_\", \"cc_\", \"isc_oth\",\n",
    "  \"dcardiac\", \"dcon\", \"dpri\", \"dpricaus\", \"rec_\", \"papooth\",\n",
    "  \"dneuro\", \"sdprathr\", \"int_dead\", \"listing_year\", \"cpathneg\",\n",
    "  \"dcauseod\",\n",
    "  \n",
    "  # Demographics (if not clinically relevant)\n",
    "  \"race\", \"sex\", \"drace_b\", \"rrace_a\", \"hisp\", \"lscntry\",\n",
    "  \n",
    "  # Transplant-specific variables\n",
    "  \"dreject\", \"dsecaccsEmpty\", \"dmajbldEmpty\", \"pishltgr1R\", \n",
    "  \"drejectEmpty\", \"drejectHyperacute\", \"pishltgrEmpty\",\n",
    "  \"pishltgr\", \"dmajbld\", \"dsecaccs\", \"dsecaccs_bin\", \n",
    "  \n",
    "  # Clinical variables to exclude\n",
    "  \"dx_cardiomyopathy\", \"deathspc\", \"dlist\", \"pmorexam\", \n",
    "  \"patsupp\", \"concod\", \"pcadrem\", \"pcadrec\", \"pathero\", \n",
    "  \"pdiffib\", \"dmalcanc\", \"alt_tx\", \"age_death\", \"pacuref\",\n",
    "  \"cpbypass\",\n",
    "  \n",
    "  # Additional variables\n",
    "  \"lsvcma\"\n",
    ")\n",
    "\n",
    "cat(\"âœ“ Classification lagging keywords defined\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Define Cohorts and Prepare Data\n",
    "\n",
    "Define cohorts (CHD vs MyoCardio) and prepare data for classification analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# 6.2 Define Cohorts and Prepare Data\n",
    "# Prepare data for classification (ensure outcome variable exists)\n",
    "# Use phts_base loaded earlier in the notebook and create outcome variable\n",
    "\n",
    "cat(\"â†’ Preparing cohorts for classification analysis\\n\")\n",
    "\n",
    "# Create outcome variable: event by 1 year vs. no event with â‰¥1 year follow-up\n",
    "# Use ev_time and ev_type if available, otherwise use outcome_int_graft_loss and outcome_graft_loss\n",
    "if (\"ev_time\" %in% names(phts_base) && \"ev_type\" %in% names(phts_base)) {\n",
    "  phts_base <- phts_base %>%\n",
    "    mutate(\n",
    "      outcome = case_when(\n",
    "        ev_type == 1 & ev_time < 1 ~ 1L,  # Event by 1 year\n",
    "        ev_type == 0 & ev_time >= 1 ~ 0L,  # No event, follow-up >= 1 year\n",
    "        TRUE ~ NA_integer_  # Censored before 1 year - will be dropped\n",
    "      )\n",
    "    ) %>%\n",
    "    filter(!is.na(outcome))  # Drop censored before 1 year\n",
    "  cat(\"â†’ Created outcome variable from ev_time and ev_type\\n\")\n",
    "} else if (\"outcome_int_graft_loss\" %in% names(phts_base) && \"outcome_graft_loss\" %in% names(phts_base)) {\n",
    "  # Fallback: use time-to-event data to create binary outcome\n",
    "  phts_base <- phts_base %>%\n",
    "    mutate(\n",
    "      outcome = case_when(\n",
    "        outcome_graft_loss == 1 & outcome_int_graft_loss < 1 ~ 1L,  # Event by 1 year\n",
    "        outcome_graft_loss == 0 & outcome_int_graft_loss >= 1 ~ 0L,  # No event, follow-up >= 1 year\n",
    "        TRUE ~ NA_integer_\n",
    "      )\n",
    "    ) %>%\n",
    "    filter(!is.na(outcome))\n",
    "  cat(\"â†’ Created outcome variable from outcome_int_graft_loss and outcome_graft_loss\\n\")\n",
    "} else {\n",
    "  stop(\"Cannot find ev_time/ev_type or outcome_int_graft_loss/outcome_graft_loss to create outcome variable\")\n",
    "}\n",
    "\n",
    "# Split into cohorts\n",
    "chd_data <- phts_base %>% filter(primary_etiology == \"Congenital HD\")\n",
    "mc_data <- phts_base %>% filter(primary_etiology %in% c(\"Cardiomyopathy\", \"Myocarditis\"))\n",
    "\n",
    "cat(\"CHD Cohort Size:\", nrow(chd_data), \"patients\\n\")\n",
    "cat(\"MC Cohort Size:\", nrow(mc_data), \"patients\\n\")\n",
    "cat(\"CHD Event Rate:\", round(mean(chd_data$outcome, na.rm = TRUE) * 100, 2), \"%\\n\")\n",
    "cat(\"MC Event Rate:\", round(mean(mc_data$outcome, na.rm = TRUE) * 100, 2), \"%\\n\\n\")\n",
    "\n",
    "# Prepare data using prepare_modeling_data (classification mode)\n",
    "chd_data_prep <- prepare_modeling_data(chd_data, mode = \"classification\")\n",
    "mc_data_prep <- prepare_modeling_data(mc_data, mode = \"classification\")\n",
    "\n",
    "cat(\"âœ“ Data prepared for classification analysis\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# 6.3 Classification Models with MC-CV\n",
    "# This section implements MC-CV for classification models similar to survival models\n",
    "\n",
    "cat(\"â†’ Starting Classification MC-CV Analysis\\n\")\n",
    "cat(\"â†’ Number of MC-CV splits:\", n_mc_splits, \"\\n\\n\")\n",
    "\n",
    "# Classification model wrapper functions\n",
    "fit_lasso_classification <- function(train_data, test_data) {\n",
    "  # Prepare data\n",
    "  y_train <- train_data$outcome\n",
    "  x_train <- as.matrix(train_data %>% select(-outcome))\n",
    "  y_test <- test_data$outcome\n",
    "  x_test <- as.matrix(test_data %>% select(-outcome))\n",
    "  \n",
    "  # Fit LASSO\n",
    "  set.seed(1997)\n",
    "  cv_fit <- cv.glmnet(x_train, y_train, family = \"binomial\", alpha = 1, nfolds = 5)\n",
    "  pred_probs <- predict(cv_fit, newx = x_test, s = \"lambda.min\", type = \"response\")[, 1]\n",
    "  \n",
    "  # Calculate metrics\n",
    "  metrics <- create_classification_metrics(pred_probs, y_test, \"\", \"LASSO\")\n",
    "  return(list(metrics = metrics, predictions = pred_probs, actual = y_test))\n",
    "}\n",
    "\n",
    "fit_catboost_classification <- function(train_data, test_data) {\n",
    "  # Prepare data\n",
    "  y_train <- train_data$outcome\n",
    "  x_train <- train_data %>% select(-outcome)\n",
    "  y_test <- test_data$outcome\n",
    "  x_test <- test_data %>% select(-outcome)\n",
    "  \n",
    "  # Convert to CatBoost format\n",
    "  train_pool <- catboost.load_pool(data = x_train, label = y_train)\n",
    "  test_pool <- catboost.load_pool(data = x_test, label = y_test)\n",
    "  \n",
    "  # Fit CatBoost\n",
    "  set.seed(1997)\n",
    "  params <- list(\n",
    "    iterations = if (DEBUG_MODE) 100 else 500,\n",
    "    learning_rate = 0.1,\n",
    "    depth = 6,\n",
    "    loss_function = \"Logloss\",\n",
    "    verbose = FALSE\n",
    "  )\n",
    "  model <- catboost.train(train_pool, params = params)\n",
    "  pred_probs <- catboost.predict(model, test_pool, prediction_type = \"Probability\")\n",
    "  \n",
    "  # Calculate metrics\n",
    "  metrics <- create_classification_metrics(pred_probs, y_test, \"\", \"CatBoost\")\n",
    "  return(list(metrics = metrics, predictions = pred_probs, actual = y_test))\n",
    "}\n",
    "\n",
    "fit_catboost_rf_classification <- function(train_data, test_data) {\n",
    "  # Prepare data\n",
    "  y_train <- train_data$outcome\n",
    "  x_train <- train_data %>% select(-outcome)\n",
    "  y_test <- test_data$outcome\n",
    "  x_test <- test_data %>% select(-outcome)\n",
    "  \n",
    "  # Convert to CatBoost format\n",
    "  train_pool <- catboost.load_pool(data = x_train, label = y_train)\n",
    "  test_pool <- catboost.load_pool(data = x_test, label = y_test)\n",
    "  \n",
    "  # Fit CatBoost RF\n",
    "  set.seed(1997)\n",
    "  params <- list(\n",
    "    iterations = if (DEBUG_MODE) 100 else 500,\n",
    "    depth = 8,\n",
    "    learning_rate = 1.0,\n",
    "    bootstrap_type = \"Bernoulli\",\n",
    "    subsample = 0.8,\n",
    "    rsm = 0.5,\n",
    "    loss_function = \"Logloss\",\n",
    "    verbose = FALSE\n",
    "  )\n",
    "  model <- catboost.train(train_pool, params = params)\n",
    "  pred_probs <- catboost.predict(model, test_pool, prediction_type = \"Probability\")\n",
    "  \n",
    "  # Calculate metrics\n",
    "  metrics <- create_classification_metrics(pred_probs, y_test, \"\", \"CatBoost RF\")\n",
    "  return(list(metrics = metrics, predictions = pred_probs, actual = y_test))\n",
    "}\n",
    "\n",
    "fit_rf_classification <- function(train_data, test_data) {\n",
    "  # Prepare data\n",
    "  y_train <- as.factor(train_data$outcome)\n",
    "  x_train <- train_data %>% select(-outcome)\n",
    "  y_test <- test_data$outcome\n",
    "  x_test <- test_data %>% select(-outcome)\n",
    "  \n",
    "  # Fit Random Forest\n",
    "  set.seed(1997)\n",
    "  model <- randomForest(x = x_train, y = y_train, ntree = if (DEBUG_MODE) 100 else 500)\n",
    "  pred_probs <- predict(model, x_test, type = \"prob\")[, 2]\n",
    "  \n",
    "  # Calculate metrics\n",
    "  metrics <- create_classification_metrics(pred_probs, y_test, \"\", \"Traditional RF\")\n",
    "  return(list(metrics = metrics, predictions = pred_probs, actual = y_test))\n",
    "}\n",
    "\n",
    "cat(\"âœ“ Classification model wrapper functions defined\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# 6.4 Run MC-CV for classification models\n",
    "# Similar structure to survival MC-CV but with classification metrics\n",
    "\n",
    "cat(\"â†’ Running MC-CV for classification models\\n\")\n",
    "\n",
    "# Prepare data for each cohort (remove lagging keywords)\n",
    "prepare_classification_data <- function(data) {\n",
    "  data %>%\n",
    "    select(!matches(paste(classification_lagging_keywords, collapse = \"|\"))) %>%\n",
    "    select(-ptid_e) %>%\n",
    "    mutate(across(where(is.numeric), ~if_else(is.infinite(.), NA_real_, .))) %>%\n",
    "    select(-where(~all(is.na(.)))) %>%\n",
    "    mutate(across(where(is.character), as.factor)) %>%\n",
    "    mutate(across(where(is.factor), as.numeric)) %>%\n",
    "    filter(!is.na(outcome))  # Remove any missing outcomes\n",
    "}\n",
    "\n",
    "chd_class_data <- prepare_classification_data(chd_data_prep)\n",
    "mc_class_data <- prepare_classification_data(mc_data_prep)\n",
    "\n",
    "cat(\"CHD classification data:\", nrow(chd_class_data), \"patients\\n\")\n",
    "cat(\"MC classification data:\", nrow(mc_class_data), \"patients\\n\\n\")\n",
    "\n",
    "# MC-CV function for classification\n",
    "run_classification_mc_cv <- function(data, cohort_name, n_splits = n_mc_splits) {\n",
    "  cat(\"â†’ Running MC-CV for\", cohort_name, \"cohort\\n\")\n",
    "  \n",
    "  # Remove constant columns\n",
    "  constant_cols <- names(data)[sapply(data, function(x) length(unique(na.omit(x))) <= 1)]\n",
    "  if (length(constant_cols) > 0) {\n",
    "    data <- data %>% select(-any_of(constant_cols))\n",
    "  }\n",
    "  \n",
    "  # Impute missing values\n",
    "  for (var in names(data)) {\n",
    "    if (is.numeric(data[[var]])) {\n",
    "      data[[var]][is.na(data[[var]])] <- median(data[[var]], na.rm = TRUE)\n",
    "    } else if (is.factor(data[[var]])) {\n",
    "      mode_val <- names(sort(table(data[[var]]), decreasing = TRUE))[1]\n",
    "      data[[var]][is.na(data[[var]])] <- mode_val\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  # Store results\n",
    "  all_metrics <- list()\n",
    "  \n",
    "  # Run MC-CV splits\n",
    "  with_progress({\n",
    "    p <- progressor(steps = n_splits)\n",
    "    \n",
    "    results <- future_map(1:n_splits, function(split_idx) {\n",
    "      p()\n",
    "      \n",
    "      # Create train/test split\n",
    "      set.seed(1997 + split_idx)\n",
    "      split <- initial_split(data, prop = train_prop, strata = outcome)\n",
    "      train_data <- training(split)\n",
    "      test_data <- testing(split)\n",
    "      \n",
    "      # Fit models and collect metrics\n",
    "      metrics_list <- list()\n",
    "      \n",
    "      tryCatch({\n",
    "        lasso_result <- fit_lasso_classification(train_data, test_data)\n",
    "        metrics_list$LASSO <- lasso_result$metrics %>% mutate(Cohort = cohort_name)\n",
    "      }, error = function(e) {\n",
    "        cat(\"Error in LASSO for split\", split_idx, \":\", e$message, \"\\n\")\n",
    "      })\n",
    "      \n",
    "      tryCatch({\n",
    "        catboost_result <- fit_catboost_classification(train_data, test_data)\n",
    "        metrics_list$CatBoost <- catboost_result$metrics %>% mutate(Cohort = cohort_name)\n",
    "      }, error = function(e) {\n",
    "        cat(\"Error in CatBoost for split\", split_idx, \":\", e$message, \"\\n\")\n",
    "      })\n",
    "      \n",
    "      tryCatch({\n",
    "        catboost_rf_result <- fit_catboost_rf_classification(train_data, test_data)\n",
    "        metrics_list$`CatBoost RF` <- catboost_rf_result$metrics %>% mutate(Cohort = cohort_name)\n",
    "      }, error = function(e) {\n",
    "        cat(\"Error in CatBoost RF for split\", split_idx, \":\", e$message, \"\\n\")\n",
    "      })\n",
    "      \n",
    "      tryCatch({\n",
    "        rf_result <- fit_rf_classification(train_data, test_data)\n",
    "        metrics_list$`Traditional RF` <- rf_result$metrics %>% mutate(Cohort = cohort_name)\n",
    "      }, error = function(e) {\n",
    "        cat(\"Error in Traditional RF for split\", split_idx, \":\", e$message, \"\\n\")\n",
    "      })\n",
    "      \n",
    "      return(metrics_list)\n",
    "    }, .options = furrr_options(seed = TRUE))\n",
    "  })\n",
    "  \n",
    "  # Aggregate metrics across splits\n",
    "  all_metrics_df <- bind_rows(lapply(results, function(x) bind_rows(x)))\n",
    "  \n",
    "  # Calculate summary statistics\n",
    "  summary_metrics <- all_metrics_df %>%\n",
    "    group_by(Cohort, Model) %>%\n",
    "    summarise(\n",
    "      AUC_mean = mean(AUC, na.rm = TRUE),\n",
    "      AUC_sd = sd(AUC, na.rm = TRUE),\n",
    "      AUC_ci_lower = AUC_mean - 1.96 * AUC_sd / sqrt(n()),\n",
    "      AUC_ci_upper = AUC_mean + 1.96 * AUC_sd / sqrt(n()),\n",
    "      Brier_mean = mean(Brier_Score, na.rm = TRUE),\n",
    "      Brier_sd = sd(Brier_Score, na.rm = TRUE),\n",
    "      Accuracy_mean = mean(Accuracy, na.rm = TRUE),\n",
    "      Precision_mean = mean(Precision, na.rm = TRUE),\n",
    "      Recall_mean = mean(Recall, na.rm = TRUE),\n",
    "      F1_mean = mean(F1, na.rm = TRUE),\n",
    "      n_splits = n(),\n",
    "      .groups = \"drop\"\n",
    "    )\n",
    "  \n",
    "  return(list(\n",
    "    all_metrics = all_metrics_df,\n",
    "    summary = summary_metrics\n",
    "  ))\n",
    "}\n",
    "\n",
    "# Run MC-CV for both cohorts\n",
    "cat(\"â†’ Starting MC-CV for CHD cohort\\n\")\n",
    "chd_mc_cv_results <- run_classification_mc_cv(chd_class_data, \"CHD\", n_mc_splits)\n",
    "\n",
    "cat(\"\\nâ†’ Starting MC-CV for MC cohort\\n\")\n",
    "mc_mc_cv_results <- run_classification_mc_cv(mc_class_data, \"MC\", n_mc_splits)\n",
    "\n",
    "# Combine results\n",
    "classification_mc_metrics <- bind_rows(\n",
    "  chd_mc_cv_results$summary,\n",
    "  mc_mc_cv_results$summary\n",
    ")\n",
    "\n",
    "cat(\"\\nâœ“ Classification MC-CV completed\\n\")\n",
    "cat(\"â†’ Results summary:\\n\")\n",
    "print(classification_mc_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 Normalized Scaled Feature Importance Bar Chart\n",
    "\n",
    "Create a normalized scaled feature importance bar chart showing the top 25 modifiable clinical features. Importance is normalized within each cohort/model and scaled by model performance (MC-CV AUC).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# 6.5 Normalized Scaled Feature Importance Bar Chart\n",
    "\n",
    "# Create normalized scaled feature importance bar chart for top clinical features\n",
    "# This chart shows feature importance normalized within each cohort/model and scaled by model performance (AUC)\n",
    "\n",
    "library(ggplot2)\n",
    "library(dplyr)\n",
    "\n",
    "# Check if required files exist\n",
    "output_dir_base <- here(\"cohort_analysis\", \"outputs\", \"classification\")\n",
    "summary_dir <- file.path(output_dir_base, \"summary\")\n",
    "\n",
    "best_feat_path <- file.path(summary_dir, \"best_clinical_features_by_cohort_mc_cv.csv\")\n",
    "metrics_path <- file.path(summary_dir, \"cohort_classification_metrics_mc_cv.csv\")\n",
    "\n",
    "if (file.exists(best_feat_path) && file.exists(metrics_path)) {\n",
    "  # Read data\n",
    "  best_features <- readr::read_csv(best_feat_path, show_col_types = FALSE)\n",
    "  classification_metrics <- readr::read_csv(metrics_path, show_col_types = FALSE)\n",
    "  \n",
    "  # Prepare feature matrix: Cohort Ã— Model Ã— Feature\n",
    "  feature_matrix <- best_features %>%\n",
    "    dplyr::select(Cohort, Model, feature, importance) %>%\n",
    "    dplyr::mutate(\n",
    "      Cohort = as.character(Cohort),\n",
    "      Model  = as.character(Model),\n",
    "      importance = as.numeric(importance)\n",
    "    ) %>%\n",
    "    dplyr::mutate(importance = ifelse(is.na(importance), 0, importance)) %>%\n",
    "    dplyr::group_by(Cohort, Model) %>%\n",
    "    dplyr::mutate(\n",
    "      importance = ifelse(importance < 0, 0, importance),\n",
    "      total_imp = sum(importance),\n",
    "      importance_normalized = ifelse(total_imp > 0, importance / total_imp, 1 / dplyr::n())\n",
    "    ) %>%\n",
    "    dplyr::select(-total_imp) %>%\n",
    "    dplyr::ungroup()\n",
    "  \n",
    "  # Relative weights per cohort/model using AUC (instead of C-index for classification)\n",
    "  algorithm_ranking <- classification_metrics %>%\n",
    "    dplyr::select(Cohort, Model, AUC_mean) %>%\n",
    "    dplyr::group_by(Cohort) %>%\n",
    "    dplyr::mutate(\n",
    "      best_auc = max(AUC_mean, na.rm = TRUE),\n",
    "      n_models = sum(!is.na(AUC_mean))\n",
    "    ) %>%\n",
    "    dplyr::ungroup() %>%\n",
    "    dplyr::mutate(\n",
    "      rel_weight = ifelse(best_auc > 0,\n",
    "                          (AUC_mean / best_auc) * n_models,\n",
    "                          1)\n",
    "    ) %>%\n",
    "    dplyr::select(Cohort, Model, rel_weight)\n",
    "  \n",
    "  feature_matrix <- feature_matrix %>%\n",
    "    dplyr::left_join(algorithm_ranking, by = c(\"Cohort\", \"Model\")) %>%\n",
    "    dplyr::mutate(\n",
    "      rel_weight = ifelse(is.na(rel_weight), 1, rel_weight),\n",
    "      importance_scaled = importance_normalized * rel_weight\n",
    "    )\n",
    "  \n",
    "  # Create scaled feature importance bar chart (Top 25 features)\n",
    "  scaled_feature_importance <- feature_matrix %>%\n",
    "    dplyr::group_by(feature) %>%\n",
    "    dplyr::summarise(\n",
    "      total_scaled_importance = sum(importance_scaled, na.rm = TRUE),\n",
    "      .groups = \"drop\"\n",
    "    ) %>%\n",
    "    dplyr::arrange(desc(total_scaled_importance)) %>%\n",
    "    dplyr::slice_head(n = 25)\n",
    "  \n",
    "  scaled_feature_importance <- scaled_feature_importance %>%\n",
    "    dplyr::mutate(feature = factor(feature, levels = rev(scaled_feature_importance$feature)))\n",
    "  \n",
    "  p <- ggplot(scaled_feature_importance, aes(x = feature, y = total_scaled_importance)) +\n",
    "    geom_bar(stat = \"identity\", fill = \"steelblue\", alpha = 0.8) +\n",
    "    coord_flip() +\n",
    "    labs(\n",
    "      title = \"Normalized Scaled Feature Importance (Top 25 Features)\",\n",
    "      subtitle = \"Importance normalized within cohort/model and scaled by model performance (MC-CV AUC)\",\n",
    "      x = \"Feature\",\n",
    "      y = \"Scaled Normalized Importance\"\n",
    "    ) +\n",
    "    theme_minimal() +\n",
    "    theme(\n",
    "      plot.title = element_text(size = 14, face = \"bold\"),\n",
    "      plot.subtitle = element_text(size = 11),\n",
    "      axis.text.y = element_text(size = 9)\n",
    "    )\n",
    "  \n",
    "  # Display the plot\n",
    "  print(p)\n",
    "  \n",
    "  # Also save to summary/plots directory\n",
    "  plot_dir_summary <- file.path(summary_dir, \"plots\")\n",
    "  dir.create(plot_dir_summary, showWarnings = FALSE, recursive = TRUE)\n",
    "  \n",
    "  ggplot2::ggsave(file.path(plot_dir_summary, \"scaled_feature_importance_bar_chart.png\"), p,\n",
    "                  width = 12, height = 10, dpi = 300)\n",
    "  cat(\"\\nâœ“ Saved normalized scaled feature importance bar chart to:\", \n",
    "      file.path(plot_dir_summary, \"scaled_feature_importance_bar_chart.png\"), \"\\n\")\n",
    "  \n",
    "} else {\n",
    "  cat(\"Required files not found. Please run Sections 6.3-6.4 first to generate:\\n\")\n",
    "  cat(\"  -\", best_feat_path, \"\\n\")\n",
    "  cat(\"  -\", metrics_path, \"\\n\")\n",
    "  if (!file.exists(best_feat_path)) {\n",
    "    cat(\"\\nNote: Feature importance extraction may need to be added to the MC-CV code.\\n\")\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# 6.6 Save classification MC-CV results\n",
    "\n",
    "# Base output directory (should already exist from Section 3)\n",
    "output_dir_base <- here(\"cohort_analysis\", \"outputs\", \"classification\")\n",
    "dir.create(output_dir_base, recursive = TRUE, showWarnings = FALSE)\n",
    "\n",
    "# Summary directory for combined cohort comparisons\n",
    "summary_dir <- file.path(output_dir_base, \"summary\")\n",
    "dir.create(summary_dir, recursive = TRUE, showWarnings = FALSE)\n",
    "\n",
    "# Save combined MC-CV files (for cross-cohort comparison)\n",
    "readr::write_csv(classification_mc_metrics,\n",
    "                 file.path(summary_dir, \"cohort_classification_metrics_mc_cv.csv\"))\n",
    "\n",
    "# Save cohort-specific MC-CV files\n",
    "for (cohort_name in unique(classification_mc_metrics$Cohort)) {\n",
    "  cohort_dir <- file.path(output_dir_base, cohort_name)\n",
    "  dir.create(cohort_dir, recursive = TRUE, showWarnings = FALSE)\n",
    "  \n",
    "  # Save cohort-specific MC-CV metrics\n",
    "  cohort_metrics_subset <- classification_mc_metrics %>% filter(Cohort == cohort_name)\n",
    "  readr::write_csv(cohort_metrics_subset,\n",
    "                   file.path(cohort_dir, \"cohort_classification_metrics_mc_cv.csv\"))\n",
    "}\n",
    "\n",
    "cat(\"\\nâœ“ Saved classification MC-CV metrics:\")\n",
    "cat(\"\\n  - Combined (summary):\", summary_dir)\n",
    "cat(\"\\n  - Cohort-specific:\", file.path(output_dir_base, \"CHD\"), \"and\", file.path(output_dir_base, \"MC\"), \"\\n\")\n",
    "\n",
    "# Display summary\n",
    "classification_mc_metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.7 Visualize Cohort Classification Results\n",
    "\n",
    "Create visualization plots for cohort classification analysis comparing cohorts using the summary folder files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# 6.7 Visualize Cohort Classification Results\n",
    "\n",
    "# Create visualization plots for cohort classification analysis\n",
    "# This creates visualizations comparing cohorts using the summary folder files\n",
    "# Visualizations are saved to summary/plots/ for cross-cohort comparisons\n",
    "\n",
    "library(here)\n",
    "\n",
    "# Source the visualization script\n",
    "if (!file.exists(here(\"scripts\", \"R\", \"create_visualizations_cohort.R\"))) {\n",
    "  stop(\"Cannot find scripts/R/create_visualizations_cohort.R. Ensure scripts are in scripts/R/ directory.\")\n",
    "}\n",
    "source(here(\"scripts\", \"R\", \"create_visualizations_cohort.R\"))\n",
    "\n",
    "# Run visualizations using the base output directory (script will look for summary/ folder)\n",
    "# This creates:\n",
    "# - Feature importance heatmap (cohort comparison)\n",
    "# - AUC heatmap (cohort comparison)\n",
    "# - Scaled feature importance bar chart\n",
    "# - AUC table\n",
    "# - Cohort clinical feature Sankey diagram\n",
    "# - Scaled normalized feature importance Sankey diagram\n",
    "run_visualizations(output_dir = output_dir_base)\n",
    "\n",
    "cat(\"\\nâœ“ Cohort classification visualizations saved to:\", file.path(output_dir_base, \"summary\", \"plots\"), \"\\n\")\n",
    "cat(\"  - Feature importance heatmap\\n\")\n",
    "cat(\"  - AUC heatmap\\n\")\n",
    "cat(\"  - Scaled feature importance bar chart\\n\")\n",
    "cat(\"  - AUC table\\n\")\n",
    "cat(\"  - Cohort clinical feature Sankey diagram\\n\")\n",
    "cat(\"  - Scaled normalized feature importance Sankey diagram\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
