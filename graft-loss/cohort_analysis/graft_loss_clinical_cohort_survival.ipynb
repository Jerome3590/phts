{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clinical Cohort Analysis with Monte Carlo Cross-Validation\n",
    "\n",
    "**Study Replication:** Publication-quality cohort-specific analysis with Monte Carlo cross-validation (configurable 50â€“100 splits)  \n",
    "**Updated:** November 21, 2025  \n",
    "**Hardware:** Optimized for 32-core EC2 instance (1TB RAM)  \n",
    "**Validation:** Proper evaluation on unseen test data\n",
    "\n",
    "## Key Changes from Original\n",
    "\n",
    "âœ… **Clinical Cohort Analysis** â€“ CHD vs MyoCardio cohorts with modifiable clinical features  \n",
    "âœ… **Survival Analysis Mode** â€“ Time-to-event analysis with survival models (RSF, AORSF, CatBoost-Cox, XGBoost-Cox)  \n",
    "âœ… **Monte Carlo Cross-Validation** â€“ 50â€“100 random 80/20 train/test splits for cohort-level analysis  \n",
    "âœ… **Stratified Sampling** - Maintains event distribution  \n",
    "âœ… **Parallel Processing** - Fast execution with furrr/future (â‰ˆ30 workers)  \n",
    "âœ… **95% Confidence Intervals** - Narrow, precise estimates (tighter with more splits)  \n",
    "âœ… **Realistic C-Indexes** - Expected range 0.70-0.85\n",
    "\n",
    "## Methodology\n",
    "\n",
    "This notebook implements the feature selection methodology from the original bcjaeger/graft-loss study:\n",
    "\n",
    "1. Load data for pediatric heart transplant outcomes\n",
    "2. Define three time periods:\n",
    "   - **Original**: 2010-2019 (matches publication)\n",
    "   - **Full**: 2010-2024 (all available data)\n",
    "   - **Full No COVID**: 2010-2024 excluding 2020-2023\n",
    "3. For each period and method:\n",
    "   - Create 100â€“1000 stratified train/test splits (75/25)\n",
    "   - Train model on training set\n",
    "   - Evaluate on unseen test set\n",
    "   - Aggregate results across splits\n",
    "4. Calculate C-index with 95% CI\n",
    "5. Extract top 20 features\n",
    "\n",
    "## Expected Runtime (per full 3-period Ã— 3-method run)\n",
    "\n",
    "- **100 splits (current default):**\n",
    "  - Local (4 cores): ~2â€“4 hours (NOT RECOMMENDED)\n",
    "  - Workstation (16 cores): ~1â€“2 hours\n",
    "  - EC2 (32 cores, 1TB RAM): ~1â€“2 hours âœ… **RECOMMENDED FOR DEVELOPMENT**\n",
    "- **1000 splits (extended / publication-level):**\n",
    "  - Local (4 cores): 8â€“12+ hours (NOT RECOMMENDED)\n",
    "  - Workstation (16 cores): ~8â€“16 hours\n",
    "  - EC2 (32 cores, 1TB RAM): ~10â€“20 hours âœ… **RECOMMENDED FOR FINAL RESULTS**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'R version 4.4.3 (2025-02-28)'"
      ],
      "text/latex": [
       "'R version 4.4.3 (2025-02-28)'"
      ],
      "text/markdown": [
       "'R version 4.4.3 (2025-02-28)'"
      ],
      "text/plain": [
       "[1] \"R version 4.4.3 (2025-02-28)\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ All packages loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Check R version\n",
    "R.version.string\n",
    "\n",
    "# Load required packages\n",
    "library(here)\n",
    "library(dplyr)\n",
    "library(readr)\n",
    "library(survival)\n",
    "library(ranger)\n",
    "library(aorsf)\n",
    "library(catboost)\n",
    "library(tidyr)\n",
    "library(purrr)\n",
    "library(tibble)\n",
    "library(janitor)\n",
    "library(haven)\n",
    "library(riskRegression)\n",
    "library(prodlim)\n",
    "library(rsample)    # For MC-CV\n",
    "library(furrr)      # For parallel processing\n",
    "library(future)     # For parallel backend\n",
    "library(progressr)  # For progress bars\n",
    "\n",
    "# Load classification packages (needed for classification mode)\n",
    "if (exists(\"ANALYSIS_MODE\") && ANALYSIS_MODE == \"classification\") {\n",
    "  library(glmnet)      # For LASSO\n",
    "  library(randomForest) # For Traditional RF\n",
    "  library(pROC)         # For AUC calculation\n",
    "  library(cutpointr)    # For threshold optimization\n",
    "  source(here(\"scripts\", \"R\", \"classification_helpers.R\"))\n",
    "  cat(\"âœ“ Classification packages loaded\\n\")\n",
    "}\n",
    "\n",
    "cat(\"âœ“ All packages loaded successfully\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘          ğŸ”„ RESUME MODE: Skipping existing outputs            â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "Set SKIP_EXISTING_OUTPUTS = FALSE to force a fresh start\n",
      "\n",
      "Output directory: /home/pgx3874/graft-loss/cohort_analysis/outputs/survival \n",
      "MC-CV configuration will be displayed after setup is complete.\n"
     ]
    }
   ],
   "source": [
    "# Create output directory\n",
    "output_dir <- here(\"cohort_analysis\", \"outputs\", \"survival\")\n",
    "\n",
    "# IDEMPOTENCY: Skip existing outputs if enabled\n",
    "# Set SKIP_EXISTING_OUTPUTS = TRUE to resume from where you left off\n",
    "# Set SKIP_EXISTING_OUTPUTS = FALSE to start fresh (will clean existing outputs)\n",
    "SKIP_EXISTING_OUTPUTS <- TRUE  # Change to FALSE to force a fresh start\n",
    "\n",
    "if (SKIP_EXISTING_OUTPUTS) {\n",
    "  cat(\"\\n\")\n",
    "  cat(\"â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\\n\")\n",
    "  cat(\"â•‘          ğŸ”„ RESUME MODE: Skipping existing outputs            â•‘\\n\")\n",
    "  cat(\"â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\")\n",
    "  cat(\"Set SKIP_EXISTING_OUTPUTS = FALSE to force a fresh start\\n\\n\")\n",
    "} else {\n",
    "  cat(\"\\n\")\n",
    "  cat(\"â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\\n\")\n",
    "  cat(\"â•‘          ğŸ§¹ FRESH START MODE: Cleaning existing outputs       â•‘\\n\")\n",
    "  cat(\"â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\\n\")\n",
    "  \n",
    "  # Clean existing outputs directory to ensure fresh/clean results\n",
    "  if (dir.exists(output_dir)) {\n",
    "    # Remove all files in outputs directory\n",
    "    output_files <- list.files(output_dir, full.names = TRUE, recursive = TRUE, include.dirs = FALSE)\n",
    "    if (length(output_files) > 0) {\n",
    "      cat(sprintf(\"Cleaning %d existing output files...\\n\", length(output_files)))\n",
    "      file.remove(output_files)\n",
    "    }\n",
    "    # Remove empty subdirectories\n",
    "    output_dirs <- list.dirs(output_dir, recursive = TRUE, full.names = TRUE)\n",
    "    output_dirs <- output_dirs[output_dirs != output_dir]  # Don't remove main directory\n",
    "    for (dir in rev(output_dirs)) {  # Reverse order to remove nested dirs first\n",
    "      if (length(list.files(dir)) == 0) {\n",
    "        unlink(dir, recursive = TRUE)\n",
    "      }\n",
    "    }\n",
    "    cat(\"âœ“ Output directory cleaned\\n\")\n",
    "  }\n",
    "}\n",
    "\n",
    "# Create output directory (if it doesn't exist)\n",
    "dir.create(output_dir, showWarnings = FALSE, recursive = TRUE)\n",
    "\n",
    "cat(\"Output directory:\", output_dir, \"\\n\")\n",
    "cat(\"MC-CV configuration will be displayed after setup is complete.\n",
    "\")\n",
    "flush.console()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration\n",
    "\n",
    "Load required packages and configure parallel processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-detected 32 cores, using 30 workers\n",
      "Setting up parallel processing with 30 workers...\n",
      "Expected speedup: 24x faster than single core\n",
      "Set future.globals.maxSize to 20 GB\n",
      "Cleaning 6 existing output files...\n",
      "âœ“ Output directory cleaned\n",
      "Output directory: /home/pgx3874/graft-loss/cohort_analysis/outputs/survival \n",
      "MC-CV Configuration: 100 splits, 75/25 train/test split\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# DEBUG/TEST MODE - Quick testing before full 100-split run\n",
    "# ============================================================\n",
    "# Set DEBUG_MODE = TRUE for quick testing (5 splits, ~2-5 min)\n",
    "# Set DEBUG_MODE = FALSE for full analysis (100 splits, ~1-2 hours on EC2)\n",
    "DEBUG_MODE <- FALSE  # Change to TRUE for quick test\n",
    "\n",
    "# Analysis Mode: \"survival\" or \"classification\"\n",
    "# - \"survival\": Time-to-event analysis with survival models (RSF, AORSF, CatBoost-Cox, XGBoost-Cox)\n",
    "# - \"classification\": Binary classification at 1 year (LASSO, CatBoost, CatBoost RF, Traditional RF)\n",
    "# Survival Analysis Mode (fixed)\n",
    "\n",
    "# Analysis Mode: Survival Analysis (time-to-event)\n",
    "if (DEBUG_MODE) {\n",
    "  cat(\"\\n\")\n",
    "  cat(\"â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\\n\")\n",
    "  cat(\"â•‘                    ğŸ” DEBUG MODE ENABLED                       â•‘\\n\")\n",
    "  cat(\"â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\")\n",
    "  cat(\"\\n\")\n",
    "  cat(\"Quick test configuration:\\n\")\n",
    "  cat(\"  â€¢ MC-CV Splits: 5 (instead of 100)\\n\")\n",
    "  cat(\"  â€¢ Period: Original only (2010-2019)\\n\")\n",
    "  cat(\"  â€¢ Trees: Reduced (RSF: 100, AORSF: 50)\\n\")\n",
    "  cat(\"  â€¢ Expected time: 2-5 minutes\\n\")\n",
    "  cat(\"  â€¢ Purpose: Verify everything works before full run\\n\")\n",
    "  cat(\"\\n\")\n",
    "  cat(\"To run full analysis, set DEBUG_MODE = FALSE\\n\")\n",
    "  cat(\"\\n\")\n",
    "}\n",
    "\n",
    "# Configuration\n",
    "n_predictors <- 20                                        # Top 20 features\n",
    "n_trees_rsf <- if (DEBUG_MODE) 100 else 500              # RSF trees (reduced in debug)\n",
    "n_trees_aorsf <- if (DEBUG_MODE) 50 else 100             # AORSF trees (reduced in debug)\n",
    "horizon <- 1                                              # 1-year prediction\n",
    "n_mc_splits <- if (DEBUG_MODE) 5 else 100                # MC-CV splits (5 for debug, 100 for full)\n",
    "train_prop <- 0.75                                        # 75% training, 25% testing\n",
    "\n",
    "# Set up parallel processing - EC2 Optimized (32 cores, 1TB RAM)\n",
    "# Use 30 out of 32 cores (leave 2 for system)\n",
    "n_workers <- as.integer(Sys.getenv(\"N_WORKERS\", \"0\"))\n",
    "if (n_workers < 1) {\n",
    "  total_cores <- parallel::detectCores()\n",
    "  n_workers <- max(1, total_cores - 2)\n",
    "  cat(sprintf(\"Auto-detected %d cores, using %d workers\\n\", total_cores, n_workers))\n",
    "}\n",
    "\n",
    "cat(sprintf(\"Setting up parallel processing with %d workers...\\n\", n_workers))\n",
    "cat(sprintf(\"Expected speedup: %dx faster than single core\\n\", round(n_workers * 0.8)))\n",
    "\n",
    "# Increase future.globals.maxSize for large MC-CV splits object\n",
    "# With 1TB RAM on EC2, we can handle large transfers\n",
    "options(future.globals.maxSize = 20 * 1024^3)  # 20 GB limit (plenty for 100 splits)\n",
    "cat(\"Set future.globals.maxSize to 20 GB\\n\")\n",
    "\n",
    "plan(multisession, workers = n_workers)\n",
    "\n",
    "# Create output directory (clean first to ensure fresh start)\n",
    "output_dir <- here(\"cohort_analysis\", \"outputs\", \"survival\")\n",
    "\n",
    "# Clean existing outputs directory to ensure fresh/clean results\n",
    "if (dir.exists(output_dir)) {\n",
    "  # Remove all files in outputs directory\n",
    "  output_files <- list.files(output_dir, full.names = TRUE, recursive = TRUE, include.dirs = FALSE)\n",
    "  if (length(output_files) > 0) {\n",
    "    cat(sprintf(\"Cleaning %d existing output files...\\n\", length(output_files)))\n",
    "    file.remove(output_files)\n",
    "  }\n",
    "  # Remove empty subdirectories\n",
    "  output_dirs <- list.dirs(output_dir, recursive = TRUE, full.names = TRUE)\n",
    "  output_dirs <- output_dirs[output_dirs != output_dir]  # Don't remove main directory\n",
    "  for (dir in rev(output_dirs)) {  # Reverse order to remove nested dirs first\n",
    "    if (length(list.files(dir)) == 0) {\n",
    "      unlink(dir, recursive = TRUE)\n",
    "    }\n",
    "  }\n",
    "  cat(\"âœ“ Output directory cleaned\\n\")\n",
    "}\n",
    "\n",
    "# Create fresh output directory\n",
    "dir.create(output_dir, showWarnings = FALSE, recursive = TRUE)\n",
    "\n",
    "cat(\"Output directory:\", output_dir, \"\\n\")\n",
    "cat(sprintf(\"MC-CV Configuration: %d splits, %.0f/%.0f train/test split\\n\", \n",
    "            n_mc_splits, train_prop * 100, (1 - train_prop) * 100))\n",
    "flush.console()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Helper Functions\n",
    "\n",
    "Define functions for data preparation, C-index calculation, and prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ prepare_modeling_data() defined\n"
     ]
    }
   ],
   "source": [
    "# Prepare modeling data with leakage prevention\n",
    "# Supports both survival and classification modes\n",
    "prepare_modeling_data <- function(data, mode = \"survival\") {\n",
    "  if (mode == \"survival\") {\n",
    "    # Survival mode: Find time and status columns\n",
    "    time_col <- intersect(c(\"time\", \"outcome_int_graft_loss\", \"int_graft_loss\"), names(data))[1]\n",
    "    status_col <- intersect(c(\"status\", \"outcome_graft_loss\", \"graft_loss\"), names(data))[1]\n",
    "    \n",
    "    if (is.na(time_col) || is.na(status_col)) {\n",
    "      stop(\"Cannot find time/status columns for survival mode\")\n",
    "    }\n",
    "    \n",
    "    # Rename to standard names\n",
    "    if (time_col != \"time\") data <- data %>% rename(time = !!time_col)\n",
    "    if (status_col != \"status\") data <- data %>% rename(status = !!status_col)\n",
    "  } else if (mode == \"classification\") {\n",
    "    # Classification mode: Find outcome column\n",
    "    outcome_col <- intersect(c(\"outcome\", \"outcome_1yr\", \"event_1yr\"), names(data))[1]\n",
    "    \n",
    "    if (is.na(outcome_col)) {\n",
    "      # Try to create outcome from time/status if available\n",
    "      if (\"ev_time\" %in% names(data) && \"ev_type\" %in% names(data)) {\n",
    "        data <- data %>%\n",
    "          mutate(\n",
    "            outcome = case_when(\n",
    "              ev_type == 1 & ev_time < 1 ~ 1L,  # Event by 1 year\n",
    "              ev_type == 0 & ev_time >= 1 ~ 0L,  # No event, follow-up >= 1 year\n",
    "              TRUE ~ NA_integer_  # Censored before 1 year - drop\n",
    "            )\n",
    "          ) %>%\n",
    "          filter(!is.na(outcome))  # Drop censored before 1 year\n",
    "        cat(\"â†’ Created outcome variable from ev_time and ev_type\\n\")\n",
    "      } else {\n",
    "        stop(\"Cannot find outcome column or ev_time/ev_type for classification mode\")\n",
    "      }\n",
    "    } else if (outcome_col != \"outcome\") {\n",
    "      data <- data %>% rename(outcome = !!outcome_col)\n",
    "    }\n",
    "  } else {\n",
    "    stop(\"Invalid ANALYSIS_MODE. Must be 'survival' or 'classification'\")\n",
    "  }\n",
    "  \n",
    "  # Exclude leakage variables and identifier columns\n",
    "  exclude_exact <- c(\n",
    "    \"ID\", \"ptid_e\", \"int_dead\", \"int_death\", \"graft_loss\", \"txgloss\", \"death\", \"event\",\n",
    "    \"dpricaus\", \"deathspc\", \"concod\", \"age_death\", \"dlist\", \"txpl_year\",\n",
    "    \"rrace_b\", \"rrace_a\", \"rrace_ai\", \"rrace_pi\", \"rrace_o\", \"rrace_un\", \"race\",\n",
    "    \"patsupp\", \"pmorexam\", \"papooth\", \"pacuref\", \"pishltgr\",\n",
    "    \"pathero\", \"pcadrec\", \"pcadrem\", \"pdiffib\", \"cpathneg\",\n",
    "    \"dcardiac\", \"dneuro\", \"dreject\", \"dsecaccs\", \"dpriaccs\",\n",
    "    \"dconmbld\", \"dconmal\", \"dconcard\", \"dconneur\", \"dconrej\",\n",
    "    \"dmajbld\", \"dmalcanc\"\n",
    "  )\n",
    "  \n",
    "  exclude_prefixes <- c(\"dtx_\", \"cc_\", \"dcon\", \"dpri\", \"dsec\", \"dmaj\", \"sd\")\n",
    "  \n",
    "  exclude_by_prefix <- character(0)\n",
    "  for (prefix in exclude_prefixes) {\n",
    "    exclude_by_prefix <- c(exclude_by_prefix, \n",
    "                           names(data)[startsWith(names(data), prefix)])\n",
    "  }\n",
    "  \n",
    "  exclude_all <- unique(c(exclude_exact, exclude_by_prefix))\n",
    "  data <- data %>% select(-any_of(exclude_all))\n",
    "  \n",
    "  # Median imputation for numeric variables\n",
    "  numeric_vars <- names(data)[sapply(data, is.numeric) & names(data) != \"time\" & names(data) != \"status\"]\n",
    "  for (var in numeric_vars) {\n",
    "    if (any(is.na(data[[var]]))) {\n",
    "      median_val <- median(data[[var]], na.rm = TRUE)\n",
    "      data[[var]][is.na(data[[var]])] <- median_val\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  # Mode imputation for categorical variables\n",
    "  categorical_vars <- names(data)[sapply(data, function(x) is.factor(x) | is.character(x))]\n",
    "  for (var in categorical_vars) {\n",
    "    if (any(is.na(data[[var]]))) {\n",
    "      mode_val <- names(sort(table(data[[var]]), decreasing = TRUE))[1]\n",
    "      data[[var]][is.na(data[[var]])] <- mode_val\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  # Remove constant columns\n",
    "  constant_cols <- names(data)[sapply(data, function(x) length(unique(na.omit(x))) <= 1)]\n",
    "  if (length(constant_cols) > 0) {\n",
    "    data <- data %>% select(-any_of(constant_cols))\n",
    "  }\n",
    "  \n",
    "  # Convert character to factor\n",
    "  data <- data %>% mutate(across(where(is.character), as.factor))\n",
    "  \n",
    "  return(data)\n",
    "}\n",
    "\n",
    "cat(\"âœ“ prepare_modeling_data() defined\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ calculate_cindex() and ranger_predictrisk() defined\n"
     ]
    }
   ],
   "source": [
    "# C-index calculation\n",
    "calculate_cindex <- function(time, status, risk_scores, horizon = NULL) {\n",
    "  valid_idx <- !is.na(time) & !is.na(status) & !is.na(risk_scores) &\n",
    "               is.finite(time) & is.finite(risk_scores) & time > 0\n",
    "  \n",
    "  time   <- as.numeric(time[valid_idx])\n",
    "  status <- as.numeric(status[valid_idx])\n",
    "  risk   <- as.numeric(risk_scores[valid_idx])\n",
    "  \n",
    "  n <- length(time)\n",
    "  events <- sum(status == 1)\n",
    "  \n",
    "  if (n < 10 || events < 1 || length(unique(risk)) == 1) {\n",
    "    return(list(cindex_td = NA_real_, cindex_ti = NA_real_))\n",
    "  }\n",
    "  \n",
    "  # Time-independent C-index (Harrell's)\n",
    "  num_conc_ti <- 0\n",
    "  num_disc_ti <- 0\n",
    "  num_ties_ti <- 0\n",
    "  \n",
    "  for (i in seq_len(n)) {\n",
    "    if (status[i] != 1) next\n",
    "    for (j in seq_len(n)) {\n",
    "      if (i == j) next\n",
    "      if (time[i] < time[j]) {\n",
    "        if (risk[i] > risk[j]) {\n",
    "          num_conc_ti <- num_conc_ti + 1\n",
    "        } else if (risk[i] < risk[j]) {\n",
    "          num_disc_ti <- num_disc_ti + 1\n",
    "        } else {\n",
    "          num_ties_ti <- num_ties_ti + 1\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  denom_ti <- num_conc_ti + num_disc_ti + num_ties_ti\n",
    "  cindex_ti <- if (denom_ti > 0) (num_conc_ti + 0.5 * num_ties_ti) / denom_ti else NA_real_\n",
    "  \n",
    "  # Time-dependent C-index\n",
    "  cindex_td <- tryCatch({\n",
    "    score_data <- data.frame(time = time, status = status)\n",
    "    pred_matrix <- matrix(risk, ncol = 1)\n",
    "    \n",
    "    evaluation <- riskRegression::Score(\n",
    "      object = list(Model = pred_matrix),\n",
    "      formula = Surv(time, status) ~ 1,\n",
    "      data = score_data,\n",
    "      times = if (!is.null(horizon)) horizon else median(time[status == 1]),\n",
    "      summary = \"risks\",\n",
    "      metrics = \"auc\",\n",
    "      se.fit = FALSE\n",
    "    )\n",
    "    \n",
    "    as.numeric(evaluation$AUC$score$AUC[1])\n",
    "  }, error = function(e) cindex_ti)\n",
    "  \n",
    "  return(list(cindex_td = cindex_td, cindex_ti = cindex_ti))\n",
    "}\n",
    "\n",
    "# ranger_predictrisk function\n",
    "ranger_predictrisk <- function(object, newdata, times) {\n",
    "  preds <- predict(object, data = newdata, type = \"response\")\n",
    "  if (is.null(preds$survival)) {\n",
    "    stop(\"ranger prediction did not return survival probabilities\")\n",
    "  }\n",
    "  \n",
    "  surv_matrix <- preds$survival\n",
    "  time_points <- preds$unique.death.times\n",
    "  closest_idx <- which.min(abs(time_points - times))\n",
    "  risk_scores <- 1 - surv_matrix[, closest_idx]\n",
    "  \n",
    "  return(as.numeric(risk_scores))\n",
    "}\n",
    "\n",
    "cat(\"âœ“ calculate_cindex() and ranger_predictrisk() defined\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Monte Carlo Cross-Validation Function\n",
    "\n",
    "Main function that runs MC-CV for a single method and period.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ run_mc_cv_method() defined\n"
     ]
    }
   ],
   "source": [
    "# Run MC-CV for a single method and time period\n",
    "run_mc_cv_method <- function(data, method, period_name, mc_splits) {\n",
    "  \n",
    "  cat(sprintf(\"\\n=== Running MC-CV for %s (%s) ===\\n\", method, period_name))\n",
    "  cat(sprintf(\"Splits: %d | Train: %.0f%% | Test: %.0f%%\\n\", \n",
    "              n_mc_splits, train_prop * 100, (1 - train_prop) * 100))\n",
    "  flush.console()\n",
    "  \n",
    "  split_ids <- seq_len(n_mc_splits)\n",
    "  \n",
    "  # Run splits in parallel with progress bar\n",
    "  with_progress({\n",
    "    p <- progressor(steps = n_mc_splits)\n",
    "    \n",
    "    results <- future_map(split_ids, function(split_id) {\n",
    "      p()  # Update progress\n",
    "      \n",
    "      # Get train/test data from split\n",
    "      split <- mc_splits$splits[[split_id]]\n",
    "      train_data <- rsample::analysis(split)\n",
    "      test_data <- rsample::assessment(split)\n",
    "      \n",
    "      # Train and evaluate\n",
    "      model <- NULL\n",
    "      predictions <- NULL\n",
    "      feature_importance <- NULL\n",
    "      \n",
    "      tryCatch({\n",
    "        if (method == \"RSF\") {\n",
    "          model <- ranger(\n",
    "            Surv(time, status) ~ .,\n",
    "            data = train_data,\n",
    "            num.trees = n_trees_rsf,\n",
    "            importance = \"permutation\",\n",
    "            min.node.size = 20,\n",
    "            splitrule = \"extratrees\",\n",
    "            num.random.splits = 10\n",
    "          )\n",
    "          \n",
    "          predictions <- ranger_predictrisk(model, test_data, horizon)\n",
    "          feature_importance <- model$variable.importance\n",
    "          \n",
    "        } else if (method == \"AORSF\") {\n",
    "          # Remove constant columns from training data (can occur after train/test split)\n",
    "          constant_cols <- names(train_data)[sapply(train_data, function(x) {\n",
    "            if (is.numeric(x)) {\n",
    "              length(unique(na.omit(x))) <= 1\n",
    "            } else {\n",
    "              length(unique(na.omit(x))) <= 1\n",
    "            }\n",
    "          })]\n",
    "          constant_cols <- setdiff(constant_cols, c(\"time\", \"status\"))\n",
    "          if (length(constant_cols) > 0) {\n",
    "            train_data <- train_data %>% select(-any_of(constant_cols))\n",
    "            test_data <- test_data %>% select(-any_of(constant_cols))\n",
    "          }\n",
    "          \n",
    "          model <- aorsf::orsf(\n",
    "            data = train_data,\n",
    "            formula = Surv(time, status) ~ .,\n",
    "            n_tree = n_trees_aorsf,\n",
    "            na_action = 'impute_meanmode'\n",
    "          )\n",
    "          \n",
    "          pred_obj <- predict(model, new_data = test_data, \n",
    "                              pred_type = 'risk', pred_horizon = horizon)\n",
    "          predictions <- if (is.matrix(pred_obj)) as.numeric(pred_obj[, 1]) else as.numeric(pred_obj)\n",
    "          feature_importance <- aorsf::orsf_vi_permute(model)\n",
    "          \n",
    "        } else if (method == \"CatBoost\") {\n",
    "          # Remove constant columns from training data (can occur after train/test split)\n",
    "          constant_cols <- names(train_data)[sapply(train_data, function(x) {\n",
    "            if (is.numeric(x)) {\n",
    "              length(unique(na.omit(x))) <= 1\n",
    "            } else {\n",
    "              length(unique(na.omit(x))) <= 1\n",
    "            }\n",
    "          })]\n",
    "          constant_cols <- setdiff(constant_cols, c(\"time\", \"status\"))\n",
    "          if (length(constant_cols) > 0) {\n",
    "            train_data <- train_data %>% select(-any_of(constant_cols))\n",
    "            test_data <- test_data %>% select(-any_of(constant_cols))\n",
    "          }\n",
    "          \n",
    "          train_pool <- catboost.load_pool(\n",
    "            data = train_data %>% select(-time, -status),\n",
    "            label = train_data$time\n",
    "          )\n",
    "          \n",
    "          test_pool <- catboost.load_pool(\n",
    "            data = test_data %>% select(-time, -status)\n",
    "          )\n",
    "          \n",
    "          # CatBoost configuration: single-threaded inside each R worker to avoid\n",
    "          # logger/thread-safety issues, and quiet logging in parallel runs.\n",
    "          params <- list(\n",
    "            loss_function  = 'Cox',\n",
    "            iterations     = 100,\n",
    "            learning_rate  = 0.1,\n",
    "            depth          = 6,\n",
    "            thread_count   = 1,\n",
    "            logging_level  = 'Silent',\n",
    "            verbose        = 0L\n",
    "          )\n",
    "          \n",
    "          model <- catboost.train(train_pool, params = params)\n",
    "          predictions <- catboost.predict(model, test_pool)\n",
    "          \n",
    "          # Get feature importance - CatBoost returns a matrix with rownames as feature names\n",
    "          # IMPORTANT: catboost.get_feature_importance() returns a matrix (not a named vector)\n",
    "          # - Values are in the first column: importance_matrix[, 1]\n",
    "          # - Feature names are in rownames: rownames(importance_matrix)\n",
    "          # Convert to named vector for consistency with RSF and AORSF (which return named vectors directly)\n",
    "          importance_matrix <- catboost.get_feature_importance(model)\n",
    "          feature_importance <- as.numeric(importance_matrix[, 1])\n",
    "          names(feature_importance) <- rownames(importance_matrix)\n",
    "        }\n",
    "        \n",
    "        # Calculate C-index on TEST data\n",
    "        cindex_result <- calculate_cindex(\n",
    "          time = test_data$time,\n",
    "          status = test_data$status,\n",
    "          risk_scores = predictions,\n",
    "          horizon = horizon\n",
    "        )\n",
    "        \n",
    "        return(list(\n",
    "          split_id = split_id,\n",
    "          cindex_td = cindex_result$cindex_td,\n",
    "          cindex_ti = cindex_result$cindex_ti,\n",
    "          feature_importance = feature_importance,\n",
    "          n_train = nrow(train_data),\n",
    "          n_test = nrow(test_data),\n",
    "          success = TRUE\n",
    "        ))\n",
    "        \n",
    "      }, error = function(e) {\n",
    "        return(list(\n",
    "          split_id = split_id,\n",
    "          cindex_td = NA_real_,\n",
    "          cindex_ti = NA_real_,\n",
    "          feature_importance = NULL,\n",
    "          n_train = nrow(train_data),\n",
    "          n_test = nrow(test_data),\n",
    "          success = FALSE,\n",
    "          error = e$message\n",
    "        ))\n",
    "      })\n",
    "    }, .options = furrr_options(\n",
    "      seed = TRUE,\n",
    "      packages = c(\n",
    "        \"dplyr\", \"purrr\", \"tibble\", \"rsample\",\n",
    "        \"ranger\", \"aorsf\", \"catboost\",\n",
    "        \"riskRegression\", \"prodlim\"\n",
    "      )\n",
    "    ))\n",
    "  })\n",
    "  \n",
    "  # Aggregate results\n",
    "  successful_splits <- Filter(function(x) x$success, results)\n",
    "  n_successful <- length(successful_splits)\n",
    "  \n",
    "  cat(sprintf(\"Successful splits: %d / %d\\n\", n_successful, n_mc_splits))\n",
    "  flush.console()\n",
    "  \n",
    "  # If all splits failed (e.g., CatBoost configuration/data issue),\n",
    "  # do not stop the whole analysis. Instead, log a warning and return\n",
    "  # an empty/NA summary so that other methods and periods can continue.\n",
    "  if (n_successful == 0) {\n",
    "    error_splits <- Filter(function(x) !is.null(x$error), results)\n",
    "    if (length(error_splits) > 0) {\n",
    "      first_error <- error_splits[[1]]$error\n",
    "      cat(sprintf(\"WARNING: example error for %s (%s): %s\\n\",\n",
    "                  method, period_name, first_error))\n",
    "    }\n",
    "    cat(sprintf(\"WARNING: All MC-CV splits failed for %s (%s). Skipping this method.\\n\",\n",
    "                method, period_name))\n",
    "    flush.console()\n",
    "    \n",
    "    return(list(\n",
    "      method = method,\n",
    "      period = period_name,\n",
    "      n_splits = n_mc_splits,\n",
    "      n_successful = 0,\n",
    "      cindex_td_mean = NA_real_,\n",
    "      cindex_td_sd = NA_real_,\n",
    "      cindex_td_ci_lower = NA_real_,\n",
    "      cindex_td_ci_upper = NA_real_,\n",
    "      cindex_ti_mean = NA_real_,\n",
    "      cindex_ti_sd = NA_real_,\n",
    "      cindex_ti_ci_lower = NA_real_,\n",
    "      cindex_ti_ci_upper = NA_real_,\n",
    "      top_features = numeric(0)\n",
    "    ))\n",
    "  }\n",
    "  \n",
    "  # Extract C-indexes\n",
    "  cindex_td_values <- sapply(successful_splits, function(x) x$cindex_td)\n",
    "  cindex_ti_values <- sapply(successful_splits, function(x) x$cindex_ti)\n",
    "  \n",
    "  cindex_td_values <- cindex_td_values[!is.na(cindex_td_values)]\n",
    "  cindex_ti_values <- cindex_ti_values[!is.na(cindex_ti_values)]\n",
    "  \n",
    "  # Aggregate feature importance\n",
    "  # All methods (RSF, AORSF, CatBoost) return named numeric vectors\n",
    "  all_feature_names <- unique(unlist(lapply(successful_splits, function(x) {\n",
    "    if (is.null(x$feature_importance)) return(NULL)\n",
    "    names(x$feature_importance)\n",
    "  })))\n",
    "  \n",
    "  aggregated_importance <- sapply(all_feature_names, function(feature) {\n",
    "    importances <- sapply(successful_splits, function(x) {\n",
    "      if (is.null(x$feature_importance)) return(NA_real_)\n",
    "      if (feature %in% names(x$feature_importance)) {\n",
    "        return(as.numeric(x$feature_importance[feature]))\n",
    "      }\n",
    "      return(NA_real_)\n",
    "    })\n",
    "    mean(importances, na.rm = TRUE)\n",
    "  })\n",
    "  \n",
    "  # Ensure aggregated_importance is a numeric vector\n",
    "  aggregated_importance <- as.numeric(aggregated_importance)\n",
    "  names(aggregated_importance) <- all_feature_names\n",
    "  \n",
    "  top_features <- sort(aggregated_importance, decreasing = TRUE)[1:min(n_predictors, length(aggregated_importance))]\n",
    "  \n",
    "  # Calculate statistics\n",
    "  results_summary <- list(\n",
    "    method = method,\n",
    "    period = period_name,\n",
    "    n_splits = n_mc_splits,\n",
    "    n_successful = n_successful,\n",
    "    cindex_td_mean = mean(cindex_td_values, na.rm = TRUE),\n",
    "    cindex_td_sd = sd(cindex_td_values, na.rm = TRUE),\n",
    "    cindex_td_ci_lower = quantile(cindex_td_values, 0.025, na.rm = TRUE),\n",
    "    cindex_td_ci_upper = quantile(cindex_td_values, 0.975, na.rm = TRUE),\n",
    "    cindex_ti_mean = mean(cindex_ti_values, na.rm = TRUE),\n",
    "    cindex_ti_sd = sd(cindex_ti_values, na.rm = TRUE),\n",
    "    cindex_ti_ci_lower = quantile(cindex_ti_values, 0.025, na.rm = TRUE),\n",
    "    cindex_ti_ci_upper = quantile(cindex_ti_values, 0.975, na.rm = TRUE),\n",
    "    top_features = top_features\n",
    "  )\n",
    "  \n",
    "  # Print summary\n",
    "  cat(sprintf(\"\\n--- Results for %s (%s) ---\\n\", method, period_name))\n",
    "  cat(sprintf(\"Time-Dependent C-Index: %.4f Â± %.4f (95%% CI: %.4f - %.4f)\\n\",\n",
    "              results_summary$cindex_td_mean,\n",
    "              results_summary$cindex_td_sd,\n",
    "              results_summary$cindex_td_ci_lower,\n",
    "              results_summary$cindex_td_ci_upper))\n",
    "  cat(sprintf(\"Time-Independent C-Index: %.4f Â± %.4f (95%% CI: %.4f - %.4f)\\n\",\n",
    "              results_summary$cindex_ti_mean,\n",
    "              results_summary$cindex_ti_sd,\n",
    "              results_summary$cindex_ti_ci_lower,\n",
    "              results_summary$cindex_ti_ci_upper))\n",
    "  # Display top 10 features sorted alphabetically for easier comparison\n",
    "  top10_features <- names(top_features)[1:min(10, length(top_features))]\n",
    "  top10_features_sorted <- sort(top10_features)\n",
    "  cat(sprintf(\"Top 10 features (alphabetical): %s\\n\", paste(top10_features_sorted, collapse = \", \")))\n",
    "  flush.console()\n",
    "  \n",
    "  return(results_summary)\n",
    "}\n",
    "\n",
    "cat(\"âœ“ run_mc_cv_method() defined\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: /home/pgx3874/graft-loss/data/phts_txpl_ml.sas7bdat \n",
      "âœ“ Loaded data: 5835 rows, 478 columns\n"
     ]
    }
   ],
   "source": [
    "# Find and load SAS file\n",
    "sas_path_local <- here(\"data\", \"phts_txpl_ml.sas7bdat\")\n",
    "sas_path_external <- here(\"graft-loss-parallel-processing\", \"data\", \"phts_txpl_ml.sas7bdat\")\n",
    "sas_path_graft_loss <- here(\"graft-loss\", \"data\", \"phts_txpl_ml.sas7bdat\")\n",
    "\n",
    "sas_path <- NULL\n",
    "for (path in c(sas_path_local, sas_path_external, sas_path_graft_loss)) {\n",
    "  if (file.exists(path)) {\n",
    "    sas_path <- path\n",
    "    break\n",
    "  }\n",
    "}\n",
    "\n",
    "if (is.null(sas_path)) {\n",
    "  stop(\"Cannot find phts_txpl_ml.sas7bdat in any location\")\n",
    "}\n",
    "\n",
    "cat(\"Loading data from:\", sas_path, \"\\n\")\n",
    "\n",
    "# Load data\n",
    "phts_base <- haven::read_sas(sas_path) %>%\n",
    "  filter(TXPL_YEAR >= 2010) %>%\n",
    "  janitor::clean_names() %>%\n",
    "  rename(\n",
    "    outcome_int_graft_loss = int_graft_loss,\n",
    "    outcome_graft_loss = graft_loss\n",
    "  ) %>%\n",
    "  mutate(\n",
    "    ID = 1:n(),\n",
    "    across(.cols = where(is.character), ~ ifelse(.x %in% c(\"\", \"unknown\", \"missing\"), NA_character_, .x)),\n",
    "    across(.cols = where(is.character), as.factor),\n",
    "    tx_mcsd = if ('txnomcsd' %in% names(.)) {\n",
    "      if_else(txnomcsd == 'yes', 0, 1)\n",
    "    } else if ('txmcsd' %in% names(.)) {\n",
    "      txmcsd\n",
    "    } else {\n",
    "      NA_real_\n",
    "    }\n",
    "  )\n",
    "\n",
    "cat(sprintf(\"âœ“ Loaded data: %d rows, %d columns\\n\", nrow(phts_base), ncol(phts_base)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Period: original | N: 4036 | Events: 768 (19.03%)\n",
      "Period: full | N: 5835 | Events: 939 (16.09%)\n",
      "Period: full_no_covid | N: 4196 | Events: 774 (18.45%)\n",
      "\n",
      "âœ“ Time periods defined\n"
     ]
    }
   ],
   "source": [
    "# Define time periods\n",
    "periods <- list()\n",
    "periods$original <- phts_base %>% filter(txpl_year >= 2010 & txpl_year <= 2019)\n",
    "periods$full <- phts_base %>% filter(txpl_year >= 2010)\n",
    "periods$full_no_covid <- phts_base %>% filter(txpl_year >= 2010 & !(txpl_year >= 2020 & txpl_year <= 2023))\n",
    "\n",
    "# Print summary\n",
    "for (period_name in names(periods)) {\n",
    "  period_data <- periods[[period_name]]\n",
    "  n_events <- sum(period_data$outcome_graft_loss, na.rm = TRUE)\n",
    "  event_rate <- 100 * n_events / nrow(period_data)\n",
    "  \n",
    "  cat(sprintf(\"Period: %s | N: %d | Events: %d (%.2f%%)\\n\", \n",
    "              period_name, nrow(period_data), n_events, event_rate))\n",
    "}\n",
    "\n",
    "cat(\"\\nâœ“ Time periods defined\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run Analysis\n",
    "Execute MC-CV for all methods and periods\n",
    "- **100 splits (default full run):** Typically ~1â€“2 hours on a 32-core EC2 instance, longer on smaller machines.\n",
    "- **1000 splits (extended run):** Linearly more expensive; expect roughly 8â€“10Ã— the 100-split time.\n",
    "- **Note:** You can run each period separately by uncommenting only one `period_name` at a time, or reduce the number of methods/periods to shorten runtime further. Default is all methods for full dataset (all periods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "Processing Period: original\n",
      "========================================\n",
      "Period data: 4036 rows, 381 columns\n",
      "Events: 768 (19.03%)\n",
      "Creating 100 MC-CV splits (stratified)...\n",
      "\n",
      "=== Running MC-CV for RSF (original) ===\n",
      "Splits: 100 | Train: 75% | Test: 25%\n"
     ]
    }
   ],
   "source": [
    "# Select periods and methods to run\n",
    "# In DEBUG_MODE, only run original period for speed\n",
    "period_names <- if (DEBUG_MODE) {\n",
    "  c(\"original\")  # Debug: just one period (~2-5 min)\n",
    "} else {\n",
    "  c(\"original\", \"full\", \"full_no_covid\")  # Full: all periods (~30-45 min)\n",
    "}\n",
    "\n",
    "# Methods to run. Include CatBoost (with single-threaded, quiet config)\n",
    "# alongside RSF and AORSF.\n",
    "method_names <- c(\"RSF\", \"CatBoost\", \"AORSF\")\n",
    "\n",
    "# Store all results\n",
    "all_results <- list()\n",
    "\n",
    "# Run analysis\n",
    "for (period_name in period_names) {\n",
    "  cat(sprintf(\"\\n========================================\\n\"))\n",
    "  cat(sprintf(\"Processing Period: %s\\n\", period_name))\n",
    "  cat(sprintf(\"========================================\\n\"))\n",
    "  flush.console()\n",
    "  \n",
    "  # Prepare data\n",
    "  period_data <- prepare_modeling_data(periods[[period_name]])\n",
    "  \n",
    "  cat(sprintf(\"Period data: %d rows, %d columns\\n\", nrow(period_data), ncol(period_data)))\n",
    "  cat(sprintf(\"Events: %d (%.2f%%)\\n\", sum(period_data$status), \n",
    "              100 * sum(period_data$status) / nrow(period_data)))\n",
    "  \n",
    "  # Create MC-CV splits (stratified by outcome)\n",
    "  cat(sprintf(\"Creating %d MC-CV splits (stratified)...\\n\", n_mc_splits))\n",
    "  flush.console()\n",
    "  mc_splits <- mc_cv(\n",
    "    data = period_data,\n",
    "    prop = train_prop,\n",
    "    times = n_mc_splits,\n",
    "    strata = status\n",
    "  )\n",
    "  \n",
    "  # Run each method\n",
    "  period_results <- list()\n",
    "  \n",
    "  for (method in method_names) {\n",
    "    # Check if output file already exists (idempotency)\n",
    "    output_file <- file.path(output_dir, sprintf(\"%s_%s_top20.csv\", \n",
    "                                                  period_name, tolower(method)))\n",
    "    if (SKIP_EXISTING_OUTPUTS && file.exists(output_file)) {\n",
    "      cat(sprintf(\"\\nâ­ Skipping %s (%s) - output file already exists: %s\\n\", \n",
    "                  method, period_name, basename(output_file)))\n",
    "      period_results[[method]] <- NULL\n",
    "      next\n",
    "    }\n",
    "    \n",
    "    result <- run_mc_cv_method(period_data, method, period_name, mc_splits)\n",
    "    period_results[[method]] <- result\n",
    "    \n",
    "    # Save top features (sorted alphabetically for easier comparison)\n",
    "    top_features_df <- tibble(\n",
    "      feature = names(result$top_features),\n",
    "      importance = as.numeric(result$top_features),\n",
    "      cindex_td = result$cindex_td_mean,\n",
    "      cindex_ti = result$cindex_ti_mean\n",
    "    ) %>%\n",
    "      arrange(feature)  # Sort alphabetically for easier visual comparison\n",
    "    \n",
    "    write_csv(top_features_df, output_file)\n",
    "    cat(sprintf(\"âœ“ Saved: %s\\n\", basename(output_file)))\n",
    "  }\n",
    "    \n",
    "  all_results[[period_name]] <- period_results\n",
    "}\n",
    "\n",
    "cat(\"\\nâœ“ Analysis complete for all methods!\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Clinical Feature Importance by Cohort (Modifiable Features)\n",
    "\n",
    "This section builds **cohort-specific survival models** using **only clinically modifiable features** and reports:\n",
    "\n",
    "- **C-index for each model and cohort** (CatBoost, RSF, XGBoost, XGBoost RF-mode, AORSF)\n",
    "- **Top clinical features** (by importance) for the **best C-index model in each cohort**\n",
    "\n",
    "Cohorts follow prior work:\n",
    "\n",
    "- **CHD cohort**: `primary_etiology == \"Congenital HD\"`\n",
    "- **Myocarditis/Cardiomyopathy cohort**: `primary_etiology %in% c(\"Cardiomyopathy\", \"Myocarditis\")`\n",
    "\n",
    "All models are fit on the **same 80/20 unified train/test split per cohort** for fair comparison.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Define Cohorts and Prepare Data\n",
    "\n",
    "Filter dataset to modifiable clinical features and define CHD vs MyoCardio cohorts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# 6.1 Define modifiable clinical features\n",
    "\n",
    "library(tibble)\n",
    "library(dplyr)\n",
    "\n",
    "# Actionable / modifiable clinical features (raw PHTS variable names)\n",
    "actionable_features <- tribble(\n",
    "  ~Feature,      ~Category,              ~Potential_Intervention,                        ~Modifiability,\n",
    "  \n",
    "  # Kidney Function\n",
    "  \"txcreat_r\", \"Kidney Function\",     \"Monitor kidney function\",                      \"Partially Modifiable\",\n",
    "  \"lcreat_r\",  \"Kidney Function\",     \"Monitor kidney function\",                      \"Partially Modifiable\",\n",
    "  \"hxdysdia\",  \"Kidney Function\",     \"Dialysis management\",                          \"Partially Modifiable\",\n",
    "  \"hxrenins\",  \"Kidney Function\",     \"Renal optimization\",                           \"Partially Modifiable\",\n",
    "  \"egfr_tx\",   \"Kidney Function\",     \"eGFR-based intervention\",                      \"Partially Modifiable\",\n",
    "  \n",
    "  # Liver Function\n",
    "  \"txast\",     \"Liver Function\",      \"Liver function monitoring\",                    \"Partially Modifiable\",\n",
    "  \"lsast\",     \"Liver Function\",      \"Liver function monitoring\",                    \"Partially Modifiable\",\n",
    "  \"txalt\",     \"Liver Function\",      \"Liver function monitoring\",                    \"Partially Modifiable\",\n",
    "  \"lsalt\",     \"Liver Function\",      \"Liver function monitoring\",                    \"Partially Modifiable\",\n",
    "  \"txbili_d_r\",\"Liver Function\",      \"Direct bilirubin assessment\",                  \"Partially Modifiable\",\n",
    "  \"lsbili_d_r\",\"Liver Function\",      \"Direct bilirubin assessment\",                  \"Partially Modifiable\",\n",
    "  \"txbili_t_r\",\"Liver Function\",      \"Total bilirubin assessment\",                   \"Partially Modifiable\",\n",
    "  \"lsbili_t_r\",\"Liver Function\",      \"Total bilirubin assessment\",                   \"Partially Modifiable\",\n",
    "  \"hxfonlvr\",  \"Liver Function\",      \"Fontan liver disease management\",              \"Partially Modifiable\",\n",
    "  \n",
    "  # Nutrition\n",
    "  \"txpalb_r\",  \"Nutrition\",           \"Nutritional support\",                          \"Modifiable\",\n",
    "  \"lspalb_r\",  \"Nutrition\",           \"Nutritional support\",                          \"Modifiable\",\n",
    "  \"txsa_r\",    \"Nutrition\",           \"Albumin-based nutrition\",                      \"Modifiable\",\n",
    "  \"lssab_r\",   \"Nutrition\",           \"Albumin-based nutrition\",                      \"Modifiable\",\n",
    "  \"txtp_r\",    \"Nutrition\",           \"Protein intake optimization\",                  \"Modifiable\",\n",
    "  \"lstp_r\",    \"Nutrition\",           \"Protein intake optimization\",                  \"Modifiable\",\n",
    "  \"hxfail\",    \"Nutrition\",           \"Nutrition and growth support\",                 \"Modifiable\",\n",
    "  \"bmi_txpl\",  \"Nutrition\",           \"Nutritional optimization\",                     \"Modifiable\",\n",
    "  \"height_txpl\",\"Nutrition\",          \"Monitor growth\",                               \"Modifiable\",\n",
    "  \"height_listing\",\"Nutrition\",       \"Monitor growth\",                               \"Modifiable\",\n",
    "  \"weight_txpl\",\"Nutrition\",         \"Monitor growth\",                               \"Modifiable\",\n",
    "  \"weight_listing\",\"Nutrition\",      \"Monitor growth\",                               \"Modifiable\",\n",
    "  \n",
    "  # Respiratory\n",
    "  \"txvent\",    \"Respiratory\",         \"Ventilation weaning plan\",                     \"Partially Modifiable\",\n",
    "  \"slvent\",    \"Respiratory\",         \"Ventilation support\",                          \"Partially Modifiable\",\n",
    "  \"ltxtrach\",  \"Respiratory\",         \"Tracheostomy care\",                            \"Partially Modifiable\",\n",
    "  \"hxtrach\",   \"Respiratory\",         \"Tracheostomy care\",                            \"Partially Modifiable\",\n",
    "  \n",
    "  # Cardiac support / hemodynamics\n",
    "  \"txvad\",     \"Cardiac\",             \"VAD support\",                                  \"Partially Modifiable\",\n",
    "  \"slvad\",     \"Cardiac\",             \"VAD support\",                                  \"Partially Modifiable\",\n",
    "  \"slnomcsd\",  \"Cardiac\",             \"Consider MCSD\",                                \"Partially Modifiable\",\n",
    "  \"txecmo\",    \"Cardiac\",             \"ECMO support\",                                 \"Partially Modifiable\",\n",
    "  \"slecmo\",    \"Cardiac\",             \"ECMO support\",                                 \"Partially Modifiable\",\n",
    "  \"hxcpr\",     \"Cardiac\",             \"CPR risk mitigation\",                          \"Partially Modifiable\",\n",
    "  \"hxshock\",   \"Cardiac\",             \"Shock stabilization\",                          \"Partially Modifiable\",\n",
    "  \n",
    "  # Immunology\n",
    "  \"hlatxpre\",  \"Immunology\",          \"HLA desensitization\",                          \"Partially Modifiable\",\n",
    "  \"donspac\",   \"Immunology\",          \"Crossmatch-based donor selection\",             \"Partially Modifiable\",\n",
    "  \"txfcpra\",   \"Immunology\",          \"PRA monitoring\",                               \"Partially Modifiable\",\n",
    "  \"lsfcpra\",   \"Immunology\",          \"PRA monitoring\",                               \"Partially Modifiable\"\n",
    ")\n",
    "\n",
    "# Keep only modifiable / partially modifiable features (drop explicitly non-modifiable syndromes, anatomy, etc.)\n",
    "actionable_features <- actionable_features %>%\n",
    "  filter(Modifiability %in% c(\"Modifiable\", \"Partially Modifiable\"))\n",
    "\n",
    "modifiable_features <- unique(actionable_features$Feature)\n",
    "\n",
    "cat(\"Number of modifiable clinical features in candidate list:\", length(modifiable_features), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# 6.2 Define cohorts and prepare data\n",
    "\n",
    "library(here)\n",
    "library(survival)\n",
    "library(catboost)\n",
    "library(ranger)\n",
    "library(xgboost)\n",
    "library(aorsf)\n",
    "library(purrr)\n",
    "library(tidyr)\n",
    "library(DT)\n",
    "\n",
    "# Use phts_base already loaded earlier in the notebook\n",
    "# EFFICIENCY FIX: Filter to modifiable features BEFORE expensive data preparation\n",
    "# This avoids processing hundreds of columns we don't need\n",
    "\n",
    "# First, identify which columns we need: modifiable features + time/status + primary_etiology (for cohort filtering)\n",
    "required_cols <- c(\n",
    "  modifiable_features,  # Modifiable clinical features\n",
    "  \"primary_etiology\",   # Needed for cohort filtering\n",
    "  \"outcome_int_graft_loss\", \"outcome_graft_loss\",  # Needed to create time/status\n",
    "  \"int_graft_loss\", \"graft_loss\"  # Alternative names for time/status\n",
    ")\n",
    "\n",
    "# Find which required columns actually exist in phts_base\n",
    "available_cols <- intersect(required_cols, names(phts_base))\n",
    "\n",
    "# Filter phts_base to only the columns we need BEFORE data preparation\n",
    "phts_filtered <- phts_base %>%\n",
    "  select(all_of(available_cols))\n",
    "\n",
    "cat(sprintf(\"Filtered dataset: %d rows, %d columns (from %d original columns)\\n\",\n",
    "            nrow(phts_filtered), ncol(phts_filtered), ncol(phts_base)))\n",
    "\n",
    "# Now prepare data - this will only process the columns we actually need\n",
    "tx <- prepare_modeling_data(phts_filtered, mode = \"survival\")\n",
    "\n",
    "# Note: prepare_modeling_data already:\n",
    "# - Creates time and status columns from outcome_int_graft_loss and outcome_graft_loss\n",
    "# - Filters to 2010+ (already done in phts_base)\n",
    "# - Handles missing values and data cleaning (but now only on ~40 columns instead of ~381)\n",
    "\n",
    "# Define cohorts (CHD vs Myocarditis/Cardiomyopathy)\n",
    "cohorts <- list(\n",
    "  CHD       = tx %>% filter(primary_etiology == \"Congenital HD\"),\n",
    "  MyoCardio = tx %>% filter(primary_etiology %in% c(\"Cardiomyopathy\", \"Myocarditis\"))\n",
    ")\n",
    "\n",
    "cat(\"\\nCohort sizes (after 2010 filter):\\n\")\n",
    "for (nm in names(cohorts)) {\n",
    "  df <- cohorts[[nm]]\n",
    "  if (nrow(df) == 0) {\n",
    "    cat(sprintf(\"  %s: 0 patients\\n\", nm))\n",
    "  } else {\n",
    "    ev_rate <- mean(df$status == 1L, na.rm = TRUE)\n",
    "    cat(sprintf(\"  %s: %d patients, events = %d (%.2f%%)\\n\",\n",
    "                nm, nrow(df), sum(df$status == 1L, na.rm = TRUE), 100 * ev_rate))\n",
    "  }\n",
    "}\n",
    "\n",
    "cat(\"\\nâœ“ Cohorts defined and data prepared efficiently\\n\")\n",
    "cat(\"  Note: Data preparation only processed modifiable features (~40 cols) instead of all features (~381 cols)\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# 6.6 Monte Carlo Cross-Validation by Cohort and Model (modifiable features only)\n",
    "\n",
    "library(rsample)\n",
    "\n",
    "# Number of MC-CV splits and train proportion for cohort-level analysis\n",
    "cohort_mc_n_splits    <- if (exists(\"DEBUG_MODE\") && DEBUG_MODE) 5 else 50\n",
    "cohort_mc_train_prop  <- 0.8\n",
    "\n",
    "cat(sprintf(\"\\nCohort MC-CV configuration: %d splits, %.0f/%.0f train/test split\\n\",\n",
    "            cohort_mc_n_splits, cohort_mc_train_prop * 100, (1 - cohort_mc_train_prop) * 100))\n",
    "\n",
    "cohort_mc_metrics_rows    <- list()\n",
    "cohort_mc_importance_rows <- list()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Cohort-Specific Survival Models (Single Split)\n",
    "\n",
    "Build cohort-specific survival models using modifiable clinical features with a single 80/20 train/test split per cohort.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# 6.2 Cohort-specific survival models using modifiable features\n",
    "\n",
    "# Helper to safely run a model and capture errors\n",
    "safe_run <- function(expr, label) {\n",
    "  tryCatch(expr, error = function(e) {\n",
    "    cat(sprintf(\"  WARNING in %s: %s\\n\", label, conditionMessage(e)))\n",
    "    NULL\n",
    "  })\n",
    "}\n",
    "\n",
    "all_cohort_metrics <- list()\n",
    "all_best_importance <- list()\n",
    "\n",
    "# Check if cohort single-split results already exist (idempotency)\n",
    "output_dir_base <- here(\"cohort_analysis\", \"outputs\", \"survival\")\n",
    "summary_dir <- file.path(output_dir_base, \"summary\")\n",
    "cohort_single_split_file <- file.path(summary_dir, \"cohort_model_cindex_modifiable_clinical.csv\")\n",
    "\n",
    "if (SKIP_EXISTING_OUTPUTS && file.exists(cohort_single_split_file)) {\n",
    "  cat(\"\\nâ­ Skipping Section 6.3 (Single Split) - results already exist:\\n\")\n",
    "  cat(\"  \", cohort_single_split_file, \"\\n\")\n",
    "  cat(\"  Set SKIP_EXISTING_OUTPUTS = FALSE to rerun\\n\\n\")\n",
    "  \n",
    "  # Load existing results for display\n",
    "  if (file.exists(cohort_single_split_file)) {\n",
    "    cohort_metrics_tbl <- readr::read_csv(cohort_single_split_file, show_col_types = FALSE)\n",
    "    cohort_best_features_tbl <- NULL\n",
    "    best_features_file <- file.path(summary_dir, \"best_clinical_features_by_cohort.csv\")\n",
    "    if (file.exists(best_features_file)) {\n",
    "      cohort_best_features_tbl <- readr::read_csv(best_features_file, show_col_types = FALSE)\n",
    "    }\n",
    "    cat(\"âœ“ Loaded existing cohort single-split results\\n\")\n",
    "  }\n",
    "} else {\n",
    "  # Run cohort single-split analysis\n",
    "  for (cohort_name in names(cohorts)) {\n",
    "  cat(\"\\n========================================\\n\")\n",
    "  cat(sprintf(\"Cohort: %s\\n\", cohort_name))\n",
    "  cat(\"========================================\\n\")\n",
    "  \n",
    "  df <- cohorts[[cohort_name]]\n",
    "  \n",
    "  # Data already filtered to modifiable features in Section 6.2\n",
    "  # Just need to ensure time/status are valid and select relevant columns\n",
    "  # Note: primary_etiology may still be in df, but models will ignore it\n",
    "  feature_cols <- intersect(modifiable_features, names(df))\n",
    "  df_mod <- df %>%\n",
    "    select(time, status, all_of(feature_cols)) %>%\n",
    "    filter(is.finite(time), time > 0, !is.na(status))\n",
    "  \n",
    "  if (nrow(df_mod) < 50 || sum(df_mod$status == 1L, na.rm = TRUE) < 10) {\n",
    "    cat(sprintf(\"  Skipping %s: insufficient data after filtering (n=%d, events=%d)\\n\",\n",
    "                cohort_name, nrow(df_mod), sum(df_mod$status == 1L, na.rm = TRUE)))\n",
    "    next\n",
    "  }\n",
    "  \n",
    "  # Unified 80/20 train/test split\n",
    "  split <- create_unified_train_test_split(df_mod, cohort_name, seed = 1997)\n",
    "  train_data <- split$train_data\n",
    "  test_data  <- split$test_data\n",
    "  \n",
    "  # Container for model results\n",
    "  cohort_results <- list()\n",
    "  \n",
    "  # RSF (ranger)\n",
    "  cat(\"  Fitting RSF (ranger)...\\n\")\n",
    "  cohort_results$RSF <- safe_run(\n",
    "    run_rsf_ranger(\n",
    "      train_df   = train_data,\n",
    "      test_df    = test_data,\n",
    "      time_col   = \"time\",\n",
    "      status_col = \"status\",\n",
    "      cohort_name = cohort_name,\n",
    "      model_name  = \"RSF (ranger)\",\n",
    "      num.trees   = 500\n",
    "    ),\n",
    "    label = paste(cohort_name, \"RSF\")\n",
    "  )\n",
    "  \n",
    "  # AORSF\n",
    "  cat(\"  Fitting AORSF...\\n\")\n",
    "  cohort_results$AORSF <- safe_run(\n",
    "    run_aorsf(\n",
    "      train_df   = train_data,\n",
    "      test_df    = test_data,\n",
    "      time_col   = \"time\",\n",
    "      status_col = \"status\",\n",
    "      cohort_name = cohort_name,\n",
    "      model_name  = \"AORSF\",\n",
    "      n_tree      = 100\n",
    "    ),\n",
    "    label = paste(cohort_name, \"AORSF\")\n",
    "  )\n",
    "  \n",
    "  # CatBoost (Cox)\n",
    "  cat(\"  Fitting CatBoost (Cox)...\\n\")\n",
    "  cb_params <- list(\n",
    "    loss_function = \"Cox\",\n",
    "    eval_metric   = \"Cox\",\n",
    "    iterations    = 2000,\n",
    "    depth         = 4,\n",
    "    learning_rate = 0.1,\n",
    "    thread_count  = 1,\n",
    "    logging_level = \"Silent\",\n",
    "    verbose       = 0L\n",
    "  )\n",
    "  cohort_results$CatBoost <- safe_run(\n",
    "    run_catboost_cox(\n",
    "      train_df   = train_data,\n",
    "      test_df    = test_data,\n",
    "      time_col   = \"time\",\n",
    "      status_col = \"status\",\n",
    "      cohort_name = cohort_name,\n",
    "      model_name  = \"CatBoost\",\n",
    "      params      = cb_params\n",
    "    ),\n",
    "    label = paste(cohort_name, \"CatBoost\")\n",
    "  )\n",
    "  \n",
    "  # XGBoost-Cox (boosting)\n",
    "  cat(\"  Fitting XGBoost-Cox (boosting)...\\n\")\n",
    "  xgb_params <- list(\n",
    "    objective        = \"survival:cox\",\n",
    "    eval_metric      = \"cox-nloglik\",\n",
    "    eta              = 0.05,\n",
    "    max_depth        = 4,\n",
    "    subsample        = 0.8,\n",
    "    colsample_bytree = 0.8\n",
    "  )\n",
    "  cohort_results$XGBoost <- safe_run(\n",
    "    run_xgb_cox(\n",
    "      train_df   = train_data,\n",
    "      test_df    = test_data,\n",
    "      time_col   = \"time\",\n",
    "      status_col = \"status\",\n",
    "      cohort_name = cohort_name,\n",
    "      model_name  = \"XGBoost-Cox\",\n",
    "      params      = xgb_params,\n",
    "      nrounds     = 500,\n",
    "      early_stopping_rounds = 25\n",
    "    ),\n",
    "    label = paste(cohort_name, \"XGBoost-Cox\")\n",
    "  )\n",
    "  \n",
    "  # XGBoost-Cox in Random Forest mode (many parallel trees, 1 boosting step)\n",
    "  cat(\"  Fitting XGBoost-Cox (RF mode)...\\n\")\n",
    "  xgb_rf_params <- list(\n",
    "    objective        = \"survival:cox\",\n",
    "    eval_metric      = \"cox-nloglik\",\n",
    "    eta              = 1.0,\n",
    "    max_depth        = 6,\n",
    "    subsample        = 0.63,\n",
    "    colsample_bytree = 0.8,\n",
    "    num_parallel_tree = 500\n",
    "  )\n",
    "  cohort_results$XGBoost_RF <- safe_run(\n",
    "    run_xgb_cox(\n",
    "      train_df   = train_data,\n",
    "      test_df    = test_data,\n",
    "      time_col   = \"time\",\n",
    "      status_col = \"status\",\n",
    "      cohort_name = cohort_name,\n",
    "      model_name  = \"XGBoost RF\",\n",
    "      params      = xgb_rf_params,\n",
    "      nrounds     = 1,\n",
    "      early_stopping_rounds = 0\n",
    "    ),\n",
    "    label = paste(cohort_name, \"XGBoost RF\")\n",
    "  )\n",
    "  \n",
    "  # Collect C-index metrics for this cohort\n",
    "  metrics_df <- imap_dfr(cohort_results, function(res, model_name) {\n",
    "    if (is.null(res) || is.null(res$concordance)) return(NULL)\n",
    "    tibble(\n",
    "      Cohort  = cohort_name,\n",
    "      Model   = model_name,\n",
    "      C_Index = as.numeric(res$concordance$concordance)\n",
    "    )\n",
    "  })\n",
    "  \n",
    "  if (nrow(metrics_df) == 0) {\n",
    "    cat(sprintf(\"  No successful models for cohort %s\\n\", cohort_name))\n",
    "    next\n",
    "  }\n",
    "  \n",
    "  all_cohort_metrics[[cohort_name]] <- metrics_df\n",
    "  \n",
    "  # Identify best model by C-index\n",
    "  best_row <- metrics_df %>%\n",
    "    filter(!is.na(C_Index)) %>%\n",
    "    arrange(desc(C_Index)) %>%\n",
    "    slice(1)\n",
    "  \n",
    "  cat(\"  Best model for\", cohort_name, \":\", best_row$Model, \"(C-index =\",\n",
    "      round(best_row$C_Index, 4), \")\\n\")\n",
    "  \n",
    "  best_model_name <- best_row$Model[1]\n",
    "  best_res <- cohort_results[[best_model_name]]\n",
    "  imp_df <- best_res$importance\n",
    "  \n",
    "  if (!is.null(imp_df) && nrow(imp_df) > 0) {\n",
    "    # Map one-hot or transformed feature names back to base variable names\n",
    "    best_imp_annot <- imp_df %>%\n",
    "      mutate(\n",
    "        Cohort     = cohort_name,\n",
    "        Best_Model = best_model_name,\n",
    "        Rank       = dplyr::row_number(),\n",
    "        Base_Feature = gsub(\"(_.*)$\", \"\", feature)\n",
    "      ) %>%\n",
    "      left_join(actionable_features, by = c(\"Base_Feature\" = \"Feature\"))\n",
    "    \n",
    "    all_best_importance[[cohort_name]] <- best_imp_annot\n",
    "  } else {\n",
    "    cat(\"  WARNING: No feature importance available for best model in\", cohort_name, \"\\n\")\n",
    "  }\n",
    "}\n",
    "\n",
    "  # Aggregate metrics and best-feature tables\n",
    "  cohort_metrics_tbl <- bind_rows(all_cohort_metrics)\n",
    "  cohort_best_features_tbl <- bind_rows(all_best_importance)\n",
    "  \n",
    "  # Display summary tables\n",
    "  cohort_metrics_tbl\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Save Cohort Results (Single Split)\n",
    "\n",
    "Save cohort-specific model results and feature importance tables to both summary/ and cohort-specific folders.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# 6.3 Save Cohort Results (Single Split)\n",
    "\n",
    "# Base output directory\n",
    "output_dir_base <- here(\"cohort_analysis\", \"outputs\", \"survival\")\n",
    "dir.create(output_dir_base, recursive = TRUE, showWarnings = FALSE)\n",
    "\n",
    "# Summary directory for combined cohort comparisons\n",
    "summary_dir <- file.path(output_dir_base, \"summary\")\n",
    "dir.create(summary_dir, recursive = TRUE, showWarnings = FALSE)\n",
    "\n",
    "# Save combined files (for cross-cohort comparison)\n",
    "readr::write_csv(cohort_metrics_tbl,\n",
    "                 file.path(summary_dir, \"cohort_model_cindex_modifiable_clinical.csv\"))\n",
    "readr::write_csv(cohort_best_features_tbl,\n",
    "                 file.path(summary_dir, \"best_clinical_features_by_cohort.csv\"))\n",
    "\n",
    "# Save cohort-specific files\n",
    "for (cohort_name in unique(cohort_metrics_tbl$Cohort)) {\n",
    "  cohort_dir <- file.path(output_dir_base, cohort_name)\n",
    "  dir.create(cohort_dir, recursive = TRUE, showWarnings = FALSE)\n",
    "  \n",
    "  # Save cohort-specific metrics\n",
    "  cohort_metrics_subset <- cohort_metrics_tbl %>% filter(Cohort == cohort_name)\n",
    "  readr::write_csv(cohort_metrics_subset,\n",
    "                   file.path(cohort_dir, \"cohort_model_cindex_modifiable_clinical.csv\"))\n",
    "  \n",
    "  # Save cohort-specific features\n",
    "  cohort_features_subset <- cohort_best_features_tbl %>% filter(Cohort == cohort_name)\n",
    "  readr::write_csv(cohort_features_subset,\n",
    "                   file.path(cohort_dir, \"best_clinical_features_by_cohort.csv\"))\n",
    "}\n",
    "\n",
    "cat(\"\\nâœ“ Saved cohort model metrics and best-feature tables:\")\n",
    "cat(\"\\n  - Combined (summary):\", summary_dir)\n",
    "cat(\"\\n  - Cohort-specific:\", file.path(output_dir_base, \"CHD\"), \"and\", file.path(output_dir_base, \"MyoCardio\"), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Normalized Scaled Feature Importance Bar Chart\n",
    "\n",
    "Create a normalized scaled feature importance bar chart showing the top 25 modifiable clinical features. Importance is normalized within each cohort/model and scaled by model performance (MC-CV C-index)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Monte Carlo Cross-Validation by Cohort and Model (Modifiable Features Only)\n",
    "\n",
    "Run Monte Carlo Cross-Validation for cohort-specific survival models using modifiable clinical features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# 6.5 Normalized Scaled Feature Importance Bar Chart\n",
    "\n",
    "# Create normalized scaled feature importance bar chart for top clinical features\n",
    "# This chart shows feature importance normalized within each cohort/model and scaled by model performance (C-index)\n",
    "\n",
    "library(ggplot2)\n",
    "library(dplyr)\n",
    "\n",
    "# Check if required files exist\n",
    "output_dir_base <- here(\"cohort_analysis\", \"outputs\", \"survival\")\n",
    "summary_dir <- file.path(output_dir_base, \"summary\")\n",
    "\n",
    "best_feat_path <- file.path(summary_dir, \"best_clinical_features_by_cohort_mc_cv.csv\")\n",
    "metrics_path <- file.path(summary_dir, \"cohort_model_cindex_mc_cv_modifiable_clinical.csv\")\n",
    "\n",
    "if (file.exists(best_feat_path) && file.exists(metrics_path)) {\n",
    "  # Read data\n",
    "  best_features <- readr::read_csv(best_feat_path, show_col_types = FALSE)\n",
    "  cohort_metrics <- readr::read_csv(metrics_path, show_col_types = FALSE)\n",
    "  \n",
    "  # Prepare feature matrix: Cohort Ã— Model Ã— Feature\n",
    "  feature_matrix <- best_features %>%\n",
    "    dplyr::select(Cohort, Model, feature, importance) %>%\n",
    "    dplyr::mutate(\n",
    "      Cohort = as.character(Cohort),\n",
    "      Model  = as.character(Model),\n",
    "      importance = as.numeric(importance)\n",
    "    ) %>%\n",
    "    dplyr::mutate(importance = ifelse(is.na(importance), 0, importance)) %>%\n",
    "    dplyr::group_by(Cohort, Model) %>%\n",
    "    dplyr::mutate(\n",
    "      importance = ifelse(importance < 0, 0, importance),\n",
    "      total_imp = sum(importance),\n",
    "      importance_normalized = ifelse(total_imp > 0, importance / total_imp, 1 / dplyr::n())\n",
    "    ) %>%\n",
    "    dplyr::select(-total_imp) %>%\n",
    "    dplyr::ungroup()\n",
    "  \n",
    "  # Relative weights per cohort/model using C-index\n",
    "  algorithm_ranking <- cohort_metrics %>%\n",
    "    dplyr::select(Cohort, Model, C_Index_Mean) %>%\n",
    "    dplyr::group_by(Cohort) %>%\n",
    "    dplyr::mutate(\n",
    "      best_cindex = max(C_Index_Mean, na.rm = TRUE),\n",
    "      n_models = sum(!is.na(C_Index_Mean))\n",
    "    ) %>%\n",
    "    dplyr::ungroup() %>%\n",
    "    dplyr::mutate(\n",
    "      rel_weight = ifelse(best_cindex > 0,\n",
    "                          (C_Index_Mean / best_cindex) * n_models,\n",
    "                          1)\n",
    "    ) %>%\n",
    "    dplyr::select(Cohort, Model, rel_weight)\n",
    "  \n",
    "  feature_matrix <- feature_matrix %>%\n",
    "    dplyr::left_join(algorithm_ranking, by = c(\"Cohort\", \"Model\")) %>%\n",
    "    dplyr::mutate(\n",
    "      rel_weight = ifelse(is.na(rel_weight), 1, rel_weight),\n",
    "      importance_scaled = importance_normalized * rel_weight\n",
    "    )\n",
    "  \n",
    "  # Create scaled feature importance bar chart (Top 25 features)\n",
    "  scaled_feature_importance <- feature_matrix %>%\n",
    "    dplyr::group_by(feature) %>%\n",
    "    dplyr::summarise(\n",
    "      total_scaled_importance = sum(importance_scaled, na.rm = TRUE),\n",
    "      .groups = \"drop\"\n",
    "    ) %>%\n",
    "    dplyr::arrange(desc(total_scaled_importance)) %>%\n",
    "    dplyr::slice_head(n = 25)\n",
    "  \n",
    "  scaled_feature_importance <- scaled_feature_importance %>%\n",
    "    dplyr::mutate(feature = factor(feature, levels = rev(scaled_feature_importance$feature)))\n",
    "  \n",
    "  p <- ggplot(scaled_feature_importance, aes(x = feature, y = total_scaled_importance)) +\n",
    "    geom_bar(stat = \"identity\", fill = \"steelblue\", alpha = 0.8) +\n",
    "    coord_flip() +\n",
    "    labs(\n",
    "      title = \"Normalized Scaled Feature Importance (Top 25 Features)\",\n",
    "      subtitle = \"Importance normalized within cohort/model and scaled by model performance (MC-CV C-index)\",\n",
    "      x = \"Feature\",\n",
    "      y = \"Scaled Normalized Importance\"\n",
    "    ) +\n",
    "    theme_minimal() +\n",
    "    theme(\n",
    "      plot.title = element_text(size = 14, face = \"bold\"),\n",
    "      plot.subtitle = element_text(size = 11),\n",
    "      axis.text.y = element_text(size = 9)\n",
    "    )\n",
    "  \n",
    "  # Display the plot\n",
    "  print(p)\n",
    "  \n",
    "  # Also save to summary/plots directory\n",
    "  plot_dir_summary <- file.path(summary_dir, \"plots\")\n",
    "  dir.create(plot_dir_summary, showWarnings = FALSE, recursive = TRUE)\n",
    "  \n",
    "  ggplot2::ggsave(file.path(plot_dir_summary, \"scaled_feature_importance_bar_chart.png\"), p,\n",
    "                  width = 12, height = 10, dpi = 300)\n",
    "  cat(\"\\nâœ“ Saved normalized scaled feature importance bar chart to:\", \n",
    "      file.path(plot_dir_summary, \"scaled_feature_importance_bar_chart.png\"), \"\\n\")\n",
    "  \n",
    "} else {\n",
    "  cat(\"Required files not found. Please run Sections 6.3-6.4 first to generate:\\n\")\n",
    "  cat(\"  -\", best_feat_path, \"\\n\")\n",
    "  cat(\"  -\", metrics_path, \"\\n\")\n",
    "  if (!file.exists(best_feat_path)) {\n",
    "    cat(\"\\nNote: Feature importance extraction may need to be added to the MC-CV code.\\n\")\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# 6.6 Monte Carlo Cross-Validation by Cohort and Model (modifiable features only)\n",
    "\n",
    "library(rsample)\n",
    "\n",
    "# Number of MC-CV splits and train proportion for cohort-level analysis\n",
    "cohort_mc_n_splits    <- if (exists(\"DEBUG_MODE\") && DEBUG_MODE) 5 else 50\n",
    "cohort_mc_train_prop  <- 0.8\n",
    "\n",
    "cat(sprintf(\"\\nCohort MC-CV configuration: %d splits, %.0f/%.0f train/test split\\n\",\n",
    "            cohort_mc_n_splits, cohort_mc_train_prop * 100, (1 - cohort_mc_train_prop) * 100))\n",
    "\n",
    "cohort_mc_metrics_rows    <- list()\n",
    "cohort_mc_importance_rows <- list()\n",
    "\n",
    "# Helper to fit one model on one train/test split\n",
    "fit_cohort_model_once <- function(method, train_data, test_data, cohort_name) {\n",
    "  if (method == \"RSF\") {\n",
    "    run_rsf_ranger(\n",
    "      train_df   = train_data,\n",
    "      test_df    = test_data,\n",
    "      time_col   = \"time\",\n",
    "      status_col = \"status\",\n",
    "      cohort_name = cohort_name,\n",
    "      model_name  = \"RSF (ranger)\",\n",
    "      num.trees   = 500\n",
    "    )\n",
    "  } else if (method == \"AORSF\") {\n",
    "    run_aorsf(\n",
    "      train_df   = train_data,\n",
    "      test_df    = test_data,\n",
    "      time_col   = \"time\",\n",
    "      status_col = \"status\",\n",
    "      cohort_name = cohort_name,\n",
    "      model_name  = \"AORSF\",\n",
    "      n_tree      = 100\n",
    "    )\n",
    "  } else if (method == \"CatBoost\") {\n",
    "    cb_params <- list(\n",
    "      loss_function = \"Cox\",\n",
    "      eval_metric   = \"Cox\",\n",
    "      iterations    = 1200,\n",
    "      depth         = 4,\n",
    "      learning_rate = 0.1,\n",
    "      thread_count  = 1,\n",
    "      logging_level = \"Silent\",\n",
    "      verbose       = 0L\n",
    "    )\n",
    "    run_catboost_cox(\n",
    "      train_df   = train_data,\n",
    "      test_df    = test_data,\n",
    "      time_col   = \"time\",\n",
    "      status_col = \"status\",\n",
    "      cohort_name = cohort_name,\n",
    "      model_name  = \"CatBoost\",\n",
    "      params      = cb_params\n",
    "    )\n",
    "  } else if (method == \"XGBoost\") {\n",
    "    xgb_params <- list(\n",
    "      objective        = \"survival:cox\",\n",
    "      eval_metric      = \"cox-nloglik\",\n",
    "      eta              = 0.05,\n",
    "      max_depth        = 4,\n",
    "      subsample        = 0.8,\n",
    "      colsample_bytree = 0.8\n",
    "    )\n",
    "    run_xgb_cox(\n",
    "      train_df   = train_data,\n",
    "      test_df    = test_data,\n",
    "      time_col   = \"time\",\n",
    "      status_col = \"status\",\n",
    "      cohort_name = cohort_name,\n",
    "      model_name  = \"XGBoost-Cox\",\n",
    "      params      = xgb_params,\n",
    "      nrounds     = 400,\n",
    "      early_stopping_rounds = 25\n",
    "    )\n",
    "  } else if (method == \"XGBoost_RF\") {\n",
    "    xgb_rf_params <- list(\n",
    "      objective         = \"survival:cox\",\n",
    "      eval_metric       = \"cox-nloglik\",\n",
    "      eta               = 1.0,\n",
    "      max_depth         = 6,\n",
    "      subsample         = 0.63,\n",
    "      colsample_bytree  = 0.8,\n",
    "      num_parallel_tree = 500\n",
    "    )\n",
    "    run_xgb_cox(\n",
    "      train_df   = train_data,\n",
    "      test_df    = test_data,\n",
    "      time_col   = \"time\",\n",
    "      status_col = \"status\",\n",
    "      cohort_name = cohort_name,\n",
    "      model_name  = \"XGBoost RF\",\n",
    "      params      = xgb_rf_params,\n",
    "      nrounds     = 1,\n",
    "      early_stopping_rounds = 0\n",
    "    )\n",
    "  } else {\n",
    "    stop(\"Unknown method: \", method)\n",
    "  }\n",
    "}\n",
    "\n",
    "methods_for_mc <- c(\"RSF\", \"AORSF\", \"CatBoost\", \"XGBoost\", \"XGBoost_RF\")\n",
    "\n",
    "# Check if cohort MC-CV results already exist (idempotency)\n",
    "cohort_mc_cv_file <- file.path(summary_dir, \"cohort_model_cindex_mc_cv_modifiable_clinical.csv\")\n",
    "\n",
    "if (SKIP_EXISTING_OUTPUTS && file.exists(cohort_mc_cv_file)) {\n",
    "  cat(\"\\nâ­ Skipping Section 6.6 (MC-CV) - results already exist:\\n\")\n",
    "  cat(\"  \", cohort_mc_cv_file, \"\\n\")\n",
    "  cat(\"  Set SKIP_EXISTING_OUTPUTS = FALSE to rerun\\n\\n\")\n",
    "  \n",
    "  # Load existing results for display\n",
    "  if (file.exists(cohort_mc_cv_file)) {\n",
    "    cohort_mc_metrics_tbl <- readr::read_csv(cohort_mc_cv_file, show_col_types = FALSE)\n",
    "    cohort_best_features_tbl <- NULL\n",
    "    best_features_mc_file <- file.path(summary_dir, \"best_clinical_features_by_cohort_mc_cv.csv\")\n",
    "    if (file.exists(best_features_mc_file)) {\n",
    "      cohort_best_features_tbl <- readr::read_csv(best_features_mc_file, show_col_types = FALSE)\n",
    "    }\n",
    "    cat(\"âœ“ Loaded existing cohort MC-CV results\\n\")\n",
    "  }\n",
    "} else {\n",
    "  # Run cohort MC-CV analysis\n",
    "  for (cohort_name in names(cohorts)) {\n",
    "  cat(\"\\n----------------------------------------\\n\")\n",
    "  cat(sprintf(\"MC-CV for cohort: %s\\n\", cohort_name))\n",
    "  cat(\"----------------------------------------\\n\")\n",
    "  \n",
    "  df <- cohorts[[cohort_name]]\n",
    "  \n",
    "  # Data already filtered to modifiable features in Section 6.2\n",
    "  # Just need to ensure time/status are valid and select relevant columns\n",
    "  feature_cols <- intersect(modifiable_features, names(df))\n",
    "  df_mod <- df %>%\n",
    "    dplyr::select(time, status, dplyr::all_of(feature_cols)) %>%\n",
    "    dplyr::filter(is.finite(time), time > 0, !is.na(status))\n",
    "  \n",
    "  n_events <- sum(df_mod$status == 1L, na.rm = TRUE)\n",
    "  if (nrow(df_mod) < 50 || n_events < 10) {\n",
    "    cat(sprintf(\"  Skipping MC-CV: insufficient data after filtering (n=%d, events=%d)\\n\",\n",
    "                nrow(df_mod), n_events))\n",
    "    next\n",
    "  }\n",
    "  \n",
    "  cat(sprintf(\"  Using %d patients, %d events for MC-CV\\n\", nrow(df_mod), n_events))\n",
    "  \n",
    "  # Create MC-CV splits within this cohort (stratified by status)\n",
    "  mc_splits <- rsample::mc_cv(\n",
    "    data   = df_mod,\n",
    "    prop   = cohort_mc_train_prop,\n",
    "    times  = cohort_mc_n_splits,\n",
    "    strata = status\n",
    "  )\n",
    "  \n",
    "  for (method in methods_for_mc) {\n",
    "    cat(sprintf(\"  Method: %s\\n\", method))\n",
    "    c_vals   <- numeric(0)\n",
    "    imp_list <- list()\n",
    "    \n",
    "    for (i in seq_len(length(mc_splits$splits))) {\n",
    "      split <- mc_splits$splits[[i]]\n",
    "      train_data <- rsample::analysis(split)\n",
    "      test_data  <- rsample::assessment(split)\n",
    "      \n",
    "      res <- tryCatch({\n",
    "        fit_cohort_model_once(method, train_data, test_data, cohort_name)\n",
    "      }, error = function(e) {\n",
    "        cat(sprintf(\"    [Split %d] WARNING: %s\\n\", i, conditionMessage(e)))\n",
    "        NULL\n",
    "      })\n",
    "      \n",
    "      if (is.null(res) || is.null(res$concordance)) next\n",
    "      \n",
    "      c_vals <- c(c_vals, as.numeric(res$concordance$concordance))\n",
    "      \n",
    "      # Handle different importance slots across wrappers\n",
    "      imp_df <- NULL\n",
    "      if (!is.null(res$importance)) {\n",
    "        imp_df <- res$importance\n",
    "      } else if (!is.null(res$vi)) {\n",
    "        imp_df <- res$vi\n",
    "      }\n",
    "      if (!is.null(imp_df) && nrow(imp_df) > 0) {\n",
    "        imp_list[[length(imp_list) + 1]] <- imp_df %>%\n",
    "          dplyr::select(feature, importance)\n",
    "      }\n",
    "    }\n",
    "    \n",
    "    if (length(c_vals) == 0) {\n",
    "      cat(sprintf(\"    No successful MC-CV fits for %s in cohort %s\\n\", method, cohort_name))\n",
    "      next\n",
    "    }\n",
    "    \n",
    "    # Summary C-index statistics\n",
    "    ci_lower <- if (length(c_vals) > 1) stats::quantile(c_vals, 0.025, na.rm = TRUE) else NA_real_\n",
    "    ci_upper <- if (length(c_vals) > 1) stats::quantile(c_vals, 0.975, na.rm = TRUE) else NA_real_\n",
    "    \n",
    "    cohort_mc_metrics_rows[[length(cohort_mc_metrics_rows) + 1]] <- tibble::tibble(\n",
    "      Cohort           = cohort_name,\n",
    "      Model            = method,\n",
    "      C_Index_Mean     = mean(c_vals, na.rm = TRUE),\n",
    "      C_Index_SD       = stats::sd(c_vals, na.rm = TRUE),\n",
    "      C_Index_CI_Lower = ci_lower,\n",
    "      C_Index_CI_Upper = ci_upper,\n",
    "      n_splits         = length(c_vals)\n",
    "    )\n",
    "    \n",
    "    # Aggregate feature importance across splits (if available)\n",
    "    if (length(imp_list) > 0) {\n",
    "      imp_all <- dplyr::bind_rows(imp_list, .id = \"split\")\n",
    "      imp_agg <- imp_all %>%\n",
    "        dplyr::group_by(feature) %>%\n",
    "        dplyr::summarise(\n",
    "          importance = mean(importance, na.rm = TRUE),\n",
    "          .groups = \"drop\"\n",
    "        ) %>%\n",
    "        dplyr::arrange(dplyr::desc(importance)) %>%\n",
    "        dplyr::mutate(\n",
    "          Cohort = cohort_name,\n",
    "          Model  = method\n",
    "        )\n",
    "      cohort_mc_importance_rows[[length(cohort_mc_importance_rows) + 1]] <- imp_agg\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "# Combine all MC-CV metrics and importance tables\n",
    "cohort_mc_metrics_tbl <- dplyr::bind_rows(cohort_mc_metrics_rows)\n",
    "cohort_mc_importance_tbl <- dplyr::bind_rows(cohort_mc_importance_rows)\n",
    "\n",
    "# Derive best model per cohort by mean C-index\n",
    "cohort_best_summary <- cohort_mc_metrics_tbl %>%\n",
    "  dplyr::filter(!is.na(C_Index_Mean)) %>%\n",
    "  dplyr::group_by(Cohort) %>%\n",
    "  dplyr::arrange(dplyr::desc(C_Index_Mean), .by_group = TRUE) %>%\n",
    "  dplyr::slice(1) %>%\n",
    "  dplyr::ungroup()\n",
    "\n",
    "# Join best model summary to aggregated importance and annotate with clinical mapping\n",
    "cohort_best_features_tbl <- cohort_best_summary %>%\n",
    "  dplyr::inner_join(cohort_mc_importance_tbl, by = c(\"Cohort\", \"Model\")) %>%\n",
    "  dplyr::group_by(Cohort, Model) %>%\n",
    "  dplyr::arrange(dplyr::desc(importance), .by_group = TRUE) %>%\n",
    "  dplyr::mutate(\n",
    "    Rank        = dplyr::row_number(),\n",
    "    Base_Feature = gsub(\"(_.*)$\", \"\", feature)\n",
    "  ) %>%\n",
    "  dplyr::ungroup() %>%\n",
    "  dplyr::left_join(actionable_features, by = c(\"Base_Feature\" = \"Feature\")) %>%\n",
    "  dplyr::mutate(Best_Model = Model)\n",
    "\n",
    "  # Display MC-CV C-index summary\n",
    "  cohort_mc_metrics_tbl\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6 Save Cohort MC-CV Results\n",
    "\n",
    "Save cohort-specific MC-CV results and feature importance tables to both summary/ and cohort-specific folders.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# 6.6 Save Cohort MC-CV Results\n",
    "\n",
    "# Base output directory (should already exist from Section 6.4)\n",
    "output_dir_base <- here(\"cohort_analysis\", \"outputs\", \"survival\")\n",
    "dir.create(output_dir_base, recursive = TRUE, showWarnings = FALSE)\n",
    "\n",
    "# Summary directory for combined cohort comparisons\n",
    "summary_dir <- file.path(output_dir_base, \"summary\")\n",
    "dir.create(summary_dir, recursive = TRUE, showWarnings = FALSE)\n",
    "\n",
    "# Save combined MC-CV files (for cross-cohort comparison)\n",
    "readr::write_csv(cohort_mc_metrics_tbl,\n",
    "                 file.path(summary_dir, \"cohort_model_cindex_mc_cv_modifiable_clinical.csv\"))\n",
    "readr::write_csv(cohort_best_features_tbl,\n",
    "                 file.path(summary_dir, \"best_clinical_features_by_cohort_mc_cv.csv\"))\n",
    "\n",
    "# Save cohort-specific MC-CV files\n",
    "for (cohort_name in unique(cohort_mc_metrics_tbl$Cohort)) {\n",
    "  cohort_dir <- file.path(output_dir_base, cohort_name)\n",
    "  dir.create(cohort_dir, recursive = TRUE, showWarnings = FALSE)\n",
    "  \n",
    "  # Save cohort-specific MC-CV metrics\n",
    "  cohort_mc_metrics_subset <- cohort_mc_metrics_tbl %>% filter(Cohort == cohort_name)\n",
    "  readr::write_csv(cohort_mc_metrics_subset,\n",
    "                   file.path(cohort_dir, \"cohort_model_cindex_mc_cv_modifiable_clinical.csv\"))\n",
    "  \n",
    "  # Save cohort-specific MC-CV features\n",
    "  cohort_mc_features_subset <- cohort_best_features_tbl %>% filter(Cohort == cohort_name)\n",
    "  readr::write_csv(cohort_mc_features_subset,\n",
    "                   file.path(cohort_dir, \"best_clinical_features_by_cohort_mc_cv.csv\"))\n",
    "}\n",
    "\n",
    "cat(\"\\nâœ“ Saved cohort MC-CV metrics and best-feature tables:\")\n",
    "cat(\"\\n  - Combined (summary):\", summary_dir)\n",
    "cat(\"\\n  - Cohort-specific:\", file.path(output_dir_base, \"CHD\"), \"and\", file.path(output_dir_base, \"MyoCardio\"), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Create C-index comparison table\n",
    "cindex_comparison <- map_df(period_names, function(period) {\n",
    "  map_df(method_names, function(method) {\n",
    "    result <- all_results[[period]][[method]]\n",
    "    tibble(\n",
    "      period = period,\n",
    "      method = method,\n",
    "      cindex_td_mean = result$cindex_td_mean,\n",
    "      cindex_td_sd = result$cindex_td_sd,\n",
    "      cindex_td_ci_lower = result$cindex_td_ci_lower,\n",
    "      cindex_td_ci_upper = result$cindex_td_ci_upper,\n",
    "      cindex_ti_mean = result$cindex_ti_mean,\n",
    "      cindex_ti_sd = result$cindex_ti_sd,\n",
    "      cindex_ti_ci_lower = result$cindex_ti_ci_lower,\n",
    "      cindex_ti_ci_upper = result$cindex_ti_ci_upper,\n",
    "      n_splits = result$n_successful\n",
    "    )\n",
    "  })\n",
    "})\n",
    "\n",
    "write_csv(cindex_comparison, file.path(output_dir, \"cindex_comparison_mc_cv.csv\"))\n",
    "cat(\"âœ“ Saved: cindex_comparison_mc_cv.csv\\n\")\n",
    "\n",
    "# Display the table\n",
    "print(cindex_comparison)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Create summary statistics\n",
    "summary_stats <- map_df(period_names, function(period) {\n",
    "  period_data <- periods[[period]]\n",
    "  tibble(\n",
    "    period = period,\n",
    "    n_patients = nrow(period_data),\n",
    "    n_events = sum(period_data$outcome_graft_loss, na.rm = TRUE),\n",
    "    event_rate = 100 * sum(period_data$outcome_graft_loss, na.rm = TRUE) / nrow(period_data)\n",
    "  )\n",
    "})\n",
    "\n",
    "write_csv(summary_stats, file.path(output_dir, \"summary_statistics_mc_cv.csv\"))\n",
    "cat(\"âœ“ Saved: summary_statistics_mc_cv.csv\\n\")\n",
    "\n",
    "# Display the table\n",
    "print(summary_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Close parallel processing\n",
    "plan(sequential)\n",
    "\n",
    "cat(\"\\n========================================\\n\")\n",
    "cat(\"Analysis Complete!\\n\")\n",
    "cat(\"========================================\\n\")\n",
    "cat(sprintf(\"Output directory: %s\\n\", output_dir))\n",
    "cat(sprintf(\"MC-CV splits: %d\\n\", n_mc_splits))\n",
    "cat(sprintf(\"Train/Test ratio: %.0f/%.0f\\n\", train_prop * 100, (1 - train_prop) * 100))\n",
    "cat(\"\\nResults show C-indexes with 95% confidence intervals\\n\")\n",
    "cat(\"based on\", n_mc_splits, \"independent train/test splits.\\n\\n\")\n",
    "cat(\"âœ“ All files saved successfully!\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.7 Visualize Cohort Comparison Results\n",
    "\n",
    "Create visualization plots for cohort modifiable features analysis comparing cohorts using the summary folder files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Create visualization plots for feature importance and C-index analysis\n",
    "# Uses the updated create_visualizations.R script with improved normalization procedure\n",
    "# Creates: Feature importance heatmap, C-index heatmap, scaled bar chart, and C-index table\n",
    "\n",
    "library(here)\n",
    "\n",
    "# Source the visualization script from scripts/R/\n",
    "# Scripts are consolidated in scripts/R/ to match EC2 structure\n",
    "if (!file.exists(here(\"scripts\", \"R\", \"create_visualizations_cohort.R\"))) {\n",
    "  stop(\"Cannot find scripts/R/create_visualizations_cohort.R. Ensure scripts are in scripts/R/ directory.\")\n",
    "}\n",
    "source(here(\"scripts\", \"R\", \"create_visualizations_cohort.R\"))\n",
    "\n",
    "# Run visualizations\n",
    "# Pass the output directory to ensure visualizations are saved to the correct location\n",
    "run_visualizations(output_dir = output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# 6.8 Visualize Cohort Comparison Results\n",
    "\n",
    "# Create visualization plots for cohort modifiable features analysis\n",
    "# This creates visualizations comparing cohorts using the summary folder files\n",
    "# Visualizations are saved to summary/plots/ for cross-cohort comparisons\n",
    "\n",
    "library(here)\n",
    "\n",
    "# Source the visualization script\n",
    "if (!file.exists(here(\"scripts\", \"R\", \"create_visualizations_cohort.R\"))) {\n",
    "  stop(\"Cannot find scripts/R/create_visualizations_cohort.R. Ensure scripts are in scripts/R/ directory.\")\n",
    "}\n",
    "source(here(\"scripts\", \"R\", \"create_visualizations_cohort.R\"))\n",
    "\n",
    "# Run visualizations using the base output directory (script will look for summary/ folder)\n",
    "# This creates:\n",
    "# - Feature importance heatmap (cohort comparison)\n",
    "# - C-index heatmap (cohort comparison)\n",
    "# - Scaled feature importance bar chart\n",
    "# - C-index table\n",
    "# - Cohort clinical feature Sankey diagram\n",
    "# - Scaled normalized feature importance Sankey diagram\n",
    "run_visualizations(output_dir = output_dir_base)\n",
    "\n",
    "cat(\"\\nâœ“ Cohort comparison visualizations saved to:\", file.path(output_dir_base, \"summary\", \"plots\"), \"\\n\")\n",
    "cat(\"  - Feature importance heatmap\\n\")\n",
    "cat(\"  - C-index heatmap\\n\")\n",
    "cat(\"  - Scaled feature importance bar chart\\n\")\n",
    "cat(\"  - C-index table\\n\")\n",
    "cat(\"  - Cohort clinical feature Sankey diagram\\n\")\n",
    "cat(\"  - Scaled normalized feature importance Sankey diagram\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Sync Results and Code to S3\n",
    "\n",
    "Sync output files and code (notebook + R script) to S3 bucket after all analyses and visualizations are complete.\n",
    "- Outputs: CSV results files, plots, and visualizations\n",
    "- Code: Notebook and R script for reproducibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Sync outputs and code to S3\n",
    "# On EC2, we're in the cohort_analysis directory\n",
    "s3_bucket <- \"s3://uva-private-data-lake/graft-loss/cohort_analysis/survival/\"\n",
    "\n",
    "# Find AWS CLI (check common locations - EC2 typically has it in /usr/local/bin or /usr/bin)\n",
    "aws_cmd <- Sys.which(\"aws\")\n",
    "if (aws_cmd == \"\") {\n",
    "  # Try common EC2 installation paths\n",
    "  aws_paths <- c(\n",
    "    \"/usr/local/bin/aws\",\n",
    "    \"/usr/bin/aws\",\n",
    "    \"/home/ec2-user/.local/bin/aws\"\n",
    "  )\n",
    "  aws_cmd <- NULL\n",
    "  for (path in aws_paths) {\n",
    "    if (file.exists(path)) {\n",
    "      aws_cmd <- path\n",
    "      break\n",
    "    }\n",
    "  }\n",
    "  if (is.null(aws_cmd)) {\n",
    "    stop(\"AWS CLI not found. Please install AWS CLI or ensure it's in your PATH.\")\n",
    "  }\n",
    "}\n",
    "\n",
    "cat(\"Syncing outputs and code to S3...\\n\")\n",
    "cat(\"Source: cohort_analysis/ directory\\n\")\n",
    "cat(\"Destination:\", s3_bucket, \"\\n\")\n",
    "cat(\"AWS CLI:\", aws_cmd, \"\\n\\n\")\n",
    "\n",
    "# Get current directory (should be cohort_analysis)\n",
    "current_dir <- getwd()\n",
    "if (!grepl(\"cohort_analysis\", current_dir)) {\n",
    "  warning(\"Current directory doesn't appear to be cohort_analysis. Double-check sync destination.\")\n",
    "}\n",
    "\n",
    "# Sync survival outputs and code to S3\n",
    "# Sync the outputs/survival directory specifically to avoid overwriting classification outputs\n",
    "# Explicitly include notebook, R scripts, README files, and outputs/survival directory\n",
    "# Exclude temporary files, checkpoints, and unnecessary directories\n",
    "# Note: --delete flag removed for safety (won't delete files in S3 that don't exist locally)\n",
    "sync_cmd <- sprintf(\n",
    "  '\"%s\" s3 sync \"%s\" %s --include \"*.ipynb\" --include \"*.R\" --include \"README*.md\" --include \"outputs/survival/**\" --exclude \"*checkpoint*\" --exclude \"*.tmp\" --exclude \"*.ipynb_checkpoints/*\" --exclude \"*.RData\" --exclude \"*.Rhistory\" --exclude \".Rproj.user/*\" --exclude \"catboost_info/*\" --exclude \"*.log\" --exclude \"*\"',\n",
    "  aws_cmd,\n",
    "  current_dir,\n",
    "  s3_bucket\n",
    ")\n",
    "\n",
    "cat(\"Running:\", sync_cmd, \"\\n\\n\")\n",
    "result <- system(sync_cmd)\n",
    "\n",
    "if (result == 0) {\n",
    "  cat(\"âœ“ Successfully synced outputs and code to S3\\n\")\n",
    "  cat(\"  - Outputs:\", file.path(output_dir_base), \"\\n\")\n",
    "  cat(\"  - Code: *.ipynb, *.R, README*.md\\n\")\n",
    "} else {\n",
    "  warning(sprintf(\"S3 sync returned exit code %d. Check AWS credentials and permissions.\", result))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Shutdown EC2\n",
    "\n",
    "Shutdown EC2 instance after all analyses, visualizations, and S3 sync are complete.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Shutdown EC2 instance after analysis completes\n",
    "# Set SHUTDOWN_EC2 = TRUE to enable, FALSE to disable\n",
    "SHUTDOWN_EC2 <- TRUE  # Change to TRUE to enable auto-shutdown\n",
    "\n",
    "if (SHUTDOWN_EC2) {\n",
    "  cat(\"\\n========================================\\n\")\n",
    "  cat(\"Shutting down EC2 instance...\\n\")\n",
    "  cat(\"========================================\\n\")\n",
    "  \n",
    "  # Get instance ID from EC2 metadata service\n",
    "  instance_id <- tryCatch({\n",
    "    system(\"curl -s http://169.254.169.254/latest/meta-data/instance-id\", intern = TRUE)\n",
    "  }, error = function(e) {\n",
    "    cat(\"Warning: Could not retrieve instance ID from metadata service.\\n\")\n",
    "    cat(\"If running on EC2, check that metadata service is accessible.\\n\")\n",
    "    return(NULL)\n",
    "  })\n",
    "  \n",
    "  if (!is.null(instance_id) && length(instance_id) > 0 && nchar(instance_id[1]) > 0) {\n",
    "    instance_id <- instance_id[1]\n",
    "    cat(sprintf(\"Instance ID: %s\\n\", instance_id))\n",
    "    \n",
    "    # Find AWS CLI\n",
    "    aws_cmd <- Sys.which(\"aws\")\n",
    "    if (aws_cmd == \"\") {\n",
    "      aws_paths <- c(\n",
    "        \"/usr/local/bin/aws\",\n",
    "        \"/usr/bin/aws\",\n",
    "        \"/home/ec2-user/.local/bin/aws\"\n",
    "      )\n",
    "      aws_cmd <- NULL\n",
    "      for (path in aws_paths) {\n",
    "        if (file.exists(path)) {\n",
    "          aws_cmd <- path\n",
    "          break\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    \n",
    "    if (!is.null(aws_cmd) && aws_cmd != \"\") {\n",
    "      # Stop the instance (use terminate-instances for permanent deletion)\n",
    "      shutdown_cmd <- sprintf(\n",
    "        '\"%s\" ec2 stop-instances --instance-ids %s',\n",
    "        aws_cmd,\n",
    "        instance_id\n",
    "      )\n",
    "      \n",
    "      cat(\"Running:\", shutdown_cmd, \"\\n\")\n",
    "      result <- system(shutdown_cmd)\n",
    "      \n",
    "      if (result == 0) {\n",
    "        cat(\"âœ“ EC2 instance stop command sent successfully\\n\")\n",
    "        cat(\"Instance will stop in a few moments.\\n\")\n",
    "        cat(\"Note: This is a STOP (not terminate), so you can restart it later.\\n\")\n",
    "      } else {\n",
    "        warning(sprintf(\"EC2 stop command returned exit code %d. Check AWS credentials and permissions.\", result))\n",
    "      }\n",
    "    } else {\n",
    "      cat(\"Warning: AWS CLI not found. Cannot shutdown instance.\\n\")\n",
    "      cat(\"Install AWS CLI or ensure it's in your PATH.\\n\")\n",
    "    }\n",
    "  } else {\n",
    "    cat(\"Warning: Could not determine instance ID. Skipping shutdown.\\n\")\n",
    "    cat(\"If you want to shutdown manually, use:\\n\")\n",
    "    cat(\"  aws ec2 stop-instances --instance-ids <your-instance-id>\\n\")\n",
    "  }\n",
    "} else {\n",
    "  cat(\"\\n========================================\\n\")\n",
    "  cat(\"EC2 Auto-Shutdown: DISABLED\\n\")\n",
    "  cat(\"========================================\\n\")\n",
    "  cat(\"To enable auto-shutdown, set SHUTDOWN_EC2 = TRUE in this cell.\\n\")\n",
    "  cat(\"Instance will continue running.\\n\")\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
