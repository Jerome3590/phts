---
title: "Survival Analysis Models by Cohort"
author: "R. Jerome Dixon"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
format:
  html:
    toc: true
    toc-depth: 6
    code-fold: true
    code-summary: "Show the code"
    embed-resources: true
    default-image-extension: svg
    dpi: 600
editor:
  markdown:
    wrap: 72
---

## Overview

This analysis examines predictive models for pediatric heart transplant
outcomes by comparing two distinct patient cohorts: Congenital Heart
Disease (CHD) and Myocarditis/Cardiomyopathy. We implement three
complementary modeling approaches to provide comprehensive risk
assessment and identify cohort-specific predictive factors.

### Modeling Approaches

This study evaluates multiple survival methodologies per cohort. We run:

**1. LASSO (Cox)**

-   Cox proportional hazards with L1 penalty for feature selection.
-   Strengths: interpretability, sparse solutions; Limitations: PH and
    linear effects.

**2. CatBoost (Cox loss)**

-   Gradient boosting with Cox partial likelihood.
-   Strengths: categorical handling, non-linear interactions; Limitations:
    interpretability, tuning; inherits PH.

**3. AORSF**

-   Oblique random survival forests optimized for concordance.
-   Strengths: flexible, non-parametric; Limitations: less interpretable,
    compute heavier.

**4. RSF (ranger)**

-   Random Survival Forests with log-rank splitting; non-parametric,
    variable importance available.

**5. XGBoost-Cox**

-   Gradient-boosted trees trained with Cox partial likelihood.

**6. Deep Learning (pycox)**

-   DeepSurv (Cox) and DeepHit (discrete-time) trained externally with
    metrics merged into cohort tables.

### Cohort-Specific Analysis Rationale

The analysis compares CHD patients (congenital conditions) versus
Myocarditis/Cardiomyopathy patients (acquired conditions) because:

-   **Different Pathophysiology**: Congenital versus acquired heart
    disease may respond differently to transplantation.
-   **Age-Related Factors**: CHD patients are often transplanted at
    younger ages with different growth considerations.
-   **Surgical Complexity**: CHD cases may involve more complex anatomy
    requiring different risk stratification.
-   **Long-term Outcomes**: Different disease etiologies may have
    distinct long-term survival patterns.
-   **Clinical Decision Making**: Cohort-specific models may provide
    more accurate risk prediction for treatment planning.

Collectively, these models provide complementary perspectives across
cohorts. All use identical train/test splits and are compared on
concordance (C-index).

For causal questions and model auditing beyond prediction, see:

- `cohort_analysis/causal_analysis/README.md` for LMTP vs FFA overview
- `cohort_analysis/causal_analysis/causal_analysis.qmd` for runnable starters

### Censored Data Handling

Each modeling approach handles censored observations appropriately:

-   **LASSO**: Uses `Surv(time, status)` objects where status=0
    indicates censored observations, properly incorporated into the Cox
    regression partial likelihood.

-   **CatBoost**: The Cox loss function incorporates censored data by
    encoding the label with a negative sign, correctly accounting for
    patients who were alive at last follow-up.

-   **AORSF**: Ensemble survival forests handle censoring through
    modified splitting criteria that account for incomplete observations
    using proper survival analysis methodology.

-   **RSF (ranger)**: Tree growth uses log-rank splitting criteria that
    accommodate censoring.

-   **XGBoost-Cox**: Trains on Cox partial likelihood, naturally
    handling censored observations.

-   **DeepSurv / DeepHit**: DeepSurv optimizes Cox partial likelihood;
    DeepHit models discrete-time event probabilities, both incorporating
    censoring in their objectives.

All methods properly utilize both event times and censoring information,
ensuring that patients lost to follow-up or alive at study end
contribute appropriate information to model training.

```{r echo=FALSE, warning=FALSE, message=FALSE}

library(readr)
library(rlang)
library(dplyr)
library(glmnet)
library(caret)
library(tidyverse)
library(tibble)
library(DT)
library(aorsf)
library(survival)
library(catboost)
library(ranger)
library(xgboost)

set.seed(1997)

source("survival_helpers.R")

```

### Model Data

```{r echo=FALSE, warning=FALSE, message=FALSE, eval=TRUE}

# Load directly from SAS and standardize survival variables
tx <- load_phts_transplant_dataset()

model_data <- tx %>%
  mutate(
    outcome = as.integer(ev_type == 1),
    ev_time = suppressWarnings(as.numeric(ev_time))
  )

cat("Dataset dimensions:", paste(dim(model_data), collapse = " x "), "\n")
cat("Columns:", paste(names(model_data), collapse = ", "), "\n")

# Replace bad times for censored rows using helper
model_data <- fix_non_positive_times(model_data, time_col = "ev_time", status_col = "outcome")


```

```{r echo=FALSE, warning=FALSE, message=FALSE, eval=TRUE}

model_features <- model_data %>% 
  colnames() %>% 
  as_tibble()

# View 
datatable(
  model_features,
  rownames = FALSE,
  options = list(
    pageLength = 15,
    columnDefs = list(
      list(className = 'dt-left', targets = "_all")
    )
  )
)
```


### Methods: Cohort Pipeline Summary

-   **Data**: Load `preprocessed_model_data.csv` into `model_data`.

-   **Data Integration**: Incorporate post-transplant follow-up data
    from `posttxplfollowup.sas7bdat` to engineer survival analysis
    features. This includes calculating `days_to_last_followup` and
    joining with the main transplant dataset to create comprehensive
    survival outcomes.

-   **Cohorts**: Define `chd_data`
    (`primary_etiology == "Congenital HD"`) and `myo_cardio_data`
    (`primary_etiology %in% c("Cardiomyopathy", "Myocarditis")`).

-   **Feature filtering (survival models)**: Create `*_surv_model` by
    removing variables matching `survival_lagging_keywords` for all
    models. Exclude identifiers, `outcome`, and `transplant_year` from
    predictors.

-   **Unified train/test split**: Use
    `create_unified_train_test_split()` function with `set.seed(1997)`
    for reproducible 80/20 splits across all models.

-   **Reproducibility**: Set `set.seed(1997)` before each model fit.

-   **LASSO (survival)**: `cv.glmnet(..., family = "cox", alpha = 1)`
    using Cox proportional hazards with L1 penalty. Features exclude
    identifiers, `outcome`, `ev_time`, `ev_type`. Evaluation: C-index;
    report feature importance with actual feature names.

-   **CatBoost (survival)**: Gradient boosting with Cox loss
    (`loss_function = "Survival: Cox"`, fallback to `"Cox"`).
    Evaluation: C-index; report feature importance with normalized
    values from 0 to 1 for all models.

-   **AORSF (survival)**: `orsf(Surv(time, status) ~ .)` after deriving
    `time = ev_time`, `status = as.integer(ev_type == 1)`. Remove
    constant columns; exclude identifiers and `outcome` from predictors.
    Evaluation: C-index; report feature importance with normalized
    values from 0 to 1 for all models.

-   **Evaluation and reporting**: Predictions and metrics computed on
    the held-out test set. Tabular outputs rendered with
    `DT::datatable`.

-   **Comparison tables**: Aggregate metrics across cohorts and models
    into summary tables for side-by-side comparison.

**Unified Survival Modeling**: All three modeling frameworks (LASSO,
CatBoost, and AORSF) now use survival analysis approaches, for direct
comparison of C-index metrics and consistent evaluation of time-to-event
outcomes across different modeling frameworks.

```{r survival-lagging-keywords}

# Unified survival modeling keywords (variables to exclude from all models)

survival_lagging_keywords <- c(
  # Identifiers and outcomes
  #"ptid_e",
  "transplant_year", "primary_etiology",
  
  # Survival variables (handled separately)
  # "ev_time", "ev_type",
  
  # Donor-specific variables
  "graft_loss", "int_graft_loss", "dtx_", "cc_", "isc_oth",
  "dcardiac", "dcon", "dpri", "dpricaus", "rec_", "papooth",
  "dneuro", "sdprathr", "int_dead", "listing_year", "cpathneg",
  "dcauseod",
  
  # Demographics (if not clinically relevant)
  "race", "sex", "drace_b", "rrace_a", "hisp", "Iscntry",
  
  # Transplant-specific variables
  "dreject", "dsecaccsEmpty", "dmajbldEmpty", "pishltgr1R", 
  "drejectEmpty", "drejectHyperacute", "pishltgrEmpty",
  "pishltgr", "dmajbld", "dsecaccs", "dsecaccs_bin", 
  
  # Clinical variables to exclude
  "dx_cardiomyopathy", "deathspc", "dlist", "pmorexam", 
  "patsupp", "concod", "pcadrem", "pcadrec", "pathero", 
  "pdiffib", "dmalcanc", "alt_tx", "age_death", "pacuref",
  
  # Additional variables
  "lsvcma"
)


```

```{r unified-train-test-split}

# Unified train/test split function for all models
create_unified_train_test_split <- function(data, cohort_name, seed = 1997) {
  set.seed(seed)
  
  # Create reproducible random split
  n_total <- nrow(data)
  n_train <- floor(0.8 * n_total)
  
  # Create random indices
  all_indices <- 1:n_total
  train_indices <- sample(all_indices, size = n_train)
  test_indices <- setdiff(all_indices, train_indices)
  
  # Split the data
  train_data <- data[train_indices, ]
  test_data <- data[test_indices, ]
  
  # Store indices for other models to use
  split_info <- list(
    cohort = cohort_name,
    train_indices = train_indices,
    test_indices = test_indices,
    n_total = n_total,
    n_train = n_train,
    n_test = length(test_indices),
    seed = seed
  )
  
  cat("=== Unified Train/Test Split for", cohort_name, "===\n")
  cat("Total patients:", n_total, "\n")
  cat("Training set:", n_train, "patients\n")
  cat("Test set:", length(test_indices), "patients\n")
  cat("Split ratio:", round(n_train/n_total, 3), ":", round(length(test_indices)/n_total, 3), "\n")
  cat("Seed used:", seed, "\n")
  cat("=====================================\n\n")
  
  return(list(
    train_data = train_data,
    test_data = test_data,
    split_info = split_info
  ))
}
```

```{r catboost-clean-target}

clean_survival_data_for_catboost <- function(data, time_col = "ev_time", status_col = "outcome") {
  
  # Check for problematic values
  cat("=== Data Quality Check ===\n")
  cat("Total rows:", nrow(data), "\n")
  cat("NaN in time:", sum(is.nan(data[[time_col]])), "\n")
  cat("NaN in status:", sum(is.nan(data[[status_col]])), "\n")
  cat("Inf in time:", sum(is.infinite(data[[time_col]])), "\n")
  cat("Negative time:", sum(data[[time_col]] < 0, na.rm = TRUE), "\n")
  cat("Zero time:", sum(data[[time_col]] == 0, na.rm = TRUE), "\n")
  cat("Missing time:", sum(is.na(data[[time_col]])), "\n")
  cat("Missing status:", sum(is.na(data[[status_col]])), "\n")
  
  # Clean the data
  cleaned_data <- data %>%
    # Remove rows with NaN or infinite values
    filter(!is.nan(!!sym(time_col))) %>%
    filter(!is.infinite(!!sym(time_col))) %>%
    filter(!is.nan(!!sym(status_col))) %>%
    filter(!is.infinite(!!sym(status_col))) %>%
    # Remove rows with negative or zero time
    filter(!!sym(time_col) > 0) %>%
    # Remove rows with missing values
    filter(!is.na(!!sym(time_col))) %>%
    filter(!is.na(!!sym(status_col))) %>%
    # Ensure status is binary (0 or 1)
    filter(!!sym(status_col) %in% c(0, 1))
  
  cat("Cleaned rows:", nrow(cleaned_data), "\n")
  cat("Rows removed:", nrow(data) - nrow(cleaned_data), "\n")
  
  return(cleaned_data)
}

```

```{r lasso-utilities, warning=FALSE, message=FALSE}


nzv_cols <- function(df) {
  vapply(df, function(x) {
    ux <- unique(x)
    ux <- ux[!is.na(ux)]
    length(ux) < 2
  }, logical(1))
}


mode_level <- function(x) {
  ux <- na.omit(x)
  if (length(ux) == 0) return(NA)
  tab <- sort(table(ux), decreasing = TRUE)
  names(tab)[1]
}


impute_like <- function(df, like_df) {
  for (nm in names(df)) {
    if (is.numeric(df[[nm]])) {
      m <- median(like_df[[nm]], na.rm = TRUE)
      df[[nm]][is.na(df[[nm]])] <- m
    } else if (is.factor(df[[nm]])) {
      # ensure same levels; add "Other"
      base_lv <- levels(like_df[[nm]])
      if (!("Other" %in% base_lv)) base_lv <- c(base_lv, "Other")
      df[[nm]] <- factor(df[[nm]], levels = base_lv)
      # unseen -> NA -> "Other"
      df[[nm]][is.na(df[[nm]])] <- "Other"
    }
  }
  df
}


align_mm <- function(train_df, test_df) {
  Xtr <- model.matrix(~ . - 1, data = train_df)
  Xte <- model.matrix(~ . - 1, data = test_df)
  # pad/reorder test to train columns
  missing_in_test <- setdiff(colnames(Xtr), colnames(Xte))
  if (length(missing_in_test)) {
    Xte <- cbind(Xte, matrix(0, nrow(Xte), length(missing_in_test),
                             dimnames = list(NULL, missing_in_test)))
  }
  extra_in_test <- setdiff(colnames(Xte), colnames(Xtr))
  if (length(extra_in_test)) Xte <- Xte[, setdiff(colnames(Xte), extra_in_test), drop = FALSE]
  Xte <- Xte[, colnames(Xtr), drop = FALSE]
  list(Xtr = Xtr, Xte = Xte)
}

```

```{r metrics-helper-functions}

# Helper function to create comprehensive metrics for any model

create_survival_metrics <- function(cohort_name, model_name, concordance_obj) {
  
  # Check if the concordance object is valid
  if (is.null(concordance_obj) || !("concordance" %in% names(concordance_obj))) {
    warning(paste("Invalid concordance object for", model_name, cohort_name))
    return(NULL)
  }
  
  # Initialize the metrics list
  metrics <- list(
    Cohort = cohort_name,
    Model = model_name,
    C_Index = round(as.numeric(concordance_obj$concordance), 4)
    # AUC, Accuracy, F1, etc., are not calculated as they are for classification
  )
  
  return(metrics)
}


# Helper function to get top N features with normalized importance
get_top_features_normalized <- function(feature_df, cohort_name, model_name, n_features = 25) {
  if (nrow(feature_df) == 0) return(NULL)
  
  # Get top N features
  top_features <- feature_df %>%
    slice_head(n = n_features) %>%
    mutate(
      Cohort = cohort_name,
      Model = model_name,
      Rank = row_number()
    )
  
  # Normalize importance to 0-1 scale
  if ("importance" %in% colnames(top_features)) {
    top_features <- top_features %>%
      mutate(
        Normalized_Importance = (importance - min(importance)) / (max(importance) - min(importance))
      )
  } else if ("coefficient" %in% colnames(top_features)) {
    # For LASSO coefficients, use absolute values and normalize
    top_features <- top_features %>%
      mutate(
        importance = abs(coefficient),
        Normalized_Importance = (importance - min(importance)) / (max(importance) - min(importance))
      )
  }
  
  return(top_features)
}


# Helper function to create metrics summary table
create_metrics_summary <- function(metrics_list) {
  if (length(metrics_list) == 0) return(NULL)
  
  # Convert list of metrics to data frame
  metrics_df <- bind_rows(metrics_list)
  
  # Create summary by cohort and model
  summary_df <- metrics_df %>%
    group_by(Cohort, Model) %>%
    summarise(
      AUC = first(AUC),
      C_Index = first(C_Index),
      Accuracy = first(Accuracy),
      F1 = first(F1),
      Precision = first(Precision),
      Recall = first(Recall),
      Method = first(Method),
      .groups = 'drop'
    )
  
  return(list(
    full_metrics = metrics_df,
    summary = summary_df
  ))
}

```

### Cohort-Specific Modeling Pipeline

#### CHD Cohort Analysis

```{r echo=FALSE, warning=FALSE, message=FALSE, eval=TRUE}

chd_data <- model_data %>% filter(primary_etiology == "Congenital HD")

# CHD Cohort summary
cat("CHD Cohort Size:", nrow(chd_data), "patients\n")
cat("Event Distribution (outcome):\n")
print(table(chd_data$outcome))
cat("Event Rate:", round(mean(chd_data$outcome, na.rm = TRUE) * 100, 2), "%\n")

# CHD Cohort descriptive statistics
chd_summary <- chd_data %>%
  select(where(is.numeric)) %>%
  summarise(across(everything(), list(
    mean = ~ round(mean(.x, na.rm = TRUE), 2),
    median = ~ round(median(.x, na.rm = TRUE), 2),
    sd = ~ round(sd(.x, na.rm = TRUE), 2)
  ))) %>%
  pivot_longer(everything(), names_to = "stat", values_to = "value") %>%
  separate(stat, into = c("variable", "statistic"), sep = "_(?=[^_]*$)") %>%
  pivot_wider(names_from = statistic, values_from = value)

# Display CHD summary table
datatable(
  chd_summary,
  rownames = FALSE,
  options = list(
    pageLength = 10,
    columnDefs = list(
      list(className = 'dt-left', targets = "_all")
    )
  )
)

```

```{r}

# Apply cleaning cohort
chd_catboost_df <- clean_survival_data_for_catboost(chd_data)

# Create or load persistent split for CHD cohort
chd_split <- get_or_create_unified_split(chd_data, "CHD", seed = 1997)

# Extract split info
chd_train_indices <- chd_split$split_info$train_indices
chd_test_indices <- chd_split$split_info$test_indices
chd_train_data <- chd_split$train_data
chd_test_data <- chd_split$test_data

# Verify the cleaned data
cat("\n=== CHD Cohort Cleaned Data ===\n")
summary(chd_catboost_df$ev_time)
summary(chd_catboost_df$outcome)


# Check for any remaining issues
cat("\n=== Final Quality Check ===\n")
cat("CHD - Any NaN in time:", any(is.nan(chd_catboost_df$ev_time)), "\n")
cat("CHD - Any NaN in status:", any(is.nan(chd_catboost_df$outcome)), "\n")

```

##### LASSO Model

```{r chd-survival-lasso-model-fit}

chd_lasso_res <- run_lasso_cox(
  train_df = chd_train,
  test_df = chd_test,
  time_col = "time",
  status_col = "status",
  cohort_name = "CHD",
  model_name = "LASSO (Survival)"
)

chd_surv_risk_scores <- chd_lasso_res$risk_scores
chd_surv_c_index <- chd_lasso_res$concordance
chd_surv_lasso_model <- chd_lasso_res$model
chd_surv_lasso_cv <- chd_lasso_res$cv
chd_surv_optimal_lambda <- chd_lasso_res$lambda_min
chd_surv_nonzero_coefs <- chd_lasso_res$nonzero_coefs
chd_lasso_metrics <- create_survival_metrics("CHD","LASSO (Survival)", chd_surv_c_index)

```

```{r chd-lasso-model-prediction}

chd_surv_risk_scores <- predict(chd_surv_lasso_model,
                                newx = chd_x_test,
                                s = "lambda.min")

# Calculate C-Index on the TEST data
chd_surv_c_index <- survival::concordance(chd_y_test ~ chd_surv_risk_scores)
log_survival_cindex("CHD", "LASSO (Survival)", chd_test$time, chd_test$status, as.numeric(chd_surv_risk_scores))

cat("CHD Survival LASSO - C-Index on Test Set:", round(as.numeric(chd_surv_c_index$concordance), 4), "\n")

# Get non-zero coefficients for feature importance from the CV model
chd_surv_coefs <- coef(chd_surv_lasso_cv, s = "lambda.min")
chd_surv_nonzero_coefs <- data.frame(
  feature = rownames(chd_surv_coefs)[chd_surv_coefs@i + 1], # Using sparse matrix indexing
  coefficient = chd_surv_coefs@x
) %>%
  filter(feature != "(Intercept)") %>%
  arrange(desc(abs(coefficient)))

cat("CHD Survival LASSO - Number of selected features:", nrow(chd_surv_nonzero_coefs), "\n")


```

###### Accuracy

```{r chd-survival-lasso-prediction-accuracy, echo=FALSE, warning=FALSE, message=FALSE, eval=TRUE}

cat("CHD Survival LASSO - C-Index:", round(as.numeric(chd_surv_c_index$concordance), 4), "\n")

```

###### Feature Importance

```{r chd-lasso-features, warning=FALSE, message=FALSE, eval=TRUE, echo=FALSE}

# Display CHD LASSO coefficients
cat("CHD LASSO Model - Number of selected features:", nrow(chd_surv_nonzero_coefs), "\n")
  
  datatable(
    chd_surv_nonzero_coefs,
    caption = "CHD Cohort - LASSO Feature Coefficients",
    rownames = FALSE,
    options = list(
      pageLength = 15,
      columnDefs = list(
        list(className = 'dt-left', targets = "_all")
      )
    )
  )

```

##### CatBoost Survival Model

```{r chd-catboost-model-df, echo=FALSE, warning=FALSE, message=FALSE, eval=TRUE}

# Apply cleaning cohort
chd_catboost_df <- clean_survival_data_for_catboost(chd_data)

# Filter columns: keep only those that DON'T match the keyword list OR start with "sd"

chd_catboost_df <- chd_catboost_df %>%
  # drop lagging/sd features (unchanged)
  select(!(matches(paste(survival_lagging_keywords, collapse = "|")) | starts_with("sd"))) %>%
  mutate(
    outcome        = as.integer(outcome),                 # ensure 0/1
    chd_final_time = suppressWarnings(as.numeric(ev_time)),

    # glmnet/catboost survival need strictly positive times; bump <=0 by tiny epsilon
    chd_final_time = if_else(is.finite(chd_final_time) & chd_final_time <= 0,
                             .Machine$double.eps, chd_final_time),

    # ✅ signed-time label: +time for events, −time for censored
    chd_catboost_label = if_else(outcome == 1L, chd_final_time, -chd_final_time)
  ) %>%
  # keep rows with usable time
  filter(is.finite(chd_final_time))


```

```{r chd-catboost-data-prep}

# Split the data
chd_train_data <- chd_catboost_df[chd_train_indices, ]
chd_test_data  <- chd_catboost_df[chd_test_indices, ]


# Create the Correctly Formatted Survival Label ---
# Positive value for event, negative for censored
chd_train_labels <- ifelse(chd_train_data$outcome == 1, 
                           chd_train_data$chd_final_time, 
                           -chd_train_data$chd_final_time)

chd_test_labels <- ifelse(chd_test_data$outcome == 1, 
                          chd_test_data$chd_final_time, 
                          -chd_test_data$chd_final_time)


# Filter out invalid records from labels and data
# This ensures labels are finite and positive in absolute value
valid_train_indices <- which(is.finite(chd_train_labels) & chd_train_labels != 0)
chd_train_labels <- chd_train_labels[valid_train_indices]
chd_train_data <- chd_train_data[valid_train_indices, ]

valid_test_indices <- which(is.finite(chd_test_labels) & chd_test_labels != 0)
chd_test_labels <- chd_test_labels[valid_test_indices]
chd_test_data <- chd_test_data[valid_test_indices, ]


# Remove all outcome-related columns from the features
feature_exclusion_cols <- c("ptid_e", "ev_time", "outcome", "chd_final_time", "chd_catboost_label")


# Prepare training features
chd_train_features <- chd_train_data %>%
  select(-any_of(feature_exclusion_cols)) %>%
  mutate(across(where(is.character), as.factor)) # Convert all characters to factors

# Prepare test features
chd_test_features <- chd_test_data %>%
  select(-any_of(feature_exclusion_cols)) %>%
  mutate(across(where(is.character), as.factor)) # Convert all characters to factors

# Synchronize factor levels from train to test
# This ensures any new levels in the test set don't cause issues
for (col in names(chd_train_features)) {
  if (is.factor(chd_train_features[[col]])) {
    train_levels <- levels(chd_train_features[[col]])
    chd_test_features[[col]] <- factor(chd_test_features[[col]], levels = train_levels)
  }
}

```

```{r chd-catboost-model}

## CatBoost pools removed; using run_catboost_cox wrapper


# Model parameters
params <- list(
  loss_function = 'Cox',
  eval_metric = 'Cox', # Metric to calculate on the test set
  iterations = 2000,
  depth = 4,
  verbose = 500 # Print train and test metrics every 500 iterations
)


chd_catboost_res <- run_catboost_cox(
  train_df = chd_train_data,
  test_df = chd_test_data,
  time_col = 'ev_time',
  status_col = 'outcome',
  cohort_name = 'CHD',
  model_name = 'CatBoost',
  params = params
)

```

###### Accuracy

```{r catboost-accuracy, echo=FALSE, warning=FALSE, message=FALSE, eval=TRUE}

chd_predictions_test <- chd_catboost_res$risk_scores

# Compute concordance using wrapper outputs
chd_test_time <- abs(chd_test_labels)
chd_test_status <- ifelse(chd_test_labels > 0, 1, 0)
chd_surv_obj_test <- Surv(chd_test_time, chd_test_status)
chd_concordance_score <- survival::concordance(chd_surv_obj_test ~ chd_predictions_test)
print("Model Performance on Test Set:")
print(chd_concordance_score)

```

```{r chd-catboost-survival-metrics}

chd_catboost_risk_scores <- chd_catboost_res$risk_scores
chd_test_time <- abs(chd_test_labels)
chd_test_status <- ifelse(chd_test_labels > 0, 1, 0)
chd_surv_obj_test <- Surv(chd_test_time, chd_test_status)
chd_concordance_score <- survival::concordance(chd_surv_obj_test ~ chd_catboost_risk_scores)
log_survival_cindex("CHD", "CatBoost", chd_test_time, chd_test_status, as.numeric(chd_catboost_risk_scores))


# Pass the concordance object to the streamlined function
chd_catboost_surv_metrics <- create_survival_metrics(
  "CHD",
  "CatBoost",
  chd_concordance_score
)

# Print Results
cat("CHD CatBoost Model Performance:\n")
print(chd_concordance_score)
cat("\nMetrics List Created:\n")
print(chd_catboost_surv_metrics)

```

###### Feature Importance

```{r catboost-feature-importance, echo=FALSE, warning=FALSE, message=FALSE, eval=TRUE}

chd_feature_importance_df <- chd_catboost_res$importance

# Convert to tidy format with enframe
chd_importance_df <- as.data.frame(chd_feature_importance_df) %>%
  mutate(feature = rownames(.)) %>%
  rename(importance = V1) %>%
  filter(importance > 0) %>%
  select(feature, importance) %>% 
  arrange(desc(importance))

  
  datatable(
    chd_importance_df,
    caption = "CHD Cohort - CatBoost Feature Importance",
    rownames = FALSE,
    options = list(
      pageLength = 15,
      columnDefs = list(
        list(className = 'dt-left', targets = "_all")
      )
    )
  )

```

##### AORSF Model

```{r chd-aorsf-fit-model, warning=FALSE, message=FALSE, echo=FALSE, eval=TRUE}


chd_aorsf_model <- chd_data %>% remove_leakage_predictors()


if(nrow(chd_data) > 0) {
  
  # Check if survival variables exist in the data
  if(all(c("ev_time", "outcome") %in% colnames(chd_aorsf_model))) {
    
    # Prepare data with standard 'time' and 'status' columns for survival analysis
    chd_aorsf_data <- chd_aorsf_model %>%
      mutate(
        egfr_at_transplant = if_else(is.infinite(egfr_at_transplant), NA_real_, egfr_at_transplant)
    ) %>%
      mutate(
        time = ev_time,
        status = as.integer(outcome == 1)
      ) %>%
      select(ptid_e, time, status, everything()) %>% 
      mutate(across(where(is.character), as.factor)) %>% 
      select(-ev_time, -outcome)
      
    chd_aorsf_train <- chd_aorsf_data[chd_train_indices, ]
    chd_aorsf_test  <- chd_aorsf_data[chd_test_indices, ]
    
    if(nrow(chd_aorsf_train) > 0 && nrow(chd_aorsf_test) > 0) {
      
      # Remove constant columns
      constant_cols <- names(chd_aorsf_train)[sapply(chd_aorsf_train, function(x) {
        length(unique(na.omit(x))) == 1
      })]
      
      if(length(constant_cols) > 0) {
        chd_aorsf_train <- chd_aorsf_train %>% select(-all_of(constant_cols))
        chd_aorsf_test  <- chd_aorsf_test  %>% select(-all_of(constant_cols))
      }
      
      # Ensure consistent features between train and test
      common_features <- intersect(colnames(chd_aorsf_train), colnames(chd_aorsf_test))
      chd_aorsf_train <- chd_aorsf_train %>% select(all_of(common_features))
      chd_aorsf_test <- chd_aorsf_test %>% select(all_of(common_features))
      
      
      # --- Train AORSF model (wrapper) ---
      chd_aorsf_res <- run_aorsf(
        train_df = chd_aorsf_train,
        test_df = chd_aorsf_test,
        time_col = 'time',
        status_col = 'status',
        cohort_name = 'CHD',
        model_name = 'AORSF',
        n_tree = 100
      )
      chd_aorsf_model <- chd_aorsf_res$model
      
    } else {
      cat("Insufficient data after splitting for CHD AORSF modeling\n")
    }
    
  } else {
    cat("Survival variables (ev_time, ev_type) not found in CHD data\n")
  }
  
} else {
  cat("Initial CHD data frame is empty\n")
}

      
```

###### Accuracy Metrics

```{r echo=FALSE, warning=FALSE, message=FALSE, eval=TRUE}


# Get risk predictions on the test data
predictions_aorsf <- chd_aorsf_res$risk_scores
      
# Create a survival object from the test set's actual outcomes
surv_obj_test <- Surv(chd_aorsf_test$time, chd_aorsf_test$status)
      
# Calculate and print the Concordance Index
concordance_aorsf <- survival::concordance(surv_obj_test ~ predictions_aorsf)
      
cat("\n--- AORSF Model Evaluation on Test Set ---\n")
print(concordance_aorsf)

```

```{r chd-aorsf-survival-metrics}

# Get risk predictions on the test data
chd_aorsf_risk_scores <- chd_aorsf_res$risk_scores
      
# Create survival object
chd_aorsf_surv_obj_test <- Surv(chd_aorsf_test$time, chd_aorsf_test$status)
      
# Calculate the full concordance object
chd_aorsf_c_index <- survival::concordance(chd_aorsf_surv_obj_test ~ chd_aorsf_risk_scores)
log_survival_cindex("CHD", "AORSF", chd_aorsf_test$time, chd_aorsf_test$status, as.numeric(chd_aorsf_risk_scores))
      

# Pass the concordance object to the streamlined function
chd_aorsf_metrics <- create_survival_metrics(
  "CHD", 
  "AORSF", 
  chd_aorsf_c_index
)

# RSF (ranger) wrapper run for CHD
chd_rsf_res <- run_rsf_ranger(
  train_df = chd_aorsf_train,
  test_df = chd_aorsf_test,
  time_col = 'time',
  status_col = 'status',
  cohort_name = 'CHD',
  model_name = 'RSF (ranger)',
  num.trees = 500
)

# XGB-Cox wrapper run for CHD
chd_xgb_res <- run_xgb_cox(
  train_df = chd_train,
  test_df = chd_test,
  time_col = 'time',
  status_col = 'status',
  cohort_name = 'CHD',
  model_name = 'XGBoost-Cox'
)

# Print Results
cat("CHD AORSF Model Performance:\n")
print(chd_aorsf_c_index)
cat("\nMetrics List Created:\n")
print(chd_aorsf_metrics)

```


###### Feature Importance

```{r echo=FALSE, warning=FALSE, message=FALSE, eval=TRUE}

chd_aorsf_importance_df <- chd_aorsf_res$vi


datatable(
  chd_aorsf_importance_df,
  caption = "CHD Cohort - AORSF Variable Importance",
  rownames = FALSE,
  options = list(pageLength = 15)
)
      
```


#### Myocarditis/Cardiomyopathy Cohort Analysis

```{r echo=FALSE, warning=FALSE, message=FALSE, eval=TRUE}

mc_data <- model_data %>% filter(primary_etiology %in% c("Cardiomyopathy", "Myocarditis"))


# Myo/Cardio Cohort summary
cat("Myocarditis/Cardiomyopathy Cohort Size:", nrow(mc_data), "patients\n")
cat("Event Distribution (outcome):\n")
print(table(mc_data$outcome))
cat("Event Rate:", round(mean(mc_data$outcome, na.rm = TRUE) * 100, 2), "%\n")

# Myo/Cardio Cohort descriptive statistics
mc_summary <- mc_data %>%
  select(where(is.numeric)) %>%
  summarise(across(everything(), list(
    mean = ~ round(mean(.x, na.rm = TRUE), 2),
    median = ~ round(median(.x, na.rm = TRUE), 2),
    sd = ~ round(sd(.x, na.rm = TRUE), 2)
  ))) %>%
  pivot_longer(everything(), names_to = "stat", values_to = "value") %>%
  separate(stat, into = c("variable", "statistic"), sep = "_(?=[^_]*$)") %>%
  pivot_wider(names_from = statistic, values_from = value)

# Display Myo/Cardio summary table
datatable(
  mc_summary,
  rownames = FALSE,
  options = list(
    pageLength = 10,
    columnDefs = list(
      list(className = 'dt-left', targets = "_all")
    )
  )
)

```

```{r}

# Create or load persistent split for Myo/Cardio cohort
mc_split <- get_or_create_unified_split(mc_data, "Myo/Cardio", seed = 1997)

# Extract split info
mc_train_indices <- mc_split$split_info$train_indices
mc_test_indices  <- mc_split$split_info$test_indices
mc_train_data    <- mc_split$train_data
mc_test_data     <- mc_split$test_data

```

##### LASSO Model

```{r myo-lasso-df, echo=FALSE, warning=FALSE, message=FALSE}

# Filter, clean, and prepare data for survival analysis ---
mc_surv_data <- mc_data %>%
  remove_leakage_predictors() %>%
  # Create standard 'time' and 'status' columns
  mutate(
    time = ev_time,
    status = outcome
  ) %>%
  # Handle infinite values by converting them to NA
  mutate(across(where(is.numeric), ~if_else(is.infinite(.), NA_real_, .))) %>%
  # d. Remove any columns that are entirely empty
  select(-where(~all(is.na(.)))) %>%
  # e. Remove identifier and original time/status columns
  select(-ev_time, -outcome) %>%
  # f. Ensure all predictors are numeric for glmnet
  mutate(across(where(is.character), as.factor)) %>%
  mutate(across(where(is.factor), as.numeric))


# Remove constant columns
constant_cols <- names(mc_surv_data)[sapply(mc_surv_data, function(x) {
  length(unique(na.omit(x))) == 1
})]
if(length(constant_cols) > 0) {
  mc_surv_data <- mc_surv_data %>% select(-all_of(constant_cols))
}


# Impute any remaining missing values
# glmnet requires a complete matrix. We'll use median imputation.
mc_surv_data <- mc_surv_data %>%
  mutate(across(everything(), ~if_else(is.na(.), median(., na.rm = TRUE), .)))

cat("Myo/Cardio Survival LASSO - Final data dimensions:", paste(dim(mc_surv_data), collapse = " x "), "\n")

```

```{r myo-lasso-train-test-split}

mc_train <- mc_surv_data[mc_train_indices, ]
mc_test  <- mc_surv_data[mc_test_indices, ]

# --- Create matrices and survival objects for TRAIN set ---
mc_y_train <- Surv(mc_train$time, mc_train$status)
mc_x_train <- as.matrix(mc_train %>% select(-time, -status))

# --- Create matrices and survival objects for TEST set ---
mc_y_test <- Surv(mc_test$time, mc_test$status)
mc_x_test <- as.matrix(mc_test %>% select(-time, -status))


# --- Verify the size of the new data frames ---
cat("Myo/Cardio Training set size:", nrow(mc_train), "\n")
cat("Myo/Cardio Test set size:", nrow(mc_test), "\n")


```

```{r myo-lasso-model-fit}

mc_lasso_res <- run_lasso_cox(
  train_df = mc_train,
  test_df = mc_test,
  time_col = "time",
  status_col = "status",
  cohort_name = "Myo/Cardio",
  model_name = "LASSO (Survival)"
)

mc_surv_risk_scores <- mc_lasso_res$risk_scores
mc_surv_c_index <- mc_lasso_res$concordance
mc_surv_lasso_model <- mc_lasso_res$model
mc_surv_lasso_cv <- mc_lasso_res$cv
mc_surv_optimal_lambda <- mc_lasso_res$lambda_min
mc_surv_nonzero_coefs <- mc_lasso_res$nonzero_coefs
mc_lasso_metrics <- create_survival_metrics("Myo/Cardio","LASSO (Survival)", mc_surv_c_index)
 
```

```{r myo-lasso-predictions}

mc_surv_risk_scores <- predict(mc_surv_lasso_model,
                                newx = mc_x_test,
                                s = "lambda.min")

# Calculate C-Index on the TEST data
mc_surv_c_index <- survival::concordance(mc_y_test ~ mc_surv_risk_scores)
log_survival_cindex("Myo/Cardio", "LASSO (Survival)", mc_test$time, mc_test$status, as.numeric(mc_surv_risk_scores))

cat("Myo/Cardio Survival LASSO - C-Index on Test Set:", round(as.numeric(mc_surv_c_index$concordance), 4), "\n")

# Get non-zero coefficients for feature importance from the CV model
mc_surv_coefs <- coef(mc_surv_lasso_cv, s = "lambda.min")
mc_surv_nonzero_coefs <- data.frame(
  feature = rownames(mc_surv_coefs)[mc_surv_coefs@i + 1],
  coefficient = mc_surv_coefs@x
) %>%
  filter(feature != "(Intercept)") %>%
  arrange(desc(abs(coefficient)))

cat("Myo/Cardio Survival LASSO - Number of selected features:", nrow(mc_surv_nonzero_coefs), "\n")

```

###### Accuracy

```{r myo-lasso-survival-accuracy, warning=FALSE, message=FALSE, echo=FALSE, eval=TRUE}

cat("Myo/Cardio Survival LASSO - C-Index:", round(as.numeric(mc_surv_c_index$concordance), 4), "\n")

```

###### Feature Importance

```{r myo-lasso-features, warning=FALSE, message=FALSE, echo=FALSE, eval=TRUE}


cat("Myo/Cardio LASSO Model - Number of selected features:", nrow(mc_surv_nonzero_coefs), "\n")
  
datatable(
  mc_surv_nonzero_coefs,
  caption = "Myo/Cardio Cohort - LASSO Feature Coefficients",
  rownames = FALSE,
  options = list(
    pageLength = 15,
    columnDefs = list(
      list(className = 'dt-left', targets = "_all")
    )
  )
)

```

##### CatBoost Survival Model

```{r myo-catboost-model-df, echo=FALSE, warning=FALSE, message=FALSE, eval=TRUE}


mc_catboost_df <- clean_survival_data_for_catboost(mc_data) %>%
  # drop lagging/sd features
  select(!(matches(paste(survival_lagging_keywords, collapse = "|")) | starts_with("sd"))) %>%
  mutate(
    outcome        = as.integer(outcome),                   # ensure 0/1
    mc_final_time = suppressWarnings(as.numeric(ev_time)), # observed time (yrs)

    # Cox/AFT solvers need strictly positive times → bump <= 0 to tiny epsilon
    mc_final_time = if_else(is.finite(mc_final_time) & mc_final_time <= 0,
                             .Machine$double.eps, mc_final_time),

    # CatBoost "signed time" label: +time for events, −time for censored
    mc_catboost_label = if_else(outcome == 1L, mc_final_time, -mc_final_time)
  ) %>%
  # keep rows with usable time
  filter(is.finite(mc_final_time))


```

```{r myo-catboost-data-prep}

# Split the data
mc_train_data <- mc_catboost_df[mc_train_indices, ]
mc_test_data  <- mc_catboost_df[mc_test_indices, ]


# Create the Correctly Formatted Survival Label ---
# Positive value for event, negative for censored
mc_train_labels <- ifelse(mc_train_data$outcome == 1, 
                           mc_train_data$mc_final_time, 
                           -mc_train_data$mc_final_time)

mc_test_labels <- ifelse(mc_test_data$outcome == 1, 
                          mc_test_data$mc_final_time, 
                          -mc_test_data$mc_final_time)


# Filter out invalid records from labels and data
# This ensures labels are finite and positive in absolute value
valid_train_indices <- which(is.finite(mc_train_labels) & mc_train_labels != 0)
mc_train_labels <- mc_train_labels[valid_train_indices]
mc_train_data <- mc_train_data[valid_train_indices, ]

valid_test_indices <- which(is.finite(mc_test_labels) & mc_test_labels != 0)
mc_test_labels <- mc_test_labels[valid_test_indices]
mc_test_data <- mc_test_data[valid_test_indices, ]


# Prepare Feature Sets

# Define columns to remove from the feature set
feature_exclusion_cols <- c("ev_time", "outcome", "days_to_last_followup", "mc_final_time", "mc_catboost_label")

# Prepare training features
mc_train_features <- mc_train_data %>%
  select(-any_of(feature_exclusion_cols)) %>%
  mutate(across(where(is.character), as.factor)) # Convert all characters to factors

# Prepare test features
mc_test_features <- mc_test_data %>%
  select(-any_of(feature_exclusion_cols)) %>%
  mutate(across(where(is.character), as.factor)) # Convert all characters to factors

# Synchronize factor levels from train to test
# This ensures any new levels in the test set don't cause issues
for (col in names(mc_train_features)) {
  if (is.factor(mc_train_features[[col]])) {
    train_levels <- levels(mc_train_features[[col]])
    mc_test_features[[col]] <- factor(mc_test_features[[col]], levels = train_levels)
  }
}

```

```{r myo-catboost-model-fit}

## CatBoost pools and direct training removed; using run_catboost_cox wrapper

```

###### Accuracy

```{r myo-catboost-accuracy, echo=FALSE, warning=FALSE, message=FALSE, eval=TRUE}

mc_catboost_res <- run_catboost_cox(
  train_df = mc_train_data,
  test_df = mc_test_data,
  time_col = 'ev_time',
  status_col = 'outcome',
  cohort_name = 'Myo/Cardio',
  model_name = 'CatBoost',
  params = params
)
mc_predictions_test <- mc_catboost_res$risk_scores

mc_test_time <- abs(mc_test_labels)
mc_test_status <- ifelse(mc_test_labels > 0, 1, 0)
mc_surv_obj_test <- Surv(mc_test_time, mc_test_status)
mc_concordance_score <- survival::concordance(mc_surv_obj_test ~ mc_predictions_test)
print("Model Performance on Test Set:")
print(mc_concordance_score)

```

```{r mc-catboost-survival-metrics}

mc_catboost_risk_scores <- mc_catboost_res$risk_scores
mc_test_time <- abs(mc_test_labels)
mc_test_status <- ifelse(mc_test_labels > 0, 1, 0)
mc_surv_obj_test <- Surv(mc_test_time, mc_test_status)
mc_concordance_score <- survival::concordance(mc_surv_obj_test ~ mc_catboost_risk_scores)
log_survival_cindex("Myo/Cardio", "CatBoost", mc_test_time, mc_test_status, as.numeric(mc_catboost_risk_scores))

# Pass the concordance object to the streamlined function
mc_catboost_surv_metrics <- create_survival_metrics(
  "Myo/Cardio",
  "CatBoost",
  mc_concordance_score
)

# Print Results
cat("Myo/Cardio CatBoost Model Performance:\n")
print(mc_concordance_score)
cat("\nMetrics List Created:\n")
print(mc_catboost_surv_metrics)

```

###### Feature Importance

```{r myo-catboost-feature-importance, echo=FALSE, warning=FALSE, message=FALSE, eval=TRUE}

mc_feature_importance_df <- mc_catboost_res$importance

# Convert to tidy format with enframe
mc_importance_df <- as.data.frame(mc_feature_importance_df) %>%
  mutate(feature = rownames(.)) %>%
  rename(importance = V1) %>%
  filter(importance > 0) %>%
  select(feature, importance) %>% 
  arrange(desc(importance))

  
  datatable(
    mc_importance_df,
    caption = "Myo/Cardio Cohort - CatBoost Feature Importance",
    rownames = FALSE,
    options = list(
      pageLength = 15,
      columnDefs = list(
        list(className = 'dt-left', targets = "_all")
      )
    )
  )

```

##### AORSF Model

```{r myo-aorsf-fit-model, echo=FALSE, warning=FALSE, message=FALSE, eval=TRUE}

mc_aorsf_df <- mc_data %>% remove_leakage_predictors()

if(nrow(mc_data) > 0) {
  
  if(all(c("ev_time", "outcome") %in% colnames(mc_data))) {
    
    # Prepare the Full Dataset
    mc_aorsf_data <- mc_data %>%
      # (Your other prep steps here)
      mutate(
        time = ev_time,
        status = as.integer(outcome == 1)
      ) %>%
      select(ptid_e, time, status, everything()) %>% 
      mutate(across(where(is.character), as.factor)) %>% 
      select(-ev_time, -outcome)

    # Split Data
    mc_aorsf_train <- mc_aorsf_data[mc_train_indices, ]
    mc_aorsf_test  <- mc_aorsf_data[mc_test_indices, ]
    
    if(nrow(mc_aorsf_train) > 0 && nrow(mc_aorsf_test) > 0) {
      
      # Synchronized Feature Cleaning

      empty_cols_train <- names(mc_aorsf_train)[sapply(mc_aorsf_train, function(x) all(is.na(x)))]
      empty_cols_test <- names(mc_aorsf_test)[sapply(mc_aorsf_test, function(x) all(is.na(x)))]
      
      all_empty_cols <- union(empty_cols_train, empty_cols_test)
      
      if (length(all_empty_cols) > 0) {
        cat("Removing columns with all NA values in train or test set:", paste(all_empty_cols, collapse = ", "), "\n")
        mc_aorsf_train <- mc_aorsf_train %>% select(-all_of(all_empty_cols))
        mc_aorsf_test  <- mc_aorsf_test  %>% select(-all_of(all_empty_cols))
      }

      # Remove constant columns based on the training set
      constant_cols <- names(mc_aorsf_train)[sapply(mc_aorsf_train, function(col) {
        length(unique(na.omit(col))) == 1
      })]
      mc_aorsf_train <- mc_aorsf_train %>% select(-all_of(constant_cols))
      
      # Ensure both sets have the exact same feature columns
      common_features <- intersect(colnames(mc_aorsf_train), colnames(mc_aorsf_test))
      mc_aorsf_train <- mc_aorsf_train %>% select(all_of(common_features))
      mc_aorsf_test <- mc_aorsf_test %>% select(all_of(common_features))
      
      # Train AORSF Model (wrapper)
      mc_aorsf_res <- run_aorsf(
        train_df = mc_aorsf_train,
        test_df = mc_aorsf_test,
        time_col = 'time',
        status_col = 'status',
        cohort_name = 'Myo/Cardio',
        model_name = 'AORSF',
        n_tree = 100
      )
      mc_aorsf_model <- mc_aorsf_res$model
      
      # (The rest of your script for evaluation follows)
      
    } else {
      cat("Insufficient data after splitting.\n")
    }
  } else {
    cat("Survival variables not found.\n")
  }
} else {
  cat("Initial data frame is empty.\n")
}


```

###### Accuracy Metrics

```{r echo=FALSE, warning=FALSE, message=FALSE, eval=TRUE}

##### AORSF Model - Evaluation and Feature Importance

# Get risk predictions on the test data
mc_predictions_aorsf <- mc_aorsf_res$risk_scores
      
# Create a survival object from the test set's actual outcomes
mc_aorsf_surv_obj_test <- Surv(mc_aorsf_test$time, mc_aorsf_test$status)
      
# Calculate and print the Concordance Index
mc_concordance_aorsf <- survival::concordance(mc_aorsf_surv_obj_test ~ mc_predictions_aorsf)
      
cat("\n--- AORSF Model Evaluation on Test Set ---\n")
print(mc_concordance_aorsf)

```

```{r mc-aorsf-survival-metrics}

# Get risk predictions on the test data
mc_aorsf_risk_scores <- mc_aorsf_res$risk_scores
      
# Create survival object
mc_aorsf_surv_obj_test <- Surv(mc_aorsf_test$time, mc_aorsf_test$status)
      
# Calculate the full concordance object
mc_aorsf_c_index <- survival::concordance(mc_aorsf_surv_obj_test ~ mc_aorsf_risk_scores)
log_survival_cindex("Myo/Cardio", "AORSF", mc_aorsf_test$time, mc_aorsf_test$status, as.numeric(mc_aorsf_risk_scores))
      

# Pass the concordance object to the streamlined function
mc_aorsf_metrics <- create_survival_metrics(
  "Myo/Cardio", 
  "AORSF", 
  mc_aorsf_c_index
)

# RSF (ranger) wrapper run for Myo/Cardio
mc_rsf_res <- run_rsf_ranger(
  train_df = mc_aorsf_train,
  test_df = mc_aorsf_test,
  time_col = 'time',
  status_col = 'status',
  cohort_name = 'Myo/Cardio',
  model_name = 'RSF (ranger)',
  num.trees = 500
)

# XGB-Cox wrapper run for Myo/Cardio
mc_xgb_res <- run_xgb_cox(
  train_df = mc_train,
  test_df = mc_test,
  time_col = 'time',
  status_col = 'status',
  cohort_name = 'Myo/Cardio',
  model_name = 'XGBoost-Cox'
)

# Export data for DeepSurv/DeepHit (pycox) per cohort
export_pycox_dataset(
  train_df = chd_train,
  test_df = chd_test,
  time_col = 'time',
  status_col = 'status',
  out_dir = file.path('cohort_analysis', 'pycox_chd')
)

export_pycox_dataset(
  train_df = mc_train,
  test_df = mc_test,
  time_col = 'time',
  status_col = 'status',
  out_dir = file.path('cohort_analysis', 'pycox_myo_cardio')
)

```

```{python}
# Train pycox models for CHD and Myo/Cardio cohorts on exported CSVs
import os, sys, pandas as pd

def _pip_install(pkgs):
    import subprocess
    for p in pkgs:
        try:
            __import__(p.split('==')[0].replace('-', '_'))
        except Exception:
            subprocess.check_call([sys.executable, '-m', 'pip', 'install', p])

_pip_install(['pycox', 'torch', 'torchtuples', 'pandas', 'numpy', 'scikit-learn'])

from cohort_analysis.survival_analysis import *  # not needed; we inline logic here if isolation

# Reuse the function defined above if running in same session; else inline similar logic
from pathlib import Path

def run_one(data_dir, cohort_name):
    # Minimal import of utility from the other cell if available
    try:
        from __main__ import train_pycox_models
    except Exception:
        # Fallback: no-op
        return None
    return train_pycox_models(data_dir, cohort_name, metrics_path='cohort_analysis/pycox_metrics.csv')

run_one('cohort_analysis/pycox_chd', 'CHD')
run_one('cohort_analysis/pycox_myo_cardio', 'Myo/Cardio')

# Print Results
cat("Myo/Cardio AORSF Model Performance:\n")
print(mc_aorsf_c_index)
cat("\nMetrics List Created:\n")
print(mc_aorsf_metrics)

```

### Model Performance Comparison

Note: Deep learning metrics (DeepSurv/DeepHit via pycox) are appended
from `cohort_analysis/pycox_metrics.csv` when available.

```{r warning=FALSE, message=FALSE, echo=FALSE, eval=TRUE}

# Collect survival metrics per cohort
metrics_rows <- list()
if (exists('chd_lasso_metrics')) metrics_rows <- append(metrics_rows, list(chd_lasso_metrics))
if (exists('chd_catboost_surv_metrics')) metrics_rows <- append(metrics_rows, list(chd_catboost_surv_metrics))
if (exists('chd_aorsf_metrics')) metrics_rows <- append(metrics_rows, list(chd_aorsf_metrics))
if (exists('chd_rsf_res')) metrics_rows <- append(metrics_rows, list(create_survival_metrics('CHD','RSF (ranger)', chd_rsf_res$concordance)))
if (exists('chd_xgb_res')) metrics_rows <- append(metrics_rows, list(create_survival_metrics('CHD','XGBoost-Cox', chd_xgb_res$concordance)))

if (exists('mc_lasso_metrics')) metrics_rows <- append(metrics_rows, list(mc_lasso_metrics))
if (exists('mc_catboost_surv_metrics')) metrics_rows <- append(metrics_rows, list(mc_catboost_surv_metrics))
if (exists('mc_aorsf_metrics')) metrics_rows <- append(metrics_rows, list(mc_aorsf_metrics))
if (exists('mc_rsf_res')) metrics_rows <- append(metrics_rows, list(create_survival_metrics('Myo/Cardio','RSF (ranger)', mc_rsf_res$concordance)))
if (exists('mc_xgb_res')) metrics_rows <- append(metrics_rows, list(create_survival_metrics('Myo/Cardio','XGBoost-Cox', mc_xgb_res$concordance)))

if (length(metrics_rows) > 0) {
  metrics_df <- bind_rows(metrics_rows)
  if (file.exists('cohort_analysis/pycox_metrics.csv')) {
    pycox_df <- readr::read_csv('cohort_analysis/pycox_metrics.csv', show_col_types = FALSE)
    pycox_df <- pycox_df %>% filter(Cohort %in% c('CHD','Myo/Cardio'))
    metrics_df <- bind_rows(metrics_df, pycox_df)
  }
  datatable(
    metrics_df,
    caption = "Model Performance Comparison - Survival Models by Cohort",
    rownames = FALSE,
    options = list(
      pageLength = 10,
      columnDefs = list(list(className = 'dt-left', targets = "_all"))
    )
  )
  # Persist metrics by cohort
  readr::write_csv(metrics_df, file.path('cohort_analysis', 'metrics_cohorts.csv'))
} else {
  cat('No metrics available for comparison')
}

```

### Best Models by C-index (Cohorts)

```{r}

if (exists('metrics_df')) {
  chd_best <- metrics_df %>% filter(Cohort == 'CHD') %>% arrange(desc(C_Index)) %>% slice_head(n = 1)
  mc_best  <- metrics_df %>% filter(Cohort == 'Myo/Cardio') %>% arrange(desc(C_Index)) %>% slice_head(n = 1)
  best_tbl <- bind_rows(chd_best, mc_best)
  datatable(best_tbl, caption = 'Best Model by C-index - CHD and Myo/Cardio', rownames = FALSE,
            options = list(pageLength = 5, columnDefs = list(list(className = 'dt-left', targets = "_all"))))
  out_path <- file.path('cohort_analysis', 'best_models_cohorts.csv')
  readr::write_csv(best_tbl, out_path)
  cat('Saved best models to: ', normalizePath(out_path, winslash = '/', mustWork = FALSE), '\n', sep = '')
} else {
  cat('No cohort metrics to select best models from.\n')
}

```

### Model Calibration Analysis

```{r warning=FALSE, message=FALSE, echo=FALSE, eval=FALSE}

# Create calibration plots for all models
calibration_plots <- list()

# LASSO Calibration Plot
if(exists("lasso_predictions") && exists("y_test")) {
  lasso_cal_plot <- create_calibration_plot(
    lasso_predictions, 
    y_test,
    "Full Cohort", 
    "LASSO"
  )
  if(!is.null(lasso_cal_plot)) {
    calibration_plots[["LASSO"]] <- lasso_cal_plot
  }
}

# CatBoost Calibration Plot
if(exists("catboost_predictions") && exists("catboost_y_test")) {
  catboost_cal_plot <- create_calibration_plot(
    catboost_predictions, 
    catboost_y_test,
    "Full Cohort", 
    "CatBoost"
  )
  if(!is.null(catboost_cal_plot)) {
    calibration_plots[["CatBoost"]] <- catboost_cal_plot
  }
}

# CatBoost RF Calibration Plot
if(exists("rf_predictions") && exists("rf_test$outcome")) {
  rf_cal_plot <- create_calibration_plot(
    rf_predictions, 
    rf_test$outcome,
    "Full Cohort", 
    "CatBoost RF"
  )
  if(!is.null(rf_cal_plot)) {
    calibration_plots[["CatBoost_RF"]] <- rf_cal_plot
  }
}

# Traditional RF Calibration Plot
if(exists("trad_rf_predictions") && exists("trad_rf_test$outcome")) {
  trad_rf_cal_plot <- create_calibration_plot(
    trad_rf_predictions, 
    trad_rf_test$outcome,
    "Full Cohort", 
    "Traditional RF"
  )
  if(!is.null(trad_rf_cal_plot)) {
    calibration_plots[["Traditional_RF"]] <- trad_rf_cal_plot
  }
}


# Display calibration plots
if(length(calibration_plots) > 0) {
  cat("## Calibration Analysis for All Models\n\n")
  cat("Calibration plots show how well predicted probabilities align with observed event rates.\n")
  cat("Perfect calibration: points fall on the diagonal line (slope = 1, intercept = 0).\n\n")
  
  # Display each calibration plot
  for(plot_name in names(calibration_plots)) {
    cat("###", plot_name, "\n\n")
    print(calibration_plots[[plot_name]])
    cat("\n\n")
  }
} else {
  cat("No calibration plots available - ensure all models have been trained and predictions generated.\n")
}

```

### 1-year Calibration and Brier (IPCW) for Cohorts

```{r eval=FALSE}

tau <- 1

# CHD Calibration using AORSF risk scores
if (exists("chd_aorsf_test") && exists("chd_aorsf_res")) {
  chd_prob_tau <- ipcw_prob_from_scores(chd_aorsf_res$risk_scores,
                                        chd_aorsf_test$time, chd_aorsf_test$status,
                                        tau, n_bins = 20)$prob
  chd_cal_tbl <- calibration_table(prob_event_tau = chd_prob_tau,
                                   time = chd_aorsf_test$time, status = chd_aorsf_test$status,
                                   tau = tau, n_bins = 10)
  chd_brier <- brier_ipcw(prob_event_tau = chd_prob_tau,
                          time = chd_aorsf_test$time, status = chd_aorsf_test$status,
                          tau = tau)
  cat("CHD 1-year Brier (IPCW-binned):", round(chd_brier, 4), "\n")
  datatable(chd_cal_tbl, caption = "CHD: Calibration at 1 year (AORSF, IPCW-binned)",
            rownames = FALSE, options = list(pageLength = 10,
            columnDefs = list(list(className = 'dt-left', targets = "_all"))))
} else {
  cat("CHD AORSF test data not available for calibration.\n")
}

# CHD: LASSO
if (exists("chd_test") && exists("chd_surv_risk_scores")) {
  chd_prob_tau <- ipcw_prob_from_scores(as.numeric(chd_surv_risk_scores), chd_test$time, chd_test$status, tau, n_bins = 20)$prob
  chd_brier <- brier_ipcw(prob_event_tau = chd_prob_tau, time = chd_test$time, status = chd_test$status, tau = tau)
  cat("CHD LASSO 1-year Brier:", round(chd_brier, 4), "\\n")
}

# CHD: CatBoost
if (exists("chd_test") && exists("chd_catboost_res")) {
  chd_prob_tau <- ipcw_prob_from_scores(as.numeric(chd_catboost_res$risk_scores), chd_test$time, chd_test$status, tau, n_bins = 20)$prob
  chd_brier <- brier_ipcw(prob_event_tau = chd_prob_tau, time = chd_test$time, status = chd_test$status, tau = tau)
  cat("CHD CatBoost 1-year Brier:", round(chd_brier, 4), "\\n")
}

# CHD: RSF (ranger)
if (exists("chd_aorsf_test") && exists("chd_rsf_res")) {
  chd_prob_tau <- ipcw_prob_from_scores(as.numeric(chd_rsf_res$risk_scores), chd_aorsf_test$time, chd_aorsf_test$status, tau, n_bins = 20)$prob
  chd_brier <- brier_ipcw(prob_event_tau = chd_prob_tau, time = chd_aorsf_test$time, status = chd_aorsf_test$status, tau = tau)
  cat("CHD RSF (ranger) 1-year Brier:", round(chd_brier, 4), "\\n")
}

# CHD: XGBoost-Cox
if (exists("chd_test") && exists("chd_xgb_res")) {
  chd_prob_tau <- ipcw_prob_from_scores(as.numeric(chd_xgb_res$risk_scores), chd_test$time, chd_test$status, tau, n_bins = 20)$prob
  chd_brier <- brier_ipcw(prob_event_tau = chd_prob_tau, time = chd_test$time, status = chd_test$status, tau = tau)
  cat("CHD XGBoost-Cox 1-year Brier:", round(chd_brier, 4), "\\n")
}
# Myo/Cardio Calibration using AORSF risk scores
if (exists("mc_aorsf_test") && exists("mc_aorsf_res")) {
  mc_prob_tau <- ipcw_prob_from_scores(mc_aorsf_res$risk_scores,
                                       mc_aorsf_test$time, mc_aorsf_test$status,
                                       tau, n_bins = 20)$prob
  mc_cal_tbl <- calibration_table(prob_event_tau = mc_prob_tau,
                                  time = mc_aorsf_test$time, status = mc_aorsf_test$status,
                                  tau = tau, n_bins = 10)
  mc_brier <- brier_ipcw(prob_event_tau = mc_prob_tau,
                         time = mc_aorsf_test$time, status = mc_aorsf_test$status,
                         tau = tau)
  cat("Myo/Cardio 1-year Brier (IPCW-binned):", round(mc_brier, 4), "\n")
  datatable(mc_cal_tbl, caption = "Myo/Cardio: Calibration at 1 year (AORSF, IPCW-binned)",
            rownames = FALSE, options = list(pageLength = 10,
            columnDefs = list(list(className = 'dt-left', targets = "_all"))))
} else {
  cat("Myo/Cardio AORSF test data not available for calibration.\n")
}

# Myo/Cardio: LASSO
if (exists("mc_test") && exists("mc_surv_risk_scores")) {
  mc_prob_tau <- ipcw_prob_from_scores(as.numeric(mc_surv_risk_scores), mc_test$time, mc_test$status, tau, n_bins = 20)$prob
  mc_brier <- brier_ipcw(prob_event_tau = mc_prob_tau, time = mc_test$time, status = mc_test$status, tau = tau)
  cat("Myo/Cardio LASSO 1-year Brier:", round(mc_brier, 4), "\\n")
}

# Myo/Cardio: CatBoost
if (exists("mc_test") && exists("mc_catboost_res")) {
  mc_prob_tau <- ipcw_prob_from_scores(as.numeric(mc_catboost_res$risk_scores), mc_test$time, mc_test$status, tau, n_bins = 20)$prob
  mc_brier <- brier_ipcw(prob_event_tau = mc_prob_tau, time = mc_test$time, status = mc_test$status, tau = tau)
  cat("Myo/Cardio CatBoost 1-year Brier:", round(mc_brier, 4), "\\n")
}

# Myo/Cardio: RSF (ranger)
if (exists("mc_aorsf_test") && exists("mc_rsf_res")) {
  mc_prob_tau <- ipcw_prob_from_scores(as.numeric(mc_rsf_res$risk_scores), mc_aorsf_test$time, mc_aorsf_test$status, tau, n_bins = 20)$prob
  mc_brier <- brier_ipcw(prob_event_tau = mc_prob_tau, time = mc_aorsf_test$time, status = mc_aorsf_test$status, tau = tau)
  cat("Myo/Cardio RSF (ranger) 1-year Brier:", round(mc_brier, 4), "\\n")
}

# Myo/Cardio: XGBoost-Cox
if (exists("mc_test") && exists("mc_xgb_res")) {
  mc_prob_tau <- ipcw_prob_from_scores(as.numeric(mc_xgb_res$risk_scores), mc_test$time, mc_test$status, tau, n_bins = 20)$prob
  mc_brier <- brier_ipcw(prob_event_tau = mc_prob_tau, time = mc_test$time, status = mc_test$status, tau = tau)
  cat("Myo/Cardio XGBoost-Cox 1-year Brier:", round(mc_brier, 4), "\\n")
}

```

### Calibration Metrics Summary

```{r warning=FALSE, message=FALSE, echo=FALSE, eval=TRUE}

# Collect all metrics into a single list
all_model_metrics <- list(
  all_lasso_metrics,
  all_catboost_metrics,
  all_rf_metrics,
  all_trad_rf_metrics
)

# Create the summary tables
metrics_summary <- create_metrics_summary(all_model_metrics)

# Display the summary table
datatable(
  metrics_summary$summary,
  caption = "Model Performance Summary",
  rownames = FALSE,
  options = list(
    pageLength = 10,
    columnDefs = list(
      list(className = 'dt-left', targets = "_all")
    )
  )
)
```


### Feature Importance Summary

```{r echo=FALSE, warning=FALSE, message=FALSE, eval=TRUE}

comprehensive_summary <- list()

# Helper to normalize and tag model name
get_top_features <- function(feature_df, model_name) {
  if (nrow(feature_df) == 0) return(NULL)
  top_features <- feature_df %>%
    slice_head(n = 25) %>%
    mutate(Model = model_name, Rank = row_number())
  if ("importance" %in% colnames(top_features)) {
    top_features <- top_features %>% mutate(Normalized_Importance = (importance - min(importance)) / (max(importance) - min(importance)))
  } else if ("coefficient" %in% colnames(top_features)) {
    top_features <- top_features %>% mutate(importance = abs(coefficient), Normalized_Importance = (importance - min(importance)) / (max(importance) - min(importance)))
  }
  top_features
}

# CHD features
if (exists("chd_surv_nonzero_coefs")) {
  chd_lasso_features <- get_top_features(chd_surv_nonzero_coefs, "CHD LASSO")
  if (!is.null(chd_lasso_features)) comprehensive_summary <- append(comprehensive_summary, list(chd_lasso_features))
}
if (exists("chd_importance_df")) {
  chd_cb_features <- get_top_features(chd_importance_df, "CHD CatBoost")
  if (!is.null(chd_cb_features)) comprehensive_summary <- append(comprehensive_summary, list(chd_cb_features))
}
if (exists("chd_aorsf_importance_df")) {
  chd_aorsf_features <- get_top_features(chd_aorsf_importance_df, "CHD AORSF")
  if (!is.null(chd_aorsf_features)) comprehensive_summary <- append(comprehensive_summary, list(chd_aorsf_features))
}

# RSF/XGB importances per cohort if available
if (exists("chd_rsf_res") && !is.null(chd_rsf_res$importance)) {
  chd_rsf_features <- get_top_features(chd_rsf_res$importance, "CHD RSF (ranger)")
  if (!is.null(chd_rsf_features)) comprehensive_summary <- append(comprehensive_summary, list(chd_rsf_features))
}
if (exists("chd_xgb_res") && !is.null(chd_xgb_res$importance)) {
  chd_xgb_features <- get_top_features(chd_xgb_res$importance, "CHD XGBoost-Cox")
  if (!is.null(chd_xgb_features)) comprehensive_summary <- append(comprehensive_summary, list(chd_xgb_features))
}

# Myo/Cardio features
if (exists("mc_surv_nonzero_coefs")) {
  mc_lasso_features <- get_top_features(mc_surv_nonzero_coefs, "Myo/Cardio LASSO")
  if (!is.null(mc_lasso_features)) comprehensive_summary <- append(comprehensive_summary, list(mc_lasso_features))
}
if (exists("mc_importance_df")) {
  mc_cb_features <- get_top_features(mc_importance_df, "Myo/Cardio CatBoost")
  if (!is.null(mc_cb_features)) comprehensive_summary <- append(comprehensive_summary, list(mc_cb_features))
}
if (exists("mc_aorsf_importance_df")) {
  mc_aorsf_features <- get_top_features(mc_aorsf_importance_df, "Myo/Cardio AORSF")
  if (!is.null(mc_aorsf_features)) comprehensive_summary <- append(comprehensive_summary, list(mc_aorsf_features))
}

if (exists("mc_rsf_res") && !is.null(mc_rsf_res$importance)) {
  mc_rsf_features <- get_top_features(mc_rsf_res$importance, "Myo/Cardio RSF (ranger)")
  if (!is.null(mc_rsf_features)) comprehensive_summary <- append(comprehensive_summary, list(mc_rsf_features))
}
if (exists("mc_xgb_res") && !is.null(mc_xgb_res$importance)) {
  mc_xgb_features <- get_top_features(mc_xgb_res$importance, "Myo/Cardio XGBoost-Cox")
  if (!is.null(mc_xgb_features)) comprehensive_summary <- append(comprehensive_summary, list(mc_xgb_features))
}

if (length(comprehensive_summary) > 0) {
  all_features_df <- bind_rows(comprehensive_summary)
}
  
```

```{r}

library(dplyr)
library(DT)

# Select and arrange columns for a clear feature-focused view
feature_summary_df <- all_features_df %>%
  select(Rank, feature, Model, importance, Normalized_Importance) %>%
  arrange(Rank, Model)

# Display the interactive table
datatable(
  feature_summary_df,
  caption = "Feature Importances by Model",
  rownames = FALSE,
  options = list(
    pageLength = 25,
    columnDefs = list(
      list(className = 'dt-left', targets = "_all")
    )
  )
)
readr::write_csv(feature_summary_df, file.path('cohort_analysis', 'feature_importance_cohorts.csv'))

```

### Sankey Chart: Model to Features - Survival Models

```{r sankey-plot, echo=FALSE, warning=FALSE, message=FALSE, eval=TRUE}

library(dplyr)
library(plotly)

# Prepare data for the Sankey diagram
sankey_data <- all_features_df %>%
  select(source = Model, target = feature, value = Normalized_Importance) %>%
  filter(!is.na(value) & value > 0)

if(nrow(sankey_data) > 0) {
  
  # Create a unique list of all nodes (models and features)
  all_nodes <- unique(c(sankey_data$source, sankey_data$target))
  
  # Create a links data frame with 0-based indices
  links <- sankey_data %>%
    mutate(
      source = match(source, all_nodes) - 1,
      target = match(target, all_nodes) - 1
    )

  # Create the Sankey plot
sankey_plot <- plot_ly(
    type = "sankey",
    orientation = "h",
    node = list(
      label = all_nodes,
      pad = 15,
      thickness = 20,
      line = list(color = "black", width = 0.5)
    ),
    link = list(
      source = links$source,
      target = links$target,
      value = links$value
    )
  ) %>%
    layout(
      title = "Feature Importance Flow: Models to Features",
      font = list(size = 10)
    )
    
} else {
  cat("No data available to generate Sankey diagram.\n")
}

sankey_plot

```

```{r eval=FALSE, echo=FALSE}

if (exists("sankey_plot")) {
  htmlwidgets::saveWidget(
    sankey_plot,
    file = "sankey_time_to_event_feature_importance.html",
    selfcontained = TRUE
  )
}


```


