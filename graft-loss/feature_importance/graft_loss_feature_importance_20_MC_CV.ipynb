{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graft Loss Feature Importance with Monte Carlo Cross-Validation\n",
    "\n",
    "**Study Replication:** Publication-quality replication with Monte Carlo cross-validation (configurable 100â€“1000 splits)  \n",
    "**Updated:** November 21, 2025  \n",
    "**Hardware:** Optimized for 32-core EC2 instance (1TB RAM)  \n",
    "**Validation:** Proper evaluation on unseen test data\n",
    "\n",
    "## Key Changes from Original\n",
    "\n",
    "âœ… **Monte Carlo Cross-Validation** â€“ up to 1000 random 75/25 train/test splits (100-split runs used for faster iteration)  \n",
    "âœ… **Stratified Sampling** - Maintains event distribution  \n",
    "âœ… **Parallel Processing** - Fast execution with furrr/future (â‰ˆ30 workers)  \n",
    "âœ… **95% Confidence Intervals** - Narrow, precise estimates (tighter with more splits)  \n",
    "âœ… **Realistic C-Indexes** - Expected range 0.70-0.85\n",
    "\n",
    "## Methodology\n",
    "\n",
    "This notebook implements the feature selection methodology from the original bcjaeger/graft-loss study:\n",
    "\n",
    "1. Load data for pediatric heart transplant outcomes\n",
    "2. Define three time periods:\n",
    "   - **Original**: 2010-2019 (matches publication)\n",
    "   - **Full**: 2010-2024 (all available data)\n",
    "   - **Full No COVID**: 2010-2024 excluding 2020-2023\n",
    "3. For each period and method:\n",
    "   - Create 100â€“1000 stratified train/test splits (75/25)\n",
    "   - Train model on training set\n",
    "   - Evaluate on unseen test set\n",
    "   - Aggregate results across splits\n",
    "4. Calculate C-index with 95% CI\n",
    "5. Extract top 20 features\n",
    "\n",
    "## Expected Runtime (per full 3-period Ã— 3-method run)\n",
    "\n",
    "- **100 splits (current default):**\n",
    "  - Local (4 cores): ~2â€“4 hours (NOT RECOMMENDED)\n",
    "  - Workstation (16 cores): ~1â€“2 hours\n",
    "  - EC2 (32 cores, 1TB RAM): ~1â€“2 hours âœ… **RECOMMENDED FOR DEVELOPMENT**\n",
    "- **1000 splits (extended / publication-level):**\n",
    "  - Local (4 cores): 8â€“12+ hours (NOT RECOMMENDED)\n",
    "  - Workstation (16 cores): ~8â€“16 hours\n",
    "  - EC2 (32 cores, 1TB RAM): ~10â€“20 hours âœ… **RECOMMENDED FOR FINAL RESULTS**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration\n",
    "\n",
    "Load required packages and configure parallel processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Check R version\n",
    "R.version.string\n",
    "\n",
    "# Load required packages\n",
    "library(here)\n",
    "library(dplyr)\n",
    "library(readr)\n",
    "library(survival)\n",
    "library(ranger)\n",
    "library(aorsf)\n",
    "library(catboost)\n",
    "library(tidyr)\n",
    "library(purrr)\n",
    "library(tibble)\n",
    "library(janitor)\n",
    "library(haven)\n",
    "library(riskRegression)\n",
    "library(prodlim)\n",
    "library(rsample)    # For MC-CV\n",
    "library(furrr)      # For parallel processing\n",
    "library(future)     # For parallel backend\n",
    "library(progressr)  # For progress bars\n",
    "\n",
    "cat(\"âœ“ All packages loaded successfully\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DEBUG/TEST MODE - Quick testing before full 100-split run\n",
    "# ============================================================\n",
    "# Set DEBUG_MODE = TRUE for quick testing (5 splits, ~2-5 min)\n",
    "# Set DEBUG_MODE = FALSE for full analysis (100 splits, ~1-2 hours on EC2)\n",
    "\n",
    "DEBUG_MODE <- FALSE  # Change to TRUE for quick test\n",
    "\n",
    "if (DEBUG_MODE) {\n",
    "  cat(\"\\n\")\n",
    "  cat(\"â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\\n\")\n",
    "  cat(\"â•‘                    ðŸ” DEBUG MODE ENABLED                       â•‘\\n\")\n",
    "  cat(\"â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\")\n",
    "  cat(\"\\n\")\n",
    "  cat(\"Quick test configuration:\\n\")\n",
    "  cat(\"  â€¢ MC-CV Splits: 5 (instead of 100)\\n\")\n",
    "  cat(\"  â€¢ Period: Original only (2010-2019)\\n\")\n",
    "  cat(\"  â€¢ Trees: Reduced (RSF: 100, AORSF: 50)\\n\")\n",
    "  cat(\"  â€¢ Expected time: 2-5 minutes\\n\")\n",
    "  cat(\"  â€¢ Purpose: Verify everything works before full run\\n\")\n",
    "  cat(\"\\n\")\n",
    "  cat(\"To run full analysis, set DEBUG_MODE = FALSE\\n\")\n",
    "  cat(\"\\n\")\n",
    "}\n",
    "\n",
    "# Configuration\n",
    "n_predictors <- 20                                        # Top 20 features\n",
    "n_trees_rsf <- if (DEBUG_MODE) 100 else 500              # RSF trees (reduced in debug)\n",
    "n_trees_aorsf <- if (DEBUG_MODE) 50 else 100             # AORSF trees (reduced in debug)\n",
    "horizon <- 1                                              # 1-year prediction\n",
    "n_mc_splits <- if (DEBUG_MODE) 5 else 100                # MC-CV splits (5 for debug, 100 for full)\n",
    "train_prop <- 0.75                                        # 75% training, 25% testing\n",
    "\n",
    "# Set up parallel processing - EC2 Optimized (32 cores, 1TB RAM)\n",
    "# Use 30 out of 32 cores (leave 2 for system)\n",
    "n_workers <- as.integer(Sys.getenv(\"N_WORKERS\", \"0\"))\n",
    "if (n_workers < 1) {\n",
    "  total_cores <- parallel::detectCores()\n",
    "  n_workers <- max(1, total_cores - 2)\n",
    "  cat(sprintf(\"Auto-detected %d cores, using %d workers\\n\", total_cores, n_workers))\n",
    "}\n",
    "\n",
    "cat(sprintf(\"Setting up parallel processing with %d workers...\\n\", n_workers))\n",
    "cat(sprintf(\"Expected speedup: %dx faster than single core\\n\", round(n_workers * 0.8)))\n",
    "\n",
    "# Increase future.globals.maxSize for large MC-CV splits object\n",
    "# With 1TB RAM on EC2, we can handle large transfers\n",
    "options(future.globals.maxSize = 20 * 1024^3)  # 20 GB limit (plenty for 100 splits)\n",
    "cat(\"Set future.globals.maxSize to 20 GB\\n\")\n",
    "\n",
    "plan(multisession, workers = n_workers)\n",
    "\n",
    "# Create output directory\n",
    "output_dir <- here(\"feature_importance\", \"outputs\")\n",
    "dir.create(output_dir, showWarnings = FALSE, recursive = TRUE)\n",
    "\n",
    "cat(\"Output directory:\", output_dir, \"\\n\")\n",
    "cat(sprintf(\"MC-CV Configuration: %d splits, %.0f/%.0f train/test split\\n\", \n",
    "            n_mc_splits, train_prop * 100, (1 - train_prop) * 100))\n",
    "flush.console()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Helper Functions\n",
    "\n",
    "Define functions for data preparation, C-index calculation, and prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare modeling data with leakage prevention\n",
    "prepare_modeling_data <- function(data) {\n",
    "  # Find time and status columns\n",
    "  time_col <- intersect(c(\"time\", \"outcome_int_graft_loss\", \"int_graft_loss\"), names(data))[1]\n",
    "  status_col <- intersect(c(\"status\", \"outcome_graft_loss\", \"graft_loss\"), names(data))[1]\n",
    "  \n",
    "  if (is.na(time_col) || is.na(status_col)) {\n",
    "    stop(\"Cannot find time/status columns\")\n",
    "  }\n",
    "  \n",
    "  # Rename to standard names\n",
    "  if (time_col != \"time\") data <- data %>% rename(time = !!time_col)\n",
    "  if (status_col != \"status\") data <- data %>% rename(status = !!status_col)\n",
    "  \n",
    "  # Exclude leakage variables\n",
    "  exclude_exact <- c(\n",
    "    \"ptid_e\", \"int_dead\", \"int_death\", \"graft_loss\", \"txgloss\", \"death\", \"event\",\n",
    "    \"dpricaus\", \"deathspc\", \"concod\", \"age_death\",\n",
    "    \"patsupp\", \"pmorexam\", \"papooth\", \"pacuref\", \"pishltgr\",\n",
    "    \"pathero\", \"pcadrec\", \"pcadrem\", \"pdiffib\", \"cpathneg\",\n",
    "    \"dcardiac\", \"dneuro\", \"dreject\", \"dsecaccs\", \"dpriaccs\",\n",
    "    \"dconmbld\", \"dconmal\", \"dconcard\", \"dconneur\", \"dconrej\",\n",
    "    \"dmajbld\", \"dmalcanc\"\n",
    "  )\n",
    "  \n",
    "  exclude_prefixes <- c(\"dtx_\", \"cc_\", \"dcon\", \"dpri\", \"dsec\", \"dmaj\", \"sd\")\n",
    "  \n",
    "  exclude_by_prefix <- character(0)\n",
    "  for (prefix in exclude_prefixes) {\n",
    "    exclude_by_prefix <- c(exclude_by_prefix, \n",
    "                           names(data)[startsWith(names(data), prefix)])\n",
    "  }\n",
    "  \n",
    "  exclude_all <- unique(c(exclude_exact, exclude_by_prefix))\n",
    "  data <- data %>% select(-any_of(exclude_all))\n",
    "  \n",
    "  # Median imputation for numeric variables\n",
    "  numeric_vars <- names(data)[sapply(data, is.numeric) & names(data) != \"time\" & names(data) != \"status\"]\n",
    "  for (var in numeric_vars) {\n",
    "    if (any(is.na(data[[var]]))) {\n",
    "      median_val <- median(data[[var]], na.rm = TRUE)\n",
    "      data[[var]][is.na(data[[var]])] <- median_val\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  # Mode imputation for categorical variables\n",
    "  categorical_vars <- names(data)[sapply(data, function(x) is.factor(x) | is.character(x))]\n",
    "  for (var in categorical_vars) {\n",
    "    if (any(is.na(data[[var]]))) {\n",
    "      mode_val <- names(sort(table(data[[var]]), decreasing = TRUE))[1]\n",
    "      data[[var]][is.na(data[[var]])] <- mode_val\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  # Remove constant columns\n",
    "  constant_cols <- names(data)[sapply(data, function(x) length(unique(na.omit(x))) <= 1)]\n",
    "  if (length(constant_cols) > 0) {\n",
    "    data <- data %>% select(-any_of(constant_cols))\n",
    "  }\n",
    "  \n",
    "  # Convert character to factor\n",
    "  data <- data %>% mutate(across(where(is.character), as.factor))\n",
    "  \n",
    "  return(data)\n",
    "}\n",
    "\n",
    "cat(\"âœ“ prepare_modeling_data() defined\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# C-index calculation\n",
    "calculate_cindex <- function(time, status, risk_scores, horizon = NULL) {\n",
    "  valid_idx <- !is.na(time) & !is.na(status) & !is.na(risk_scores) &\n",
    "               is.finite(time) & is.finite(risk_scores) & time > 0\n",
    "  \n",
    "  time   <- as.numeric(time[valid_idx])\n",
    "  status <- as.numeric(status[valid_idx])\n",
    "  risk   <- as.numeric(risk_scores[valid_idx])\n",
    "  \n",
    "  n <- length(time)\n",
    "  events <- sum(status == 1)\n",
    "  \n",
    "  if (n < 10 || events < 1 || length(unique(risk)) == 1) {\n",
    "    return(list(cindex_td = NA_real_, cindex_ti = NA_real_))\n",
    "  }\n",
    "  \n",
    "  # Time-independent C-index (Harrell's)\n",
    "  num_conc_ti <- 0\n",
    "  num_disc_ti <- 0\n",
    "  num_ties_ti <- 0\n",
    "  \n",
    "  for (i in seq_len(n)) {\n",
    "    if (status[i] != 1) next\n",
    "    for (j in seq_len(n)) {\n",
    "      if (i == j) next\n",
    "      if (time[i] < time[j]) {\n",
    "        if (risk[i] > risk[j]) {\n",
    "          num_conc_ti <- num_conc_ti + 1\n",
    "        } else if (risk[i] < risk[j]) {\n",
    "          num_disc_ti <- num_disc_ti + 1\n",
    "        } else {\n",
    "          num_ties_ti <- num_ties_ti + 1\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  denom_ti <- num_conc_ti + num_disc_ti + num_ties_ti\n",
    "  cindex_ti <- if (denom_ti > 0) (num_conc_ti + 0.5 * num_ties_ti) / denom_ti else NA_real_\n",
    "  \n",
    "  # Time-dependent C-index\n",
    "  cindex_td <- tryCatch({\n",
    "    score_data <- data.frame(time = time, status = status)\n",
    "    pred_matrix <- matrix(risk, ncol = 1)\n",
    "    \n",
    "    evaluation <- riskRegression::Score(\n",
    "      object = list(Model = pred_matrix),\n",
    "      formula = Surv(time, status) ~ 1,\n",
    "      data = score_data,\n",
    "      times = if (!is.null(horizon)) horizon else median(time[status == 1]),\n",
    "      summary = \"risks\",\n",
    "      metrics = \"auc\",\n",
    "      se.fit = FALSE\n",
    "    )\n",
    "    \n",
    "    as.numeric(evaluation$AUC$score$AUC[1])\n",
    "  }, error = function(e) cindex_ti)\n",
    "  \n",
    "  return(list(cindex_td = cindex_td, cindex_ti = cindex_ti))\n",
    "}\n",
    "\n",
    "# ranger_predictrisk function\n",
    "ranger_predictrisk <- function(object, newdata, times) {\n",
    "  preds <- predict(object, data = newdata, type = \"response\")\n",
    "  if (is.null(preds$survival)) {\n",
    "    stop(\"ranger prediction did not return survival probabilities\")\n",
    "  }\n",
    "  \n",
    "  surv_matrix <- preds$survival\n",
    "  time_points <- preds$unique.death.times\n",
    "  closest_idx <- which.min(abs(time_points - times))\n",
    "  risk_scores <- 1 - surv_matrix[, closest_idx]\n",
    "  \n",
    "  return(as.numeric(risk_scores))\n",
    "}\n",
    "\n",
    "cat(\"âœ“ calculate_cindex() and ranger_predictrisk() defined\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Monte Carlo Cross-Validation Function\n",
    "\n",
    "Main function that runs MC-CV for a single method and period.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Run MC-CV for a single method and time period\n",
    "run_mc_cv_method <- function(data, method, period_name, mc_splits) {\n",
    "  \n",
    "  cat(sprintf(\"\\n=== Running MC-CV for %s (%s) ===\\n\", method, period_name))\n",
    "  cat(sprintf(\"Splits: %d | Train: %.0f%% | Test: %.0f%%\\n\", \n",
    "              n_mc_splits, train_prop * 100, (1 - train_prop) * 100))\n",
    "  flush.console()\n",
    "  \n",
    "  split_ids <- seq_len(n_mc_splits)\n",
    "  \n",
    "  # Run splits in parallel with progress bar\n",
    "  with_progress({\n",
    "    p <- progressor(steps = n_mc_splits)\n",
    "    \n",
    "    results <- future_map(split_ids, function(split_id) {\n",
    "      p()  # Update progress\n",
    "      \n",
    "      # Get train/test data from split\n",
    "      split <- mc_splits$splits[[split_id]]\n",
    "      train_data <- rsample::analysis(split)\n",
    "      test_data <- rsample::assessment(split)\n",
    "      \n",
    "      # Train and evaluate\n",
    "      model <- NULL\n",
    "      predictions <- NULL\n",
    "      feature_importance <- NULL\n",
    "      \n",
    "      tryCatch({\n",
    "        if (method == \"RSF\") {\n",
    "          model <- ranger(\n",
    "            Surv(time, status) ~ .,\n",
    "            data = train_data,\n",
    "            num.trees = n_trees_rsf,\n",
    "            importance = \"permutation\",\n",
    "            min.node.size = 20,\n",
    "            splitrule = \"extratrees\",\n",
    "            num.random.splits = 10\n",
    "          )\n",
    "          \n",
    "          predictions <- ranger_predictrisk(model, test_data, horizon)\n",
    "          feature_importance <- model$variable.importance\n",
    "          \n",
    "        } else if (method == \"AORSF\") {\n",
    "          # Remove constant columns from training data (can occur after train/test split)\n",
    "          constant_cols <- names(train_data)[sapply(train_data, function(x) {\n",
    "            if (is.numeric(x)) {\n",
    "              length(unique(na.omit(x))) <= 1\n",
    "            } else {\n",
    "              length(unique(na.omit(x))) <= 1\n",
    "            }\n",
    "          })]\n",
    "          constant_cols <- setdiff(constant_cols, c(\"time\", \"status\"))\n",
    "          if (length(constant_cols) > 0) {\n",
    "            train_data <- train_data %>% select(-any_of(constant_cols))\n",
    "            test_data <- test_data %>% select(-any_of(constant_cols))\n",
    "          }\n",
    "          \n",
    "          model <- aorsf::orsf(\n",
    "            data = train_data,\n",
    "            formula = Surv(time, status) ~ .,\n",
    "            n_tree = n_trees_aorsf,\n",
    "            na_action = 'impute_meanmode'\n",
    "          )\n",
    "          \n",
    "          pred_obj <- predict(model, new_data = test_data, \n",
    "                              pred_type = 'risk', pred_horizon = horizon)\n",
    "          predictions <- if (is.matrix(pred_obj)) as.numeric(pred_obj[, 1]) else as.numeric(pred_obj)\n",
    "          feature_importance <- aorsf::orsf_vi_permute(model)\n",
    "          \n",
    "        } else if (method == \"CatBoost\") {\n",
    "          # Remove constant columns from training data (can occur after train/test split)\n",
    "          constant_cols <- names(train_data)[sapply(train_data, function(x) {\n",
    "            if (is.numeric(x)) {\n",
    "              length(unique(na.omit(x))) <= 1\n",
    "            } else {\n",
    "              length(unique(na.omit(x))) <= 1\n",
    "            }\n",
    "          })]\n",
    "          constant_cols <- setdiff(constant_cols, c(\"time\", \"status\"))\n",
    "          if (length(constant_cols) > 0) {\n",
    "            train_data <- train_data %>% select(-any_of(constant_cols))\n",
    "            test_data <- test_data %>% select(-any_of(constant_cols))\n",
    "          }\n",
    "          \n",
    "          train_pool <- catboost.load_pool(\n",
    "            data = train_data %>% select(-time, -status),\n",
    "            label = train_data$time\n",
    "          )\n",
    "          \n",
    "          test_pool <- catboost.load_pool(\n",
    "            data = test_data %>% select(-time, -status)\n",
    "          )\n",
    "          \n",
    "          # CatBoost configuration: single-threaded inside each R worker to avoid\n",
    "          # logger/thread-safety issues, and quiet logging in parallel runs.\n",
    "          params <- list(\n",
    "            loss_function  = 'Cox',\n",
    "            iterations     = 100,\n",
    "            learning_rate  = 0.1,\n",
    "            depth          = 6,\n",
    "            thread_count   = 1,\n",
    "            logging_level  = 'Silent',\n",
    "            verbose        = 0L\n",
    "          )\n",
    "          \n",
    "          model <- catboost.train(train_pool, params = params)\n",
    "          predictions <- catboost.predict(model, test_pool)\n",
    "          \n",
    "          # Get feature importance - CatBoost returns a matrix with rownames as feature names\n",
    "          # IMPORTANT: catboost.get_feature_importance() returns a matrix (not a named vector)\n",
    "          # - Values are in the first column: importance_matrix[, 1]\n",
    "          # - Feature names are in rownames: rownames(importance_matrix)\n",
    "          # Convert to named vector for consistency with RSF and AORSF (which return named vectors directly)\n",
    "          importance_matrix <- catboost.get_feature_importance(model)\n",
    "          feature_importance <- as.numeric(importance_matrix[, 1])\n",
    "          names(feature_importance) <- rownames(importance_matrix)\n",
    "        }\n",
    "        \n",
    "        # Calculate C-index on TEST data\n",
    "        cindex_result <- calculate_cindex(\n",
    "          time = test_data$time,\n",
    "          status = test_data$status,\n",
    "          risk_scores = predictions,\n",
    "          horizon = horizon\n",
    "        )\n",
    "        \n",
    "        return(list(\n",
    "          split_id = split_id,\n",
    "          cindex_td = cindex_result$cindex_td,\n",
    "          cindex_ti = cindex_result$cindex_ti,\n",
    "          feature_importance = feature_importance,\n",
    "          n_train = nrow(train_data),\n",
    "          n_test = nrow(test_data),\n",
    "          success = TRUE\n",
    "        ))\n",
    "        \n",
    "      }, error = function(e) {\n",
    "        return(list(\n",
    "          split_id = split_id,\n",
    "          cindex_td = NA_real_,\n",
    "          cindex_ti = NA_real_,\n",
    "          feature_importance = NULL,\n",
    "          n_train = nrow(train_data),\n",
    "          n_test = nrow(test_data),\n",
    "          success = FALSE,\n",
    "          error = e$message\n",
    "        ))\n",
    "      })\n",
    "    }, .options = furrr_options(\n",
    "      seed = TRUE,\n",
    "      packages = c(\n",
    "        \"dplyr\", \"purrr\", \"tibble\", \"rsample\",\n",
    "        \"ranger\", \"aorsf\", \"catboost\",\n",
    "        \"riskRegression\", \"prodlim\"\n",
    "      )\n",
    "    ))\n",
    "  })\n",
    "  \n",
    "  # Aggregate results\n",
    "  successful_splits <- Filter(function(x) x$success, results)\n",
    "  n_successful <- length(successful_splits)\n",
    "  \n",
    "  cat(sprintf(\"Successful splits: %d / %d\\n\", n_successful, n_mc_splits))\n",
    "  flush.console()\n",
    "  \n",
    "  # If all splits failed (e.g., CatBoost configuration/data issue),\n",
    "  # do not stop the whole analysis. Instead, log a warning and return\n",
    "  # an empty/NA summary so that other methods and periods can continue.\n",
    "  if (n_successful == 0) {\n",
    "    error_splits <- Filter(function(x) !is.null(x$error), results)\n",
    "    if (length(error_splits) > 0) {\n",
    "      first_error <- error_splits[[1]]$error\n",
    "      cat(sprintf(\"WARNING: example error for %s (%s): %s\\n\",\n",
    "                  method, period_name, first_error))\n",
    "    }\n",
    "    cat(sprintf(\"WARNING: All MC-CV splits failed for %s (%s). Skipping this method.\\n\",\n",
    "                method, period_name))\n",
    "    flush.console()\n",
    "    \n",
    "    return(list(\n",
    "      method = method,\n",
    "      period = period_name,\n",
    "      n_splits = n_mc_splits,\n",
    "      n_successful = 0,\n",
    "      cindex_td_mean = NA_real_,\n",
    "      cindex_td_sd = NA_real_,\n",
    "      cindex_td_ci_lower = NA_real_,\n",
    "      cindex_td_ci_upper = NA_real_,\n",
    "      cindex_ti_mean = NA_real_,\n",
    "      cindex_ti_sd = NA_real_,\n",
    "      cindex_ti_ci_lower = NA_real_,\n",
    "      cindex_ti_ci_upper = NA_real_,\n",
    "      top_features = numeric(0)\n",
    "    ))\n",
    "  }\n",
    "  \n",
    "  # Extract C-indexes\n",
    "  cindex_td_values <- sapply(successful_splits, function(x) x$cindex_td)\n",
    "  cindex_ti_values <- sapply(successful_splits, function(x) x$cindex_ti)\n",
    "  \n",
    "  cindex_td_values <- cindex_td_values[!is.na(cindex_td_values)]\n",
    "  cindex_ti_values <- cindex_ti_values[!is.na(cindex_ti_values)]\n",
    "  \n",
    "  # Aggregate feature importance\n",
    "  # All methods (RSF, AORSF, CatBoost) return named numeric vectors\n",
    "  all_feature_names <- unique(unlist(lapply(successful_splits, function(x) {\n",
    "    if (is.null(x$feature_importance)) return(NULL)\n",
    "    names(x$feature_importance)\n",
    "  })))\n",
    "  \n",
    "  aggregated_importance <- sapply(all_feature_names, function(feature) {\n",
    "    importances <- sapply(successful_splits, function(x) {\n",
    "      if (is.null(x$feature_importance)) return(NA_real_)\n",
    "      if (feature %in% names(x$feature_importance)) {\n",
    "        return(as.numeric(x$feature_importance[feature]))\n",
    "      }\n",
    "      return(NA_real_)\n",
    "    })\n",
    "    mean(importances, na.rm = TRUE)\n",
    "  })\n",
    "  \n",
    "  # Ensure aggregated_importance is a numeric vector\n",
    "  aggregated_importance <- as.numeric(aggregated_importance)\n",
    "  names(aggregated_importance) <- all_feature_names\n",
    "  \n",
    "  top_features <- sort(aggregated_importance, decreasing = TRUE)[1:min(n_predictors, length(aggregated_importance))]\n",
    "  \n",
    "  # Calculate statistics\n",
    "  results_summary <- list(\n",
    "    method = method,\n",
    "    period = period_name,\n",
    "    n_splits = n_mc_splits,\n",
    "    n_successful = n_successful,\n",
    "    cindex_td_mean = mean(cindex_td_values, na.rm = TRUE),\n",
    "    cindex_td_sd = sd(cindex_td_values, na.rm = TRUE),\n",
    "    cindex_td_ci_lower = quantile(cindex_td_values, 0.025, na.rm = TRUE),\n",
    "    cindex_td_ci_upper = quantile(cindex_td_values, 0.975, na.rm = TRUE),\n",
    "    cindex_ti_mean = mean(cindex_ti_values, na.rm = TRUE),\n",
    "    cindex_ti_sd = sd(cindex_ti_values, na.rm = TRUE),\n",
    "    cindex_ti_ci_lower = quantile(cindex_ti_values, 0.025, na.rm = TRUE),\n",
    "    cindex_ti_ci_upper = quantile(cindex_ti_values, 0.975, na.rm = TRUE),\n",
    "    top_features = top_features\n",
    "  )\n",
    "  \n",
    "  # Print summary\n",
    "  cat(sprintf(\"\\n--- Results for %s (%s) ---\\n\", method, period_name))\n",
    "  cat(sprintf(\"Time-Dependent C-Index: %.4f Â± %.4f (95%% CI: %.4f - %.4f)\\n\",\n",
    "              results_summary$cindex_td_mean,\n",
    "              results_summary$cindex_td_sd,\n",
    "              results_summary$cindex_td_ci_lower,\n",
    "              results_summary$cindex_td_ci_upper))\n",
    "  cat(sprintf(\"Time-Independent C-Index: %.4f Â± %.4f (95%% CI: %.4f - %.4f)\\n\",\n",
    "              results_summary$cindex_ti_mean,\n",
    "              results_summary$cindex_ti_sd,\n",
    "              results_summary$cindex_ti_ci_lower,\n",
    "              results_summary$cindex_ti_ci_upper))\n",
    "  cat(sprintf(\"Top 5 features: %s\\n\", paste(names(top_features)[1:min(5, length(top_features))], collapse = \", \")))\n",
    "  flush.console()\n",
    "  \n",
    "  return(results_summary)\n",
    "}\n",
    "\n",
    "cat(\"âœ“ run_mc_cv_method() defined\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Find and load SAS file\n",
    "sas_path_local <- here(\"data\", \"phts_txpl_ml.sas7bdat\")\n",
    "sas_path_external <- here(\"graft-loss-parallel-processing\", \"data\", \"phts_txpl_ml.sas7bdat\")\n",
    "sas_path_graft_loss <- here(\"graft-loss\", \"data\", \"phts_txpl_ml.sas7bdat\")\n",
    "\n",
    "sas_path <- NULL\n",
    "for (path in c(sas_path_local, sas_path_external, sas_path_graft_loss)) {\n",
    "  if (file.exists(path)) {\n",
    "    sas_path <- path\n",
    "    break\n",
    "  }\n",
    "}\n",
    "\n",
    "if (is.null(sas_path)) {\n",
    "  stop(\"Cannot find phts_txpl_ml.sas7bdat in any location\")\n",
    "}\n",
    "\n",
    "cat(\"Loading data from:\", sas_path, \"\\n\")\n",
    "\n",
    "# Load data\n",
    "phts_base <- haven::read_sas(sas_path) %>%\n",
    "  filter(TXPL_YEAR >= 2010) %>%\n",
    "  janitor::clean_names() %>%\n",
    "  rename(\n",
    "    outcome_int_graft_loss = int_graft_loss,\n",
    "    outcome_graft_loss = graft_loss\n",
    "  ) %>%\n",
    "  mutate(\n",
    "    ID = 1:n(),\n",
    "    across(.cols = where(is.character), ~ ifelse(.x %in% c(\"\", \"unknown\", \"missing\"), NA_character_, .x)),\n",
    "    across(.cols = where(is.character), as.factor),\n",
    "    tx_mcsd = if ('txnomcsd' %in% names(.)) {\n",
    "      if_else(txnomcsd == 'yes', 0, 1)\n",
    "    } else if ('txmcsd' %in% names(.)) {\n",
    "      txmcsd\n",
    "    } else {\n",
    "      NA_real_\n",
    "    }\n",
    "  )\n",
    "\n",
    "cat(sprintf(\"âœ“ Loaded data: %d rows, %d columns\\n\", nrow(phts_base), ncol(phts_base)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Define time periods\n",
    "periods <- list()\n",
    "periods$original <- phts_base %>% filter(txpl_year >= 2010 & txpl_year <= 2019)\n",
    "periods$full <- phts_base %>% filter(txpl_year >= 2010)\n",
    "periods$full_no_covid <- phts_base %>% filter(txpl_year >= 2010 & !(txpl_year >= 2020 & txpl_year <= 2023))\n",
    "\n",
    "# Print summary\n",
    "for (period_name in names(periods)) {\n",
    "  period_data <- periods[[period_name]]\n",
    "  n_events <- sum(period_data$outcome_graft_loss, na.rm = TRUE)\n",
    "  event_rate <- 100 * n_events / nrow(period_data)\n",
    "  \n",
    "  cat(sprintf(\"Period: %s | N: %d | Events: %d (%.2f%%)\\n\", \n",
    "              period_name, nrow(period_data), n_events, event_rate))\n",
    "}\n",
    "\n",
    "cat(\"\\nâœ“ Time periods defined\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run Analysis\n",
    "\n",
    "Execute MC-CV for all methods and periods.\n",
    "\n",
    "- **100 splits (default full run):** Typically ~1â€“2 hours on a 32-core EC2 instance, longer on smaller machines.\n",
    "- **1000 splits (extended run):** Linearly more expensive; expect roughly 8â€“10Ã— the 100-split time.\n",
    "\n",
    "**Note:** You can run each period separately by uncommenting only one `period_name` at a time, or reduce the number of methods/periods to shorten runtime further.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Select periods and methods to run\n",
    "# In DEBUG_MODE, only run original period for speed\n",
    "period_names <- if (DEBUG_MODE) {\n",
    "  c(\"original\")  # Debug: just one period (~2-5 min)\n",
    "} else {\n",
    "  c(\"original\", \"full\", \"full_no_covid\")  # Full: all periods (~30-45 min)\n",
    "}\n",
    "\n",
    "# Methods to run. Include CatBoost (with single-threaded, quiet config)\n",
    "# alongside RSF and AORSF.\n",
    "method_names <- c(\"RSF\", \"CatBoost\", \"AORSF\")\n",
    "\n",
    "# Store all results\n",
    "all_results <- list()\n",
    "\n",
    "# Run analysis\n",
    "for (period_name in period_names) {\n",
    "  cat(sprintf(\"\\n========================================\\n\"))\n",
    "  cat(sprintf(\"Processing Period: %s\\n\", period_name))\n",
    "  cat(sprintf(\"========================================\\n\"))\n",
    "  flush.console()\n",
    "  \n",
    "  # Prepare data\n",
    "  period_data <- prepare_modeling_data(periods[[period_name]])\n",
    "  \n",
    "  cat(sprintf(\"Period data: %d rows, %d columns\\n\", nrow(period_data), ncol(period_data)))\n",
    "  cat(sprintf(\"Events: %d (%.2f%%)\\n\", sum(period_data$status), \n",
    "              100 * sum(period_data$status) / nrow(period_data)))\n",
    "  \n",
    "  # Create MC-CV splits (stratified by outcome)\n",
    "  cat(sprintf(\"Creating %d MC-CV splits (stratified)...\\n\", n_mc_splits))\n",
    "  flush.console()\n",
    "  mc_splits <- mc_cv(\n",
    "    data = period_data,\n",
    "    prop = train_prop,\n",
    "    times = n_mc_splits,\n",
    "    strata = status\n",
    "  )\n",
    "  \n",
    "  # Run each method\n",
    "  period_results <- list()\n",
    "  \n",
    "  for (method in method_names) {\n",
    "    result <- run_mc_cv_method(period_data, method, period_name, mc_splits)\n",
    "    period_results[[method]] <- result\n",
    "    \n",
    "    # Save top features\n",
    "    top_features_df <- tibble(\n",
    "      feature = names(result$top_features),\n",
    "      importance = as.numeric(result$top_features),\n",
    "      cindex_td = result$cindex_td_mean,\n",
    "      cindex_ti = result$cindex_ti_mean\n",
    "    )\n",
    "    \n",
    "    output_file <- file.path(output_dir, sprintf(\"%s_%s_top20.csv\", \n",
    "                                                  period_name, tolower(method)))\n",
    "    write_csv(top_features_df, output_file)\n",
    "    cat(sprintf(\"âœ“ Saved: %s\\n\", basename(output_file)))\n",
    "  }\n",
    "  \n",
    "  all_results[[period_name]] <- period_results\n",
    "}\n",
    "\n",
    "cat(\"\\nâœ“ Analysis complete for all periods!\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Summary Results\n",
    "\n",
    "Create summary tables with C-index comparisons and statistics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Create C-index comparison table\n",
    "cindex_comparison <- map_df(period_names, function(period) {\n",
    "  map_df(method_names, function(method) {\n",
    "    result <- all_results[[period]][[method]]\n",
    "    tibble(\n",
    "      period = period,\n",
    "      method = method,\n",
    "      cindex_td_mean = result$cindex_td_mean,\n",
    "      cindex_td_sd = result$cindex_td_sd,\n",
    "      cindex_td_ci_lower = result$cindex_td_ci_lower,\n",
    "      cindex_td_ci_upper = result$cindex_td_ci_upper,\n",
    "      cindex_ti_mean = result$cindex_ti_mean,\n",
    "      cindex_ti_sd = result$cindex_ti_sd,\n",
    "      cindex_ti_ci_lower = result$cindex_ti_ci_lower,\n",
    "      cindex_ti_ci_upper = result$cindex_ti_ci_upper,\n",
    "      n_splits = result$n_successful\n",
    "    )\n",
    "  })\n",
    "})\n",
    "\n",
    "write_csv(cindex_comparison, file.path(output_dir, \"cindex_comparison_mc_cv.csv\"))\n",
    "cat(\"âœ“ Saved: cindex_comparison_mc_cv.csv\\n\")\n",
    "\n",
    "# Display the table\n",
    "print(cindex_comparison)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Create summary statistics\n",
    "summary_stats <- map_df(period_names, function(period) {\n",
    "  period_data <- periods[[period]]\n",
    "  tibble(\n",
    "    period = period,\n",
    "    n_patients = nrow(period_data),\n",
    "    n_events = sum(period_data$outcome_graft_loss, na.rm = TRUE),\n",
    "    event_rate = 100 * sum(period_data$outcome_graft_loss, na.rm = TRUE) / nrow(period_data)\n",
    "  )\n",
    "})\n",
    "\n",
    "write_csv(summary_stats, file.path(output_dir, \"summary_statistics_mc_cv.csv\"))\n",
    "cat(\"âœ“ Saved: summary_statistics_mc_cv.csv\\n\")\n",
    "\n",
    "# Display the table\n",
    "print(summary_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Close parallel processing\n",
    "plan(sequential)\n",
    "\n",
    "cat(\"\\n========================================\\n\")\n",
    "cat(\"Analysis Complete!\\n\")\n",
    "cat(\"========================================\\n\")\n",
    "cat(sprintf(\"Output directory: %s\\n\", output_dir))\n",
    "cat(sprintf(\"MC-CV splits: %d\\n\", n_mc_splits))\n",
    "cat(sprintf(\"Train/Test ratio: %.0f/%.0f\\n\", train_prop * 100, (1 - train_prop) * 100))\n",
    "cat(\"\\nResults show C-indexes with 95% confidence intervals\\n\")\n",
    "cat(\"based on\", n_mc_splits, \"independent train/test splits.\\n\\n\")\n",
    "cat(\"âœ“ All files saved successfully!\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Sync Results and Code to S3\n",
    "\n",
    "Sync output files and code (notebook + R script) to S3 bucket. \n",
    "- Outputs: CSV results files\n",
    "- Code: Notebook and R script for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Sync outputs and code to S3\n",
    "# On EC2, we're in the feature_importance directory\n",
    "s3_bucket <- \"s3://uva-private-data-lake/graft-loss/feature_importance/\"\n",
    "\n",
    "# Find AWS CLI (check common locations - EC2 typically has it in /usr/local/bin or /usr/bin)\n",
    "aws_cmd <- Sys.which(\"aws\")\n",
    "if (aws_cmd == \"\") {\n",
    "  # Try common EC2 installation paths\n",
    "  aws_paths <- c(\n",
    "    \"/usr/local/bin/aws\",\n",
    "    \"/usr/bin/aws\",\n",
    "    \"/home/ec2-user/.local/bin/aws\"\n",
    "  )\n",
    "  aws_cmd <- NULL\n",
    "  for (path in aws_paths) {\n",
    "    if (file.exists(path)) {\n",
    "      aws_cmd <- path\n",
    "      break\n",
    "    }\n",
    "  }\n",
    "  if (is.null(aws_cmd)) {\n",
    "    stop(\"AWS CLI not found. Please install AWS CLI or ensure it's in your PATH.\")\n",
    "  }\n",
    "}\n",
    "\n",
    "cat(\"Syncing outputs and code to S3...\\n\")\n",
    "cat(\"Source: feature_importance/ directory\\n\")\n",
    "cat(\"Destination:\", s3_bucket, \"\\n\")\n",
    "cat(\"AWS CLI:\", aws_cmd, \"\\n\\n\")\n",
    "\n",
    "# Get current directory (should be feature_importance)\n",
    "current_dir <- getwd()\n",
    "if (!grepl(\"feature_importance\", current_dir)) {\n",
    "  warning(\"Current directory doesn't appear to be feature_importance. Double-check sync destination.\")\n",
    "}\n",
    "\n",
    "# Sync feature_importance directory (includes outputs/ and code files)\n",
    "# Exclude temporary files, checkpoints, and unnecessary directories\n",
    "# Note: --delete flag removed for safety (won't delete files in S3 that don't exist locally)\n",
    "# This will sync: outputs/*, *.ipynb, *.R, README*.md (and exclude everything else unwanted)\n",
    "sync_cmd <- sprintf(\n",
    "  '\"%s\" s3 sync \"%s\" %s --exclude \"*checkpoint*\" --exclude \"*.tmp\" --exclude \"*.ipynb_checkpoints/*\" --exclude \"*.RData\" --exclude \"*.Rhistory\" --exclude \".Rproj.user/*\" --exclude \"catboost_info/*\" --exclude \"*.log\"',\n",
    "  aws_cmd,\n",
    "  current_dir,\n",
    "  s3_bucket\n",
    ")\n",
    "\n",
    "cat(\"Running:\", sync_cmd, \"\\n\\n\")\n",
    "result <- system(sync_cmd)\n",
    "\n",
    "if (result == 0) {\n",
    "  cat(\"âœ“ Successfully synced outputs and code to S3\\n\")\n",
    "  cat(\"  - Outputs:\", file.path(output_dir), \"\\n\")\n",
    "  cat(\"  - Code: *.ipynb, *.R, README*.md\\n\")\n",
    "} else {\n",
    "  warning(sprintf(\"S3 sync returned exit code %d. Check AWS credentials and permissions.\", result))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R (PGX-Analysis)",
   "language": "R",
   "name": "pgx-analysis"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
