{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graft Loss Feature Importance with Monte Carlo Cross-Validation\n",
    "\n",
    "**Study Replication:** Publication-quality replication with Monte Carlo cross-validation (configurable 100â€“1000 splits)  \n",
    "**Updated:** November 21, 2025  \n",
    "**Hardware:** Optimized for 32-core EC2 instance (1TB RAM)  \n",
    "**Validation:** Proper evaluation on unseen test data\n",
    "\n",
    "## Key Changes from Original\n",
    "\n",
    "âœ… **Monte Carlo Cross-Validation** â€“ up to 1000 random 75/25 train/test splits (100-split runs used for faster iteration)  \n",
    "âœ… **Stratified Sampling** - Maintains event distribution  \n",
    "âœ… **Parallel Processing** - Fast execution with furrr/future (â‰ˆ30 workers)  \n",
    "âœ… **95% Confidence Intervals** - Narrow, precise estimates (tighter with more splits)  \n",
    "âœ… **Realistic C-Indexes** - Expected range 0.70-0.85\n",
    "\n",
    "## Methodology\n",
    "\n",
    "This notebook implements the feature selection methodology from the original bcjaeger/graft-loss study:\n",
    "\n",
    "1. Load data for pediatric heart transplant outcomes\n",
    "2. Define three time periods:\n",
    "   - **Original**: 2010-2019 (matches publication)\n",
    "   - **Full**: 2010-2024 (all available data)\n",
    "   - **Full No COVID**: 2010-2024 excluding 2020-2023\n",
    "3. For each period and method:\n",
    "   - Create 100â€“1000 stratified train/test splits (75/25)\n",
    "   - Train model on training set\n",
    "   - Evaluate on unseen test set\n",
    "   - Aggregate results across splits\n",
    "4. Calculate C-index with 95% CI\n",
    "5. Extract top 20 features\n",
    "\n",
    "## Expected Runtime (per full 3-period Ã— 3-method run)\n",
    "\n",
    "- **100 splits (current default):**\n",
    "  - Local (4 cores): ~2â€“4 hours (NOT RECOMMENDED)\n",
    "  - Workstation (16 cores): ~1â€“2 hours\n",
    "  - EC2 (32 cores, 1TB RAM): ~1â€“2 hours âœ… **RECOMMENDED FOR DEVELOPMENT**\n",
    "- **1000 splits (extended / publication-level):**\n",
    "  - Local (4 cores): 8â€“12+ hours (NOT RECOMMENDED)\n",
    "  - Workstation (16 cores): ~8â€“16 hours\n",
    "  - EC2 (32 cores, 1TB RAM): ~10â€“20 hours âœ… **RECOMMENDED FOR FINAL RESULTS**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration\n",
    "\n",
    "Load required packages and configure parallel processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'R version 4.4.3 (2025-02-28)'"
      ],
      "text/latex": [
       "'R version 4.4.3 (2025-02-28)'"
      ],
      "text/markdown": [
       "'R version 4.4.3 (2025-02-28)'"
      ],
      "text/plain": [
       "[1] \"R version 4.4.3 (2025-02-28)\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "here() starts at /home/pgx3874/graft-loss\n",
      "\n",
      "\n",
      "Attaching package: â€˜dplyrâ€™\n",
      "\n",
      "\n",
      "The following objects are masked from â€˜package:statsâ€™:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "The following objects are masked from â€˜package:baseâ€™:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: â€˜janitorâ€™\n",
      "\n",
      "\n",
      "The following objects are masked from â€˜package:statsâ€™:\n",
      "\n",
      "    chisq.test, fisher.test\n",
      "\n",
      "\n",
      "riskRegression version 2025.09.17\n",
      "\n",
      "Loading required package: future\n",
      "\n",
      "\n",
      "Attaching package: â€˜futureâ€™\n",
      "\n",
      "\n",
      "The following object is masked from â€˜package:survivalâ€™:\n",
      "\n",
      "    cluster\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ All packages loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Check R version\n",
    "R.version.string\n",
    "\n",
    "# Load required packages\n",
    "library(here)\n",
    "library(dplyr)\n",
    "library(readr)\n",
    "library(survival)\n",
    "library(ranger)\n",
    "library(aorsf)\n",
    "library(catboost)\n",
    "library(tidyr)\n",
    "library(purrr)\n",
    "library(tibble)\n",
    "library(janitor)\n",
    "library(haven)\n",
    "library(riskRegression)\n",
    "library(prodlim)\n",
    "library(rsample)    # For MC-CV\n",
    "library(furrr)      # For parallel processing\n",
    "library(future)     # For parallel backend\n",
    "library(progressr)  # For progress bars\n",
    "\n",
    "cat(\"âœ“ All packages loaded successfully\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-detected 32 cores, using 30 workers\n",
      "Setting up parallel processing with 30 workers...\n",
      "Expected speedup: 24x faster than single core\n",
      "Set future.globals.maxSize to 20 GB\n",
      "Output directory: /home/pgx3874/graft-loss/feature_importance/outputs \n",
      "MC-CV Configuration: 100 splits, 75/25 train/test split\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# DEBUG/TEST MODE - Quick testing before full 100-split run\n",
    "# ============================================================\n",
    "# Set DEBUG_MODE = TRUE for quick testing (5 splits, ~2-5 min)\n",
    "# Set DEBUG_MODE = FALSE for full analysis (100 splits, ~1-2 hours on EC2)\n",
    "\n",
    "DEBUG_MODE <- FALSE  # Change to TRUE for quick test\n",
    "\n",
    "if (DEBUG_MODE) {\n",
    "  cat(\"\\n\")\n",
    "  cat(\"â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\\n\")\n",
    "  cat(\"â•‘                    ðŸ” DEBUG MODE ENABLED                       â•‘\\n\")\n",
    "  cat(\"â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\")\n",
    "  cat(\"\\n\")\n",
    "  cat(\"Quick test configuration:\\n\")\n",
    "  cat(\"  â€¢ MC-CV Splits: 5 (instead of 100)\\n\")\n",
    "  cat(\"  â€¢ Period: Original only (2010-2019)\\n\")\n",
    "  cat(\"  â€¢ Trees: Reduced (RSF: 100, AORSF: 50)\\n\")\n",
    "  cat(\"  â€¢ Expected time: 2-5 minutes\\n\")\n",
    "  cat(\"  â€¢ Purpose: Verify everything works before full run\\n\")\n",
    "  cat(\"\\n\")\n",
    "  cat(\"To run full analysis, set DEBUG_MODE = FALSE\\n\")\n",
    "  cat(\"\\n\")\n",
    "}\n",
    "\n",
    "# Configuration\n",
    "n_predictors <- 20                                        # Top 20 features\n",
    "n_trees_rsf <- if (DEBUG_MODE) 100 else 500              # RSF trees (reduced in debug)\n",
    "n_trees_aorsf <- if (DEBUG_MODE) 50 else 100             # AORSF trees (reduced in debug)\n",
    "horizon <- 1                                              # 1-year prediction\n",
    "n_mc_splits <- if (DEBUG_MODE) 5 else 100                # MC-CV splits (5 for debug, 100 for full)\n",
    "train_prop <- 0.75                                        # 75% training, 25% testing\n",
    "\n",
    "# Set up parallel processing - EC2 Optimized (32 cores, 1TB RAM)\n",
    "# Use 30 out of 32 cores (leave 2 for system)\n",
    "n_workers <- as.integer(Sys.getenv(\"N_WORKERS\", \"0\"))\n",
    "if (n_workers < 1) {\n",
    "  total_cores <- parallel::detectCores()\n",
    "  n_workers <- max(1, total_cores - 2)\n",
    "  cat(sprintf(\"Auto-detected %d cores, using %d workers\\n\", total_cores, n_workers))\n",
    "}\n",
    "\n",
    "cat(sprintf(\"Setting up parallel processing with %d workers...\\n\", n_workers))\n",
    "cat(sprintf(\"Expected speedup: %dx faster than single core\\n\", round(n_workers * 0.8)))\n",
    "\n",
    "# Increase future.globals.maxSize for large MC-CV splits object\n",
    "# With 1TB RAM on EC2, we can handle large transfers\n",
    "options(future.globals.maxSize = 20 * 1024^3)  # 20 GB limit (plenty for 100 splits)\n",
    "cat(\"Set future.globals.maxSize to 20 GB\\n\")\n",
    "\n",
    "plan(multisession, workers = n_workers)\n",
    "\n",
    "# Create output directory\n",
    "output_dir <- here(\"feature_importance\", \"outputs\")\n",
    "dir.create(output_dir, showWarnings = FALSE, recursive = TRUE)\n",
    "\n",
    "cat(\"Output directory:\", output_dir, \"\\n\")\n",
    "cat(sprintf(\"MC-CV Configuration: %d splits, %.0f/%.0f train/test split\\n\", \n",
    "            n_mc_splits, train_prop * 100, (1 - train_prop) * 100))\n",
    "flush.console()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Helper Functions\n",
    "\n",
    "Define functions for data preparation, C-index calculation, and prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ prepare_modeling_data() defined\n"
     ]
    }
   ],
   "source": [
    "# Prepare modeling data with leakage prevention\n",
    "prepare_modeling_data <- function(data) {\n",
    "  # Find time and status columns\n",
    "  time_col <- intersect(c(\"time\", \"outcome_int_graft_loss\", \"int_graft_loss\"), names(data))[1]\n",
    "  status_col <- intersect(c(\"status\", \"outcome_graft_loss\", \"graft_loss\"), names(data))[1]\n",
    "  \n",
    "  if (is.na(time_col) || is.na(status_col)) {\n",
    "    stop(\"Cannot find time/status columns\")\n",
    "  }\n",
    "  \n",
    "  # Rename to standard names\n",
    "  if (time_col != \"time\") data <- data %>% rename(time = !!time_col)\n",
    "  if (status_col != \"status\") data <- data %>% rename(status = !!status_col)\n",
    "  \n",
    "  # Exclude leakage variables and identifier columns\n",
    "  exclude_exact <- c(\n",
    "    \"ID\", \"ptid_e\", \"int_dead\", \"int_death\", \"graft_loss\", \"txgloss\", \"death\", \"event\",\n",
    "    \"dpricaus\", \"deathspc\", \"concod\", \"age_death\", \"dlist\", \"txpl_year\",\n",
    "    \"rrace_b\", \"rrace_a\", \"rrace_ai\", \"rrace_pi\", \"rrace_o\", \"rrace_un\", \"race\",\n",
    "    \"patsupp\", \"pmorexam\", \"papooth\", \"pacuref\", \"pishltgr\",\n",
    "    \"pathero\", \"pcadrec\", \"pcadrem\", \"pdiffib\", \"cpathneg\",\n",
    "    \"dcardiac\", \"dneuro\", \"dreject\", \"dsecaccs\", \"dpriaccs\",\n",
    "    \"dconmbld\", \"dconmal\", \"dconcard\", \"dconneur\", \"dconrej\",\n",
    "    \"dmajbld\", \"dmalcanc\"\n",
    "  )\n",
    "  \n",
    "  exclude_prefixes <- c(\"dtx_\", \"cc_\", \"dcon\", \"dpri\", \"dsec\", \"dmaj\", \"sd\")\n",
    "  \n",
    "  exclude_by_prefix <- character(0)\n",
    "  for (prefix in exclude_prefixes) {\n",
    "    exclude_by_prefix <- c(exclude_by_prefix, \n",
    "                           names(data)[startsWith(names(data), prefix)])\n",
    "  }\n",
    "  \n",
    "  exclude_all <- unique(c(exclude_exact, exclude_by_prefix))\n",
    "  data <- data %>% select(-any_of(exclude_all))\n",
    "  \n",
    "  # Median imputation for numeric variables\n",
    "  numeric_vars <- names(data)[sapply(data, is.numeric) & names(data) != \"time\" & names(data) != \"status\"]\n",
    "  for (var in numeric_vars) {\n",
    "    if (any(is.na(data[[var]]))) {\n",
    "      median_val <- median(data[[var]], na.rm = TRUE)\n",
    "      data[[var]][is.na(data[[var]])] <- median_val\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  # Mode imputation for categorical variables\n",
    "  categorical_vars <- names(data)[sapply(data, function(x) is.factor(x) | is.character(x))]\n",
    "  for (var in categorical_vars) {\n",
    "    if (any(is.na(data[[var]]))) {\n",
    "      mode_val <- names(sort(table(data[[var]]), decreasing = TRUE))[1]\n",
    "      data[[var]][is.na(data[[var]])] <- mode_val\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  # Remove constant columns\n",
    "  constant_cols <- names(data)[sapply(data, function(x) length(unique(na.omit(x))) <= 1)]\n",
    "  if (length(constant_cols) > 0) {\n",
    "    data <- data %>% select(-any_of(constant_cols))\n",
    "  }\n",
    "  \n",
    "  # Convert character to factor\n",
    "  data <- data %>% mutate(across(where(is.character), as.factor))\n",
    "  \n",
    "  return(data)\n",
    "}\n",
    "\n",
    "cat(\"âœ“ prepare_modeling_data() defined\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ calculate_cindex() and ranger_predictrisk() defined\n"
     ]
    }
   ],
   "source": [
    "# C-index calculation\n",
    "calculate_cindex <- function(time, status, risk_scores, horizon = NULL) {\n",
    "  valid_idx <- !is.na(time) & !is.na(status) & !is.na(risk_scores) &\n",
    "               is.finite(time) & is.finite(risk_scores) & time > 0\n",
    "  \n",
    "  time   <- as.numeric(time[valid_idx])\n",
    "  status <- as.numeric(status[valid_idx])\n",
    "  risk   <- as.numeric(risk_scores[valid_idx])\n",
    "  \n",
    "  n <- length(time)\n",
    "  events <- sum(status == 1)\n",
    "  \n",
    "  if (n < 10 || events < 1 || length(unique(risk)) == 1) {\n",
    "    return(list(cindex_td = NA_real_, cindex_ti = NA_real_))\n",
    "  }\n",
    "  \n",
    "  # Time-independent C-index (Harrell's)\n",
    "  num_conc_ti <- 0\n",
    "  num_disc_ti <- 0\n",
    "  num_ties_ti <- 0\n",
    "  \n",
    "  for (i in seq_len(n)) {\n",
    "    if (status[i] != 1) next\n",
    "    for (j in seq_len(n)) {\n",
    "      if (i == j) next\n",
    "      if (time[i] < time[j]) {\n",
    "        if (risk[i] > risk[j]) {\n",
    "          num_conc_ti <- num_conc_ti + 1\n",
    "        } else if (risk[i] < risk[j]) {\n",
    "          num_disc_ti <- num_disc_ti + 1\n",
    "        } else {\n",
    "          num_ties_ti <- num_ties_ti + 1\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  denom_ti <- num_conc_ti + num_disc_ti + num_ties_ti\n",
    "  cindex_ti <- if (denom_ti > 0) (num_conc_ti + 0.5 * num_ties_ti) / denom_ti else NA_real_\n",
    "  \n",
    "  # Time-dependent C-index\n",
    "  cindex_td <- tryCatch({\n",
    "    score_data <- data.frame(time = time, status = status)\n",
    "    pred_matrix <- matrix(risk, ncol = 1)\n",
    "    \n",
    "    evaluation <- riskRegression::Score(\n",
    "      object = list(Model = pred_matrix),\n",
    "      formula = Surv(time, status) ~ 1,\n",
    "      data = score_data,\n",
    "      times = if (!is.null(horizon)) horizon else median(time[status == 1]),\n",
    "      summary = \"risks\",\n",
    "      metrics = \"auc\",\n",
    "      se.fit = FALSE\n",
    "    )\n",
    "    \n",
    "    as.numeric(evaluation$AUC$score$AUC[1])\n",
    "  }, error = function(e) cindex_ti)\n",
    "  \n",
    "  return(list(cindex_td = cindex_td, cindex_ti = cindex_ti))\n",
    "}\n",
    "\n",
    "# ranger_predictrisk function\n",
    "ranger_predictrisk <- function(object, newdata, times) {\n",
    "  preds <- predict(object, data = newdata, type = \"response\")\n",
    "  if (is.null(preds$survival)) {\n",
    "    stop(\"ranger prediction did not return survival probabilities\")\n",
    "  }\n",
    "  \n",
    "  surv_matrix <- preds$survival\n",
    "  time_points <- preds$unique.death.times\n",
    "  closest_idx <- which.min(abs(time_points - times))\n",
    "  risk_scores <- 1 - surv_matrix[, closest_idx]\n",
    "  \n",
    "  return(as.numeric(risk_scores))\n",
    "}\n",
    "\n",
    "cat(\"âœ“ calculate_cindex() and ranger_predictrisk() defined\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Monte Carlo Cross-Validation Function\n",
    "\n",
    "Main function that runs MC-CV for a single method and period.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ run_mc_cv_method() defined\n"
     ]
    }
   ],
   "source": [
    "# Run MC-CV for a single method and time period\n",
    "run_mc_cv_method <- function(data, method, period_name, mc_splits) {\n",
    "  \n",
    "  cat(sprintf(\"\\n=== Running MC-CV for %s (%s) ===\\n\", method, period_name))\n",
    "  cat(sprintf(\"Splits: %d | Train: %.0f%% | Test: %.0f%%\\n\", \n",
    "              n_mc_splits, train_prop * 100, (1 - train_prop) * 100))\n",
    "  flush.console()\n",
    "  \n",
    "  split_ids <- seq_len(n_mc_splits)\n",
    "  \n",
    "  # Run splits in parallel with progress bar\n",
    "  with_progress({\n",
    "    p <- progressor(steps = n_mc_splits)\n",
    "    \n",
    "    results <- future_map(split_ids, function(split_id) {\n",
    "      p()  # Update progress\n",
    "      \n",
    "      # Get train/test data from split\n",
    "      split <- mc_splits$splits[[split_id]]\n",
    "      train_data <- rsample::analysis(split)\n",
    "      test_data <- rsample::assessment(split)\n",
    "      \n",
    "      # Train and evaluate\n",
    "      model <- NULL\n",
    "      predictions <- NULL\n",
    "      feature_importance <- NULL\n",
    "      \n",
    "      tryCatch({\n",
    "        if (method == \"RSF\") {\n",
    "          model <- ranger(\n",
    "            Surv(time, status) ~ .,\n",
    "            data = train_data,\n",
    "            num.trees = n_trees_rsf,\n",
    "            importance = \"permutation\",\n",
    "            min.node.size = 20,\n",
    "            splitrule = \"extratrees\",\n",
    "            num.random.splits = 10\n",
    "          )\n",
    "          \n",
    "          predictions <- ranger_predictrisk(model, test_data, horizon)\n",
    "          feature_importance <- model$variable.importance\n",
    "          \n",
    "        } else if (method == \"AORSF\") {\n",
    "          # Remove constant columns from training data (can occur after train/test split)\n",
    "          constant_cols <- names(train_data)[sapply(train_data, function(x) {\n",
    "            if (is.numeric(x)) {\n",
    "              length(unique(na.omit(x))) <= 1\n",
    "            } else {\n",
    "              length(unique(na.omit(x))) <= 1\n",
    "            }\n",
    "          })]\n",
    "          constant_cols <- setdiff(constant_cols, c(\"time\", \"status\"))\n",
    "          if (length(constant_cols) > 0) {\n",
    "            train_data <- train_data %>% select(-any_of(constant_cols))\n",
    "            test_data <- test_data %>% select(-any_of(constant_cols))\n",
    "          }\n",
    "          \n",
    "          model <- aorsf::orsf(\n",
    "            data = train_data,\n",
    "            formula = Surv(time, status) ~ .,\n",
    "            n_tree = n_trees_aorsf,\n",
    "            na_action = 'impute_meanmode'\n",
    "          )\n",
    "          \n",
    "          pred_obj <- predict(model, new_data = test_data, \n",
    "                              pred_type = 'risk', pred_horizon = horizon)\n",
    "          predictions <- if (is.matrix(pred_obj)) as.numeric(pred_obj[, 1]) else as.numeric(pred_obj)\n",
    "          feature_importance <- aorsf::orsf_vi_permute(model)\n",
    "          \n",
    "        } else if (method == \"CatBoost\") {\n",
    "          # Remove constant columns from training data (can occur after train/test split)\n",
    "          constant_cols <- names(train_data)[sapply(train_data, function(x) {\n",
    "            if (is.numeric(x)) {\n",
    "              length(unique(na.omit(x))) <= 1\n",
    "            } else {\n",
    "              length(unique(na.omit(x))) <= 1\n",
    "            }\n",
    "          })]\n",
    "          constant_cols <- setdiff(constant_cols, c(\"time\", \"status\"))\n",
    "          if (length(constant_cols) > 0) {\n",
    "            train_data <- train_data %>% select(-any_of(constant_cols))\n",
    "            test_data <- test_data %>% select(-any_of(constant_cols))\n",
    "          }\n",
    "          \n",
    "          train_pool <- catboost.load_pool(\n",
    "            data = train_data %>% select(-time, -status),\n",
    "            label = train_data$time\n",
    "          )\n",
    "          \n",
    "          test_pool <- catboost.load_pool(\n",
    "            data = test_data %>% select(-time, -status)\n",
    "          )\n",
    "          \n",
    "          # CatBoost configuration: single-threaded inside each R worker to avoid\n",
    "          # logger/thread-safety issues, and quiet logging in parallel runs.\n",
    "          params <- list(\n",
    "            loss_function  = 'Cox',\n",
    "            iterations     = 100,\n",
    "            learning_rate  = 0.1,\n",
    "            depth          = 6,\n",
    "            thread_count   = 1,\n",
    "            logging_level  = 'Silent',\n",
    "            verbose        = 0L\n",
    "          )\n",
    "          \n",
    "          model <- catboost.train(train_pool, params = params)\n",
    "          predictions <- catboost.predict(model, test_pool)\n",
    "          \n",
    "          # Get feature importance - CatBoost returns a matrix with rownames as feature names\n",
    "          # IMPORTANT: catboost.get_feature_importance() returns a matrix (not a named vector)\n",
    "          # - Values are in the first column: importance_matrix[, 1]\n",
    "          # - Feature names are in rownames: rownames(importance_matrix)\n",
    "          # Convert to named vector for consistency with RSF and AORSF (which return named vectors directly)\n",
    "          importance_matrix <- catboost.get_feature_importance(model)\n",
    "          feature_importance <- as.numeric(importance_matrix[, 1])\n",
    "          names(feature_importance) <- rownames(importance_matrix)\n",
    "        }\n",
    "        \n",
    "        # Calculate C-index on TEST data\n",
    "        cindex_result <- calculate_cindex(\n",
    "          time = test_data$time,\n",
    "          status = test_data$status,\n",
    "          risk_scores = predictions,\n",
    "          horizon = horizon\n",
    "        )\n",
    "        \n",
    "        return(list(\n",
    "          split_id = split_id,\n",
    "          cindex_td = cindex_result$cindex_td,\n",
    "          cindex_ti = cindex_result$cindex_ti,\n",
    "          feature_importance = feature_importance,\n",
    "          n_train = nrow(train_data),\n",
    "          n_test = nrow(test_data),\n",
    "          success = TRUE\n",
    "        ))\n",
    "        \n",
    "      }, error = function(e) {\n",
    "        return(list(\n",
    "          split_id = split_id,\n",
    "          cindex_td = NA_real_,\n",
    "          cindex_ti = NA_real_,\n",
    "          feature_importance = NULL,\n",
    "          n_train = nrow(train_data),\n",
    "          n_test = nrow(test_data),\n",
    "          success = FALSE,\n",
    "          error = e$message\n",
    "        ))\n",
    "      })\n",
    "    }, .options = furrr_options(\n",
    "      seed = TRUE,\n",
    "      packages = c(\n",
    "        \"dplyr\", \"purrr\", \"tibble\", \"rsample\",\n",
    "        \"ranger\", \"aorsf\", \"catboost\",\n",
    "        \"riskRegression\", \"prodlim\"\n",
    "      )\n",
    "    ))\n",
    "  })\n",
    "  \n",
    "  # Aggregate results\n",
    "  successful_splits <- Filter(function(x) x$success, results)\n",
    "  n_successful <- length(successful_splits)\n",
    "  \n",
    "  cat(sprintf(\"Successful splits: %d / %d\\n\", n_successful, n_mc_splits))\n",
    "  flush.console()\n",
    "  \n",
    "  # If all splits failed (e.g., CatBoost configuration/data issue),\n",
    "  # do not stop the whole analysis. Instead, log a warning and return\n",
    "  # an empty/NA summary so that other methods and periods can continue.\n",
    "  if (n_successful == 0) {\n",
    "    error_splits <- Filter(function(x) !is.null(x$error), results)\n",
    "    if (length(error_splits) > 0) {\n",
    "      first_error <- error_splits[[1]]$error\n",
    "      cat(sprintf(\"WARNING: example error for %s (%s): %s\\n\",\n",
    "                  method, period_name, first_error))\n",
    "    }\n",
    "    cat(sprintf(\"WARNING: All MC-CV splits failed for %s (%s). Skipping this method.\\n\",\n",
    "                method, period_name))\n",
    "    flush.console()\n",
    "    \n",
    "    return(list(\n",
    "      method = method,\n",
    "      period = period_name,\n",
    "      n_splits = n_mc_splits,\n",
    "      n_successful = 0,\n",
    "      cindex_td_mean = NA_real_,\n",
    "      cindex_td_sd = NA_real_,\n",
    "      cindex_td_ci_lower = NA_real_,\n",
    "      cindex_td_ci_upper = NA_real_,\n",
    "      cindex_ti_mean = NA_real_,\n",
    "      cindex_ti_sd = NA_real_,\n",
    "      cindex_ti_ci_lower = NA_real_,\n",
    "      cindex_ti_ci_upper = NA_real_,\n",
    "      top_features = numeric(0)\n",
    "    ))\n",
    "  }\n",
    "  \n",
    "  # Extract C-indexes\n",
    "  cindex_td_values <- sapply(successful_splits, function(x) x$cindex_td)\n",
    "  cindex_ti_values <- sapply(successful_splits, function(x) x$cindex_ti)\n",
    "  \n",
    "  cindex_td_values <- cindex_td_values[!is.na(cindex_td_values)]\n",
    "  cindex_ti_values <- cindex_ti_values[!is.na(cindex_ti_values)]\n",
    "  \n",
    "  # Aggregate feature importance\n",
    "  # All methods (RSF, AORSF, CatBoost) return named numeric vectors\n",
    "  all_feature_names <- unique(unlist(lapply(successful_splits, function(x) {\n",
    "    if (is.null(x$feature_importance)) return(NULL)\n",
    "    names(x$feature_importance)\n",
    "  })))\n",
    "  \n",
    "  aggregated_importance <- sapply(all_feature_names, function(feature) {\n",
    "    importances <- sapply(successful_splits, function(x) {\n",
    "      if (is.null(x$feature_importance)) return(NA_real_)\n",
    "      if (feature %in% names(x$feature_importance)) {\n",
    "        return(as.numeric(x$feature_importance[feature]))\n",
    "      }\n",
    "      return(NA_real_)\n",
    "    })\n",
    "    mean(importances, na.rm = TRUE)\n",
    "  })\n",
    "  \n",
    "  # Ensure aggregated_importance is a numeric vector\n",
    "  aggregated_importance <- as.numeric(aggregated_importance)\n",
    "  names(aggregated_importance) <- all_feature_names\n",
    "  \n",
    "  top_features <- sort(aggregated_importance, decreasing = TRUE)[1:min(n_predictors, length(aggregated_importance))]\n",
    "  \n",
    "  # Calculate statistics\n",
    "  results_summary <- list(\n",
    "    method = method,\n",
    "    period = period_name,\n",
    "    n_splits = n_mc_splits,\n",
    "    n_successful = n_successful,\n",
    "    cindex_td_mean = mean(cindex_td_values, na.rm = TRUE),\n",
    "    cindex_td_sd = sd(cindex_td_values, na.rm = TRUE),\n",
    "    cindex_td_ci_lower = quantile(cindex_td_values, 0.025, na.rm = TRUE),\n",
    "    cindex_td_ci_upper = quantile(cindex_td_values, 0.975, na.rm = TRUE),\n",
    "    cindex_ti_mean = mean(cindex_ti_values, na.rm = TRUE),\n",
    "    cindex_ti_sd = sd(cindex_ti_values, na.rm = TRUE),\n",
    "    cindex_ti_ci_lower = quantile(cindex_ti_values, 0.025, na.rm = TRUE),\n",
    "    cindex_ti_ci_upper = quantile(cindex_ti_values, 0.975, na.rm = TRUE),\n",
    "    top_features = top_features\n",
    "  )\n",
    "  \n",
    "  # Print summary\n",
    "  cat(sprintf(\"\\n--- Results for %s (%s) ---\\n\", method, period_name))\n",
    "  cat(sprintf(\"Time-Dependent C-Index: %.4f Â± %.4f (95%% CI: %.4f - %.4f)\\n\",\n",
    "              results_summary$cindex_td_mean,\n",
    "              results_summary$cindex_td_sd,\n",
    "              results_summary$cindex_td_ci_lower,\n",
    "              results_summary$cindex_td_ci_upper))\n",
    "  cat(sprintf(\"Time-Independent C-Index: %.4f Â± %.4f (95%% CI: %.4f - %.4f)\\n\",\n",
    "              results_summary$cindex_ti_mean,\n",
    "              results_summary$cindex_ti_sd,\n",
    "              results_summary$cindex_ti_ci_lower,\n",
    "              results_summary$cindex_ti_ci_upper))\n",
    "  # Display top 10 features sorted alphabetically for easier comparison\n",
    "  top10_features <- names(top_features)[1:min(10, length(top_features))]\n",
    "  top10_features_sorted <- sort(top10_features)\n",
    "  cat(sprintf(\"Top 10 features (alphabetical): %s\\n\", paste(top10_features_sorted, collapse = \", \")))\n",
    "  flush.console()\n",
    "  \n",
    "  return(results_summary)\n",
    "}\n",
    "\n",
    "cat(\"âœ“ run_mc_cv_method() defined\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: /home/pgx3874/graft-loss/data/phts_txpl_ml.sas7bdat \n",
      "âœ“ Loaded data: 5835 rows, 478 columns\n"
     ]
    }
   ],
   "source": [
    "# Find and load SAS file\n",
    "sas_path_local <- here(\"data\", \"phts_txpl_ml.sas7bdat\")\n",
    "sas_path_external <- here(\"graft-loss-parallel-processing\", \"data\", \"phts_txpl_ml.sas7bdat\")\n",
    "sas_path_graft_loss <- here(\"graft-loss\", \"data\", \"phts_txpl_ml.sas7bdat\")\n",
    "\n",
    "sas_path <- NULL\n",
    "for (path in c(sas_path_local, sas_path_external, sas_path_graft_loss)) {\n",
    "  if (file.exists(path)) {\n",
    "    sas_path <- path\n",
    "    break\n",
    "  }\n",
    "}\n",
    "\n",
    "if (is.null(sas_path)) {\n",
    "  stop(\"Cannot find phts_txpl_ml.sas7bdat in any location\")\n",
    "}\n",
    "\n",
    "cat(\"Loading data from:\", sas_path, \"\\n\")\n",
    "\n",
    "# Load data\n",
    "phts_base <- haven::read_sas(sas_path) %>%\n",
    "  filter(TXPL_YEAR >= 2010) %>%\n",
    "  janitor::clean_names() %>%\n",
    "  rename(\n",
    "    outcome_int_graft_loss = int_graft_loss,\n",
    "    outcome_graft_loss = graft_loss\n",
    "  ) %>%\n",
    "  mutate(\n",
    "    ID = 1:n(),\n",
    "    across(.cols = where(is.character), ~ ifelse(.x %in% c(\"\", \"unknown\", \"missing\"), NA_character_, .x)),\n",
    "    across(.cols = where(is.character), as.factor),\n",
    "    tx_mcsd = if ('txnomcsd' %in% names(.)) {\n",
    "      if_else(txnomcsd == 'yes', 0, 1)\n",
    "    } else if ('txmcsd' %in% names(.)) {\n",
    "      txmcsd\n",
    "    } else {\n",
    "      NA_real_\n",
    "    }\n",
    "  )\n",
    "\n",
    "cat(sprintf(\"âœ“ Loaded data: %d rows, %d columns\\n\", nrow(phts_base), ncol(phts_base)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Period: original | N: 4036 | Events: 768 (19.03%)\n",
      "Period: full | N: 5835 | Events: 939 (16.09%)\n",
      "Period: full_no_covid | N: 4196 | Events: 774 (18.45%)\n",
      "\n",
      "âœ“ Time periods defined\n"
     ]
    }
   ],
   "source": [
    "# Define time periods\n",
    "periods <- list()\n",
    "periods$original <- phts_base %>% filter(txpl_year >= 2010 & txpl_year <= 2019)\n",
    "periods$full <- phts_base %>% filter(txpl_year >= 2010)\n",
    "periods$full_no_covid <- phts_base %>% filter(txpl_year >= 2010 & !(txpl_year >= 2020 & txpl_year <= 2023))\n",
    "\n",
    "# Print summary\n",
    "for (period_name in names(periods)) {\n",
    "  period_data <- periods[[period_name]]\n",
    "  n_events <- sum(period_data$outcome_graft_loss, na.rm = TRUE)\n",
    "  event_rate <- 100 * n_events / nrow(period_data)\n",
    "  \n",
    "  cat(sprintf(\"Period: %s | N: %d | Events: %d (%.2f%%)\\n\", \n",
    "              period_name, nrow(period_data), n_events, event_rate))\n",
    "}\n",
    "\n",
    "cat(\"\\nâœ“ Time periods defined\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run Analysis\n",
    "\n",
    "Execute MC-CV for all methods and periods.\n",
    "\n",
    "- **100 splits (default full run):** Typically ~1â€“2 hours on a 32-core EC2 instance, longer on smaller machines.\n",
    "- **1000 splits (extended run):** Linearly more expensive; expect roughly 8â€“10Ã— the 100-split time.\n",
    "\n",
    "**Note:** You can run each period separately by uncommenting only one `period_name` at a time, or reduce the number of methods/periods to shorten runtime further.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "Processing Period: original\n",
      "========================================\n",
      "Period data: 4036 rows, 381 columns\n",
      "Events: 768 (19.03%)\n",
      "Creating 100 MC-CV splits (stratified)...\n",
      "\n",
      "=== Running MC-CV for RSF (original) ===\n",
      "Splits: 100 | Train: 75% | Test: 25%\n"
     ]
    }
   ],
   "source": [
    "# Select periods and methods to run\n",
    "# In DEBUG_MODE, only run original period for speed\n",
    "period_names <- if (DEBUG_MODE) {\n",
    "  c(\"original\")  # Debug: just one period (~2-5 min)\n",
    "} else {\n",
    "  c(\"original\", \"full\", \"full_no_covid\")  # Full: all periods (~30-45 min)\n",
    "}\n",
    "\n",
    "# Methods to run. Include CatBoost (with single-threaded, quiet config)\n",
    "# alongside RSF and AORSF.\n",
    "method_names <- c(\"RSF\", \"CatBoost\", \"AORSF\")\n",
    "\n",
    "# Store all results\n",
    "all_results <- list()\n",
    "\n",
    "# Run analysis\n",
    "for (period_name in period_names) {\n",
    "  cat(sprintf(\"\\n========================================\\n\"))\n",
    "  cat(sprintf(\"Processing Period: %s\\n\", period_name))\n",
    "  cat(sprintf(\"========================================\\n\"))\n",
    "  flush.console()\n",
    "  \n",
    "  # Prepare data\n",
    "  period_data <- prepare_modeling_data(periods[[period_name]])\n",
    "  \n",
    "  cat(sprintf(\"Period data: %d rows, %d columns\\n\", nrow(period_data), ncol(period_data)))\n",
    "  cat(sprintf(\"Events: %d (%.2f%%)\\n\", sum(period_data$status), \n",
    "              100 * sum(period_data$status) / nrow(period_data)))\n",
    "  \n",
    "  # Create MC-CV splits (stratified by outcome)\n",
    "  cat(sprintf(\"Creating %d MC-CV splits (stratified)...\\n\", n_mc_splits))\n",
    "  flush.console()\n",
    "  mc_splits <- mc_cv(\n",
    "    data = period_data,\n",
    "    prop = train_prop,\n",
    "    times = n_mc_splits,\n",
    "    strata = status\n",
    "  )\n",
    "  \n",
    "  # Run each method\n",
    "  period_results <- list()\n",
    "  \n",
    "  for (method in method_names) {\n",
    "    result <- run_mc_cv_method(period_data, method, period_name, mc_splits)\n",
    "    period_results[[method]] <- result\n",
    "    \n",
    "    # Save top features (sorted alphabetically for easier comparison)\n",
    "    top_features_df <- tibble(\n",
    "      feature = names(result$top_features),\n",
    "      importance = as.numeric(result$top_features),\n",
    "      cindex_td = result$cindex_td_mean,\n",
    "      cindex_ti = result$cindex_ti_mean\n",
    "    ) %>%\n",
    "      arrange(feature)  # Sort alphabetically for easier visual comparison\n",
    "    \n",
    "    output_file <- file.path(output_dir, sprintf(\"%s_%s_top20.csv\", \n",
    "                                                  period_name, tolower(method)))\n",
    "    write_csv(top_features_df, output_file)\n",
    "    cat(sprintf(\"âœ“ Saved: %s\\n\", basename(output_file)))\n",
    "  }\n",
    "  \n",
    "  all_results[[period_name]] <- period_results\n",
    "}\n",
    "\n",
    "cat(\"\\nâœ“ Analysis complete for all periods!\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Summary Results\n",
    "\n",
    "Create summary tables with C-index comparisons and statistics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Create C-index comparison table\n",
    "cindex_comparison <- map_df(period_names, function(period) {\n",
    "  map_df(method_names, function(method) {\n",
    "    result <- all_results[[period]][[method]]\n",
    "    tibble(\n",
    "      period = period,\n",
    "      method = method,\n",
    "      cindex_td_mean = result$cindex_td_mean,\n",
    "      cindex_td_sd = result$cindex_td_sd,\n",
    "      cindex_td_ci_lower = result$cindex_td_ci_lower,\n",
    "      cindex_td_ci_upper = result$cindex_td_ci_upper,\n",
    "      cindex_ti_mean = result$cindex_ti_mean,\n",
    "      cindex_ti_sd = result$cindex_ti_sd,\n",
    "      cindex_ti_ci_lower = result$cindex_ti_ci_lower,\n",
    "      cindex_ti_ci_upper = result$cindex_ti_ci_upper,\n",
    "      n_splits = result$n_successful\n",
    "    )\n",
    "  })\n",
    "})\n",
    "\n",
    "write_csv(cindex_comparison, file.path(output_dir, \"cindex_comparison_mc_cv.csv\"))\n",
    "cat(\"âœ“ Saved: cindex_comparison_mc_cv.csv\\n\")\n",
    "\n",
    "# Display the table\n",
    "print(cindex_comparison)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Create summary statistics\n",
    "summary_stats <- map_df(period_names, function(period) {\n",
    "  period_data <- periods[[period]]\n",
    "  tibble(\n",
    "    period = period,\n",
    "    n_patients = nrow(period_data),\n",
    "    n_events = sum(period_data$outcome_graft_loss, na.rm = TRUE),\n",
    "    event_rate = 100 * sum(period_data$outcome_graft_loss, na.rm = TRUE) / nrow(period_data)\n",
    "  )\n",
    "})\n",
    "\n",
    "write_csv(summary_stats, file.path(output_dir, \"summary_statistics_mc_cv.csv\"))\n",
    "cat(\"âœ“ Saved: summary_statistics_mc_cv.csv\\n\")\n",
    "\n",
    "# Display the table\n",
    "print(summary_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Close parallel processing\n",
    "plan(sequential)\n",
    "\n",
    "cat(\"\\n========================================\\n\")\n",
    "cat(\"Analysis Complete!\\n\")\n",
    "cat(\"========================================\\n\")\n",
    "cat(sprintf(\"Output directory: %s\\n\", output_dir))\n",
    "cat(sprintf(\"MC-CV splits: %d\\n\", n_mc_splits))\n",
    "cat(sprintf(\"Train/Test ratio: %.0f/%.0f\\n\", train_prop * 100, (1 - train_prop) * 100))\n",
    "cat(\"\\nResults show C-indexes with 95% confidence intervals\\n\")\n",
    "cat(\"based on\", n_mc_splits, \"independent train/test splits.\\n\\n\")\n",
    "cat(\"âœ“ All files saved successfully!\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Create visualization plots for feature importance and C-index analysis\n",
    "# Updated to match MC-CV implementation output structure\n",
    "# Creates: Feature importance heatmap, C-index heatmap, and C-index table\n",
    "\n",
    "library(tidyverse)\n",
    "library(ggplot2)\n",
    "library(here)\n",
    "\n",
    "# Set output directory (matches notebook output directory)\n",
    "output_dir <- here(\"feature_importance\", \"outputs\")\n",
    "plot_dir <- file.path(output_dir, \"plots\")\n",
    "dir.create(plot_dir, showWarnings = FALSE, recursive = TRUE)\n",
    "\n",
    "# Read MC-CV results\n",
    "cindex_comparison <- read_csv(file.path(output_dir, \"cindex_comparison_mc_cv.csv\"))\n",
    "\n",
    "# Read individual feature files for each method and period\n",
    "periods <- c(\"original\", \"full\", \"full_no_covid\")\n",
    "methods <- c(\"rsf\", \"catboost\", \"aorsf\")\n",
    "\n",
    "# Load feature importance data\n",
    "# Map lowercase method names to the format used in cindex_comparison\n",
    "method_map <- c(\"rsf\" = \"RSF\", \"catboost\" = \"CatBoost\", \"aorsf\" = \"AORSF\")\n",
    "\n",
    "load_features <- function(period, method) {\n",
    "  file_path <- file.path(output_dir, sprintf(\"%s_%s_top20.csv\", period, method))\n",
    "  if (file.exists(file_path)) {\n",
    "    df <- read_csv(file_path) %>%\n",
    "      mutate(period = period, method = method_map[[method]])\n",
    "    cat(sprintf(\"âœ“ Loaded: %s\\n\", basename(file_path)))\n",
    "    return(df)\n",
    "  } else {\n",
    "    warning(sprintf(\"File not found: %s\", file_path))\n",
    "    return(NULL)\n",
    "  }\n",
    "}\n",
    "\n",
    "# Combine all feature files - read all 9 files (3 periods Ã— 3 methods)\n",
    "cat(\"\\nLoading feature importance files...\\n\")\n",
    "all_features <- map_df(periods, function(p) {\n",
    "  map_df(methods, function(m) {\n",
    "    load_features(p, m)\n",
    "  })\n",
    "}) %>%\n",
    "  filter(!is.null(feature))\n",
    "\n",
    "# Verify we loaded all expected files\n",
    "expected_files <- length(periods) * length(methods)\n",
    "loaded_count <- length(unique(paste(all_features$period, all_features$method)))\n",
    "cat(sprintf(\"\\nLoaded %d/%d expected feature files\\n\", loaded_count, expected_files))\n",
    "cat(sprintf(\"Total features loaded: %d\\n\", nrow(all_features)))\n",
    "cat(sprintf(\"Unique features: %d\\n\", length(unique(all_features$feature))))\n",
    "\n",
    "# ============================================================================\n",
    "# 1. FEATURE IMPORTANCE HEATMAP\n",
    "# ============================================================================\n",
    "\n",
    "# Get all unique features across all methods and periods\n",
    "all_unique_features <- unique(all_features$feature)\n",
    "\n",
    "# Debug: Check what methods and periods are actually in the data\n",
    "cat(\"\\nDebug: Methods in all_features:\", unique(all_features$method), \"\\n\")\n",
    "cat(\"Debug: Periods in all_features:\", unique(all_features$period), \"\\n\")\n",
    "cat(\"Debug: Sample of all_features:\\n\")\n",
    "print(head(all_features %>% select(feature, period, method, importance), 10))\n",
    "\n",
    "# Create a matrix: features (rows) x cohort-method combinations (columns)\n",
    "# For each feature, get its importance value (or 0 if not in top 20)\n",
    "feature_matrix <- map_df(all_unique_features, function(feat) {\n",
    "  map_df(periods, function(per) {\n",
    "    map_df(methods, function(meth) {\n",
    "      method_name <- method_map[[meth]]\n",
    "      feat_data <- all_features %>%\n",
    "        filter(feature == feat, period == per, method == method_name)\n",
    "      \n",
    "      importance_val <- if (nrow(feat_data) > 0) {\n",
    "        feat_data$importance[1]\n",
    "      } else {\n",
    "        0\n",
    "      }\n",
    "      \n",
    "      tibble(\n",
    "        feature = feat,\n",
    "        period = per,\n",
    "        method = method_name,\n",
    "        importance = importance_val\n",
    "      )\n",
    "    })\n",
    "  })\n",
    "}) %>%\n",
    "  mutate(\n",
    "    cohort_method = paste(period, method, sep = \"_\"),\n",
    "    period = factor(period, levels = c(\"original\", \"full\", \"full_no_covid\")),\n",
    "    method = factor(method, levels = c(\"RSF\", \"CatBoost\", \"AORSF\"))\n",
    "  )\n",
    "\n",
    "# Debug: Check feature_matrix before normalization\n",
    "cat(\"\\nDebug: Feature matrix summary (before normalization):\\n\")\n",
    "cat(\"Methods in feature_matrix:\", unique(feature_matrix$method), \"\\n\")\n",
    "cat(\"Non-zero importance values by method:\\n\")\n",
    "print(feature_matrix %>% \n",
    "      group_by(method) %>% \n",
    "      summarise(n_nonzero = sum(importance > 0), \n",
    "                max_importance = max(importance), \n",
    "                mean_importance = mean(importance), \n",
    "                .groups = \"drop\"))\n",
    "\n",
    "# Normalize importance values within each method-period combination\n",
    "# This makes values comparable across different algorithms (RSF, CatBoost, AORSF)\n",
    "feature_matrix <- feature_matrix %>%\n",
    "  group_by(period, method) %>%\n",
    "  mutate(\n",
    "    importance_normalized = if (max(importance) > 0) {\n",
    "      (importance - min(importance)) / (max(importance) - min(importance))\n",
    "    } else {\n",
    "      0\n",
    "    }\n",
    "  ) %>%\n",
    "  ungroup()\n",
    "\n",
    "cat(\"\\nDebug: After normalization - importance range by method:\\n\")\n",
    "print(feature_matrix %>% \n",
    "      group_by(method) %>% \n",
    "      summarise(min_imp = min(importance_normalized), \n",
    "                max_imp = max(importance_normalized), \n",
    "                mean_imp = mean(importance_normalized), \n",
    "                .groups = \"drop\"))\n",
    "\n",
    "# Determine algorithm ranking by C-index for each period\n",
    "# Best algorithm gets scale factor 3, second best gets 2, third gets 1\n",
    "cat(\"\\nDetermining algorithm ranking by C-index for scaling...\\n\")\n",
    "algorithm_ranking <- cindex_comparison %>%\n",
    "  select(period, method, cindex_td_mean) %>%\n",
    "  group_by(period) %>%\n",
    "  arrange(desc(cindex_td_mean)) %>%\n",
    "  mutate(\n",
    "    rank = row_number(),\n",
    "    scale_factor = case_when(\n",
    "      rank == 1 ~ 3,  # Best algorithm\n",
    "      rank == 2 ~ 2,  # Second best algorithm\n",
    "      rank == 3 ~ 1   # Third algorithm (no scaling)\n",
    "    )\n",
    "  ) %>%\n",
    "  ungroup() %>%\n",
    "  select(period, method, scale_factor)\n",
    "\n",
    "cat(\"Algorithm ranking and scale factors:\\n\")\n",
    "print(algorithm_ranking)\n",
    "\n",
    "# Apply scaling to normalized feature importance\n",
    "feature_matrix <- feature_matrix %>%\n",
    "  left_join(algorithm_ranking, by = c(\"period\", \"method\")) %>%\n",
    "  mutate(\n",
    "    importance_scaled = importance_normalized * scale_factor,\n",
    "    importance = importance_scaled  # Use scaled values for heatmap\n",
    "  ) %>%\n",
    "  select(-importance_scaled)\n",
    "\n",
    "cat(\"\\nDebug: After scaling - importance range by method:\\n\")\n",
    "print(feature_matrix %>% \n",
    "      group_by(method) %>% \n",
    "      summarise(min_imp = min(importance), \n",
    "                max_imp = max(importance), \n",
    "                mean_imp = mean(importance), \n",
    "                .groups = \"drop\"))\n",
    "\n",
    "# Create heatmap\n",
    "# Order features by total importance across all cohort-method combinations\n",
    "feature_order <- feature_matrix %>%\n",
    "  group_by(feature) %>%\n",
    "  summarise(total_importance = sum(importance), .groups = \"drop\") %>%\n",
    "  arrange(desc(total_importance)) %>%\n",
    "  pull(feature)\n",
    "\n",
    "feature_matrix <- feature_matrix %>%\n",
    "  mutate(feature = factor(feature, levels = feature_order))\n",
    "\n",
    "# Create cohort_method labels with better formatting\n",
    "feature_matrix <- feature_matrix %>%\n",
    "  mutate(\n",
    "    cohort_label = case_when(\n",
    "      period == \"original\" ~ \"Original\",\n",
    "      period == \"full\" ~ \"Full\",\n",
    "      period == \"full_no_covid\" ~ \"Full No COVID\"\n",
    "    ),\n",
    "    cohort_method_label = paste(cohort_label, method, sep = \"\\n\")\n",
    "  )\n",
    "\n",
    "p1 <- ggplot(feature_matrix, aes(x = cohort_method_label, y = feature, fill = importance)) +\n",
    "  geom_tile(color = \"white\", linewidth = 0.1) +\n",
    "  scale_fill_gradient(low = \"orange\", high = \"darkblue\",\n",
    "                      name = \"Importance\") +\n",
    "  labs(title = \"Feature Importance Heatmap by Cohort and Algorithm\",\n",
    "       x = \"Cohort Ã— Algorithm\", y = \"Feature\") +\n",
    "  theme_minimal() +\n",
    "  theme(\n",
    "    axis.text.x = element_text(angle = 0, hjust = 0.5, size = 10),\n",
    "    axis.text.y = element_text(size = 8),\n",
    "    axis.title = element_text(size = 12, face = \"bold\"),\n",
    "    plot.title = element_text(size = 14, face = \"bold\", hjust = 0.5),\n",
    "    legend.position = \"right\",\n",
    "    panel.grid = element_blank()\n",
    "  )\n",
    "\n",
    "ggsave(file.path(plot_dir, \"feature_importance_heatmap.png\"), p1, \n",
    "       width = 12, height = max(16, length(all_unique_features) * 0.3), dpi = 300, limitsize = FALSE)\n",
    "\n",
    "# ============================================================================\n",
    "# 2. C-INDEX HEATMAP\n",
    "# ============================================================================\n",
    "\n",
    "# Prepare data for C-index heatmap (both time-dependent and time-independent)\n",
    "cindex_heatmap_data <- bind_rows(\n",
    "  cindex_comparison %>%\n",
    "    select(period, method, cindex_td_mean) %>%\n",
    "    rename(cindex = cindex_td_mean) %>%\n",
    "    mutate(cindex_type = \"Time-Dependent\"),\n",
    "  cindex_comparison %>%\n",
    "    select(period, method, cindex_ti_mean) %>%\n",
    "    rename(cindex = cindex_ti_mean) %>%\n",
    "    mutate(cindex_type = \"Time-Independent\")\n",
    ") %>%\n",
    "  mutate(\n",
    "    period = factor(period, levels = c(\"original\", \"full\", \"full_no_covid\")),\n",
    "    method = factor(method, levels = c(\"RSF\", \"CatBoost\", \"AORSF\")),\n",
    "    cohort_label = case_when(\n",
    "      period == \"original\" ~ \"Original\",\n",
    "      period == \"full\" ~ \"Full\",\n",
    "      period == \"full_no_covid\" ~ \"Full No COVID\"\n",
    "    )\n",
    "  )\n",
    "\n",
    "p2 <- ggplot(cindex_heatmap_data, aes(x = method, y = cohort_label, fill = cindex)) +\n",
    "  geom_tile(color = \"white\", linewidth = 0.5) +\n",
    "  geom_text(aes(label = sprintf(\"%.3f\", cindex)), color = \"black\", size = 4, fontface = \"bold\") +\n",
    "  scale_fill_gradient2(low = \"red\", mid = \"white\", high = \"green\",\n",
    "                       midpoint = 0.5,\n",
    "                       name = \"C-index\") +\n",
    "  facet_wrap(~cindex_type, ncol = 2) +\n",
    "  labs(title = \"Concordance Index Heatmap by Cohort and Algorithm (MC-CV)\",\n",
    "       x = \"Algorithm\", y = \"Cohort\") +\n",
    "  theme_minimal() +\n",
    "  theme(\n",
    "    axis.text = element_text(size = 11),\n",
    "    axis.title = element_text(size = 12, face = \"bold\"),\n",
    "    plot.title = element_text(size = 14, face = \"bold\", hjust = 0.5),\n",
    "    legend.position = \"right\",\n",
    "    strip.text = element_text(size = 12, face = \"bold\"),\n",
    "    panel.grid = element_blank()\n",
    "  )\n",
    "\n",
    "ggsave(file.path(plot_dir, \"cindex_heatmap.png\"), p2, width = 12, height = 6, dpi = 300)\n",
    "\n",
    "# ============================================================================\n",
    "# 3. SCALED FEATURE IMPORTANCE BAR CHART\n",
    "# ============================================================================\n",
    "\n",
    "cat(\"\\nCreating scaled feature importance bar chart...\\n\")\n",
    "\n",
    "# Aggregate scaled importance by feature across all periods and methods\n",
    "# Sum the scaled importance values for each feature\n",
    "scaled_feature_importance <- feature_matrix %>%\n",
    "  group_by(feature) %>%\n",
    "  summarise(\n",
    "    total_scaled_importance = sum(importance_normalized * scale_factor, na.rm = TRUE),\n",
    "    .groups = \"drop\"\n",
    "  ) %>%\n",
    "  arrange(desc(total_scaled_importance)) %>%\n",
    "  # Get top 20 features\n",
    "  slice_head(n = 20)\n",
    "\n",
    "# Order features by total scaled importance\n",
    "scaled_feature_importance <- scaled_feature_importance %>%\n",
    "  mutate(feature = factor(feature, levels = rev(scaled_feature_importance$feature)))\n",
    "\n",
    "p3 <- ggplot(scaled_feature_importance, aes(x = feature, y = total_scaled_importance)) +\n",
    "  geom_bar(stat = \"identity\", fill = \"steelblue\", alpha = 0.8) +\n",
    "  coord_flip() +\n",
    "  labs(\n",
    "    title = \"Scaled Feature Importance (Top 20 Features)\",\n",
    "    subtitle = \"Importance scaled by algorithm performance: Best C-index (Ã—3), Second best (Ã—2), Third (Ã—1)\",\n",
    "    x = \"Feature\",\n",
    "    y = \"Scaled Normalized Importance\"\n",
    "  ) +\n",
    "  theme_minimal() +\n",
    "  theme(\n",
    "    axis.text = element_text(size = 10),\n",
    "    axis.title = element_text(size = 12, face = \"bold\"),\n",
    "    plot.title = element_text(size = 14, face = \"bold\", hjust = 0.5),\n",
    "    plot.subtitle = element_text(size = 11, hjust = 0.5),\n",
    "    panel.grid.major.y = element_blank(),\n",
    "    panel.grid.minor = element_blank()\n",
    "  )\n",
    "\n",
    "ggsave(file.path(plot_dir, \"scaled_feature_importance_bar_chart.png\"), p3, \n",
    "       width = 12, height = 10, dpi = 300)\n",
    "cat(\"âœ“ Saved: scaled_feature_importance_bar_chart.png\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# 4. C-INDEX TABLE\n",
    "# ============================================================================\n",
    "\n",
    "# Create formatted table with both C-index types and confidence intervals\n",
    "cindex_table <- cindex_comparison %>%\n",
    "  mutate(\n",
    "    period_label = case_when(\n",
    "      period == \"original\" ~ \"Original\",\n",
    "      period == \"full\" ~ \"Full\",\n",
    "      period == \"full_no_covid\" ~ \"Full No COVID\"\n",
    "    ),\n",
    "    # Format C-index with CI\n",
    "    cindex_td_formatted = sprintf(\"%.3f (%.3f-%.3f)\", \n",
    "                                  cindex_td_mean, cindex_td_ci_lower, cindex_td_ci_upper),\n",
    "    cindex_ti_formatted = sprintf(\"%.3f (%.3f-%.3f)\", \n",
    "                                   cindex_ti_mean, cindex_ti_ci_lower, cindex_ti_ci_upper)\n",
    "  ) %>%\n",
    "  select(period_label, method, cindex_td_formatted, cindex_ti_formatted, n_splits) %>%\n",
    "  arrange(period_label, method) %>%\n",
    "  rename(\n",
    "    Cohort = period_label,\n",
    "    Algorithm = method,\n",
    "    `Time-Dependent C-index (95% CI)` = cindex_td_formatted,\n",
    "    `Time-Independent C-index (95% CI)` = cindex_ti_formatted,\n",
    "    `N Splits` = n_splits\n",
    "  )\n",
    "\n",
    "# Save as CSV\n",
    "write_csv(cindex_table, file.path(plot_dir, \"cindex_table.csv\"))\n",
    "\n",
    "# Also create a formatted text table for display\n",
    "cat(\"\\n========================================\\n\")\n",
    "cat(\"Concordance Index Table\\n\")\n",
    "cat(\"========================================\\n\")\n",
    "print(cindex_table)\n",
    "cat(\"\\n\")\n",
    "\n",
    "# Save summary\n",
    "cat(\"Plots saved to:\", plot_dir, \"\\n\")\n",
    "cat(\"Created visualizations:\\n\")\n",
    "cat(\"  1. feature_importance_heatmap.png - Feature importance by cohort and algorithm (scaled by C-index)\\n\")\n",
    "cat(\"  2. cindex_heatmap.png - Concordance index by cohort and algorithm\\n\")\n",
    "cat(\"  3. scaled_feature_importance_bar_chart.png - Bar chart of scaled feature importance (top 20)\\n\")\n",
    "cat(\"  4. cindex_table.csv - Concordance index table with confidence intervals\\n\")\n",
    "cat(\"\\nAll visualizations use MC-CV results with 95% confidence intervals.\\n\")\n",
    "cat(\"Feature importance values are normalized within each method-period combination,\\n\")\n",
    "cat(\"then scaled by algorithm performance: Best C-index algorithm (Ã—3), Second best (Ã—2), Third (Ã—1).\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Sync Results and Code to S3\n",
    "\n",
    "Sync output files and code (notebook + R script) to S3 bucket. \n",
    "- Outputs: CSV results files\n",
    "- Code: Notebook and R script for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Sync outputs and code to S3\n",
    "# On EC2, we're in the feature_importance directory\n",
    "s3_bucket <- \"s3://uva-private-data-lake/graft-loss/feature_importance/\"\n",
    "\n",
    "# Find AWS CLI (check common locations - EC2 typically has it in /usr/local/bin or /usr/bin)\n",
    "aws_cmd <- Sys.which(\"aws\")\n",
    "if (aws_cmd == \"\") {\n",
    "  # Try common EC2 installation paths\n",
    "  aws_paths <- c(\n",
    "    \"/usr/local/bin/aws\",\n",
    "    \"/usr/bin/aws\",\n",
    "    \"/home/ec2-user/.local/bin/aws\"\n",
    "  )\n",
    "  aws_cmd <- NULL\n",
    "  for (path in aws_paths) {\n",
    "    if (file.exists(path)) {\n",
    "      aws_cmd <- path\n",
    "      break\n",
    "    }\n",
    "  }\n",
    "  if (is.null(aws_cmd)) {\n",
    "    stop(\"AWS CLI not found. Please install AWS CLI or ensure it's in your PATH.\")\n",
    "  }\n",
    "}\n",
    "\n",
    "cat(\"Syncing outputs and code to S3...\\n\")\n",
    "cat(\"Source: feature_importance/ directory\\n\")\n",
    "cat(\"Destination:\", s3_bucket, \"\\n\")\n",
    "cat(\"AWS CLI:\", aws_cmd, \"\\n\\n\")\n",
    "\n",
    "# Get current directory (should be feature_importance)\n",
    "current_dir <- getwd()\n",
    "if (!grepl(\"feature_importance\", current_dir)) {\n",
    "  warning(\"Current directory doesn't appear to be feature_importance. Double-check sync destination.\")\n",
    "}\n",
    "\n",
    "# Sync feature_importance directory (includes outputs/ and code files)\n",
    "# Exclude temporary files, checkpoints, and unnecessary directories\n",
    "# Note: --delete flag removed for safety (won't delete files in S3 that don't exist locally)\n",
    "# This will sync: outputs/*, *.ipynb, *.R, README*.md (and exclude everything else unwanted)\n",
    "sync_cmd <- sprintf(\n",
    "  '\"%s\" s3 sync \"%s\" %s --exclude \"*checkpoint*\" --exclude \"*.tmp\" --exclude \"*.ipynb_checkpoints/*\" --exclude \"*.RData\" --exclude \"*.Rhistory\" --exclude \".Rproj.user/*\" --exclude \"catboost_info/*\" --exclude \"*.log\"',\n",
    "  aws_cmd,\n",
    "  current_dir,\n",
    "  s3_bucket\n",
    ")\n",
    "\n",
    "cat(\"Running:\", sync_cmd, \"\\n\\n\")\n",
    "result <- system(sync_cmd)\n",
    "\n",
    "if (result == 0) {\n",
    "  cat(\"âœ“ Successfully synced outputs and code to S3\\n\")\n",
    "  cat(\"  - Outputs:\", file.path(output_dir), \"\\n\")\n",
    "  cat(\"  - Code: *.ipynb, *.R, README*.md\\n\")\n",
    "} else {\n",
    "  warning(sprintf(\"S3 sync returned exit code %d. Check AWS credentials and permissions.\", result))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Shutdown EC2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Shutdown EC2 instance after analysis completes\n",
    "# Set SHUTDOWN_EC2 = TRUE to enable, FALSE to disable\n",
    "SHUTDOWN_EC2 <- TRUE  # Change to TRUE to enable auto-shutdown\n",
    "\n",
    "if (SHUTDOWN_EC2) {\n",
    "  cat(\"\\n========================================\\n\")\n",
    "  cat(\"Shutting down EC2 instance...\\n\")\n",
    "  cat(\"========================================\\n\")\n",
    "  \n",
    "  # Get instance ID from EC2 metadata service\n",
    "  instance_id <- tryCatch({\n",
    "    system(\"curl -s http://169.254.169.254/latest/meta-data/instance-id\", intern = TRUE)\n",
    "  }, error = function(e) {\n",
    "    cat(\"Warning: Could not retrieve instance ID from metadata service.\\n\")\n",
    "    cat(\"If running on EC2, check that metadata service is accessible.\\n\")\n",
    "    return(NULL)\n",
    "  })\n",
    "  \n",
    "  if (!is.null(instance_id) && length(instance_id) > 0 && nchar(instance_id[1]) > 0) {\n",
    "    instance_id <- instance_id[1]\n",
    "    cat(sprintf(\"Instance ID: %s\\n\", instance_id))\n",
    "    \n",
    "    # Find AWS CLI\n",
    "    aws_cmd <- Sys.which(\"aws\")\n",
    "    if (aws_cmd == \"\") {\n",
    "      aws_paths <- c(\n",
    "        \"/usr/local/bin/aws\",\n",
    "        \"/usr/bin/aws\",\n",
    "        \"/home/ec2-user/.local/bin/aws\"\n",
    "      )\n",
    "      aws_cmd <- NULL\n",
    "      for (path in aws_paths) {\n",
    "        if (file.exists(path)) {\n",
    "          aws_cmd <- path\n",
    "          break\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    \n",
    "    if (!is.null(aws_cmd) && aws_cmd != \"\") {\n",
    "      # Stop the instance (use terminate-instances for permanent deletion)\n",
    "      shutdown_cmd <- sprintf(\n",
    "        '\"%s\" ec2 stop-instances --instance-ids %s',\n",
    "        aws_cmd,\n",
    "        instance_id\n",
    "      )\n",
    "      \n",
    "      cat(\"Running:\", shutdown_cmd, \"\\n\")\n",
    "      result <- system(shutdown_cmd)\n",
    "      \n",
    "      if (result == 0) {\n",
    "        cat(\"âœ“ EC2 instance stop command sent successfully\\n\")\n",
    "        cat(\"Instance will stop in a few moments.\\n\")\n",
    "        cat(\"Note: This is a STOP (not terminate), so you can restart it later.\\n\")\n",
    "      } else {\n",
    "        warning(sprintf(\"EC2 stop command returned exit code %d. Check AWS credentials and permissions.\", result))\n",
    "      }\n",
    "    } else {\n",
    "      cat(\"Warning: AWS CLI not found. Cannot shutdown instance.\\n\")\n",
    "      cat(\"Install AWS CLI or ensure it's in your PATH.\\n\")\n",
    "    }\n",
    "  } else {\n",
    "    cat(\"Warning: Could not determine instance ID. Skipping shutdown.\\n\")\n",
    "    cat(\"If you want to shutdown manually, use:\\n\")\n",
    "    cat(\"  aws ec2 stop-instances --instance-ids <your-instance-id>\\n\")\n",
    "  }\n",
    "} else {\n",
    "  cat(\"\\n========================================\\n\")\n",
    "  cat(\"EC2 Auto-Shutdown: DISABLED\\n\")\n",
    "  cat(\"========================================\\n\")\n",
    "  cat(\"To enable auto-shutdown, set SHUTDOWN_EC2 = TRUE in this cell.\\n\")\n",
    "  cat(\"Instance will continue running.\\n\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R (PGX-Analysis)",
   "language": "R",
   "name": "pgx-analysis"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
