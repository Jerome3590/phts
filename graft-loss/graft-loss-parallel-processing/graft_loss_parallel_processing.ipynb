{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dc3f47a-8348-40aa-b8f8-5c04a854fe73",
   "metadata": {},
   "source": [
    "# Graft Loss: Three Dataset Parallel Execution Driver\n",
    "\n",
    "**Enhanced Pipeline Management for AWS Linux 2023 EC2**\n",
    "\n",
    "This notebook provides comprehensive management and monitoring for running the graft-loss pipeline across three datasets in parallel:\n",
    "\n",
    "- **Original Study** (2010-2019) \n",
    "- **Full Dataset with COVID** (2010-2023)\n",
    "- **Full Dataset without COVID** (2010-2019, excluding 2020+)\n",
    "\n",
    "Key Features:\n",
    "- ðŸš€ Parallel execution with resource optimization\n",
    "- ðŸ“Š Real-time monitoring with progress logging\n",
    "- ðŸ’¾ Memory optimization for large datasets (1TB RAM support)\n",
    "- ðŸŽ¯ Background execution with PID tracking\n",
    "\n",
    "All logs and step summaries are written to `logs/` by enhanced pipeline logger. Use the cells below to execute runs, then review summaries and monitoring outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaccd66",
   "metadata": {},
   "source": [
    "## ðŸ§© Stepwise Pipeline Execution (Manual/Debug)\n",
    "\n",
    "Use these cells to run each pipeline step individually. This is useful for debugging, validation, or running the pipeline outside the parallel orchestrator. Each cell is idempotent and can be run multiple times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27b2464-a99d-4ec5-8ec1-846c24fe1d60",
   "metadata": {},
   "source": [
    "### Step 0: Set Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c452a24-0ac3-4725-abc5-8bf29a2ca623",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Force-delete entire folder trees (including subfolders and files)\n",
    "rm_all_dirs <- function(dirs) {\n",
    "  for (dir_path in dirs) {\n",
    "    dir_path <- path.expand(dir_path)\n",
    "    if (dir.exists(dir_path)) {\n",
    "      message(\"Removing: \", dir_path)\n",
    "      unlink(dir_path, recursive = TRUE, force = TRUE)\n",
    "      message(\"âœ… Removed: \", dir_path)\n",
    "    } else {\n",
    "      message(\"âš ï¸ Directory not found: \", dir_path)\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "# Your directories - Updated to use current working directory\n",
    "base <- getwd()  # Use current working directory instead of ~/graft-loss-parallel-processing\n",
    "dirs <- file.path(base, c(\"model_data\", \"logs\", \"models\"))\n",
    "rm_all_dirs(dirs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e6231d-7f41-4e2d-9fbb-ded101b1a1be",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "R.version.string\n",
    "getRversion()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b254e0-87bd-4fa6-9b0c-54d9c8a185f1",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# In an R cell in Jupyter notebook\n",
    "source(\"scripts/R/check_model_versions.R\")\n",
    "\n",
    "# Check versions\n",
    "versions <- check_model_versions()\n",
    "print_model_versions(versions)\n",
    "\n",
    "# Check compatibility\n",
    "compatibility <- check_version_compatibility(versions)\n",
    "if (compatibility$critical_issues) {\n",
    "  cat(\"Warnings:\\n\")\n",
    "  for (warning in compatibility$warnings) {\n",
    "    cat(sprintf(\"  â€¢ %s\\n\", warning))\n",
    "  }\n",
    "  cat(\"\\nRecommendations:\\n\")\n",
    "  for (rec in compatibility$recommendations) {\n",
    "    cat(sprintf(\"  â€¢ %s\\n\", rec))\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f63775e-1baf-4469-a027-c738cb6bd1a1",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# run_step_local\n",
    "\n",
    "suppressPackageStartupMessages({\n",
    "  library(furrr)\n",
    "  library(purrr)\n",
    "  library(withr)\n",
    "  library(fs)\n",
    "  library(tibble)\n",
    "})\n",
    "\n",
    "# Set number of threads per worker for max CPU utilization\n",
    "threads_per_worker <- 8  # Adjust as needed for your instance\n",
    "Sys.setenv(\n",
    "  OMP_NUM_THREADS = as.character(threads_per_worker),\n",
    "  MKL_NUM_THREADS = as.character(threads_per_worker),\n",
    "  OPENBLAS_NUM_THREADS = as.character(threads_per_worker),\n",
    "  NUMEXPR_NUM_THREADS = as.character(threads_per_worker),\n",
    "  VECLIB_MAXIMUM_THREADS = as.character(threads_per_worker)\n",
    ")\n",
    "\n",
    "cohorts <- list(\n",
    "    original = list(\n",
    "      env = list(DATASET_COHORT = \"original\"),\n",
    "      log = file.path(getwd(), \"logs/orch_bg_original_study.log\")\n",
    "    ),\n",
    "    full_with_covid = list(\n",
    "      env = list(DATASET_COHORT = \"full_with_covid\"), \n",
    "      log = file.path(getwd(), \"logs/orch_bg_full_with_covid.log\")\n",
    "    ),\n",
    "    full_without_covid = list(\n",
    "      env = list(DATASET_COHORT = \"full_without_covid\"),\n",
    "      log = file.path(getwd(), \"logs/orch_bg_full_without_covid.log\")\n",
    "    )\n",
    "  )\n",
    "\n",
    "# Generic runner for local-only steps with proper orch_bg_* logging\n",
    "run_step_local <- function(step_label, script_rel, cohorts, workers = NULL, seed = TRUE) {\n",
    "  root <- getwd()\n",
    "  step_script <- file.path(root, script_rel)\n",
    "  if (!file.exists(step_script)) stop(sprintf(\"Script not found: %s\", step_script))\n",
    "\n",
    "  # Forked workers for Linux + local IO\n",
    "  if (is.null(workers)) workers <- max(1, min(3, parallel::detectCores() - 1))\n",
    "  plan(multicore, workers = workers)\n",
    "\n",
    "  on.exit(plan(sequential), add = TRUE)\n",
    "\n",
    "  results <- future_map(\n",
    "    names(cohorts),\n",
    "    function(cohort) {\n",
    "      cfg <- cohorts[[cohort]]\n",
    "      env_vars <- c(cfg$env, COHORT_NAME = cohort)\n",
    "      log_file <- cfg$log\n",
    "\n",
    "      tryCatch({\n",
    "        old_wd <- setwd(root); on.exit(setwd(old_wd), add = TRUE)\n",
    "        \n",
    "        # Create/ensure log directory exists\n",
    "        log_dir <- dirname(log_file)\n",
    "        dir.create(log_dir, showWarnings = FALSE, recursive = TRUE)\n",
    "        \n",
    "        # Enhanced logging function\n",
    "        log_with_resources <- function(message, step = step_label) {\n",
    "          timestamp <- format(Sys.time(), \"%Y-%m-%d %H:%M:%S\")\n",
    "          pid <- Sys.getpid()\n",
    "          \n",
    "          # Memory usage\n",
    "          mem_info <- tryCatch({\n",
    "            if (file.exists(\"/proc/meminfo\")) {\n",
    "              meminfo <- readLines(\"/proc/meminfo\")\n",
    "              total_mem <- as.numeric(gsub(\".*: *([0-9]+) kB\", \"\\\\1\", meminfo[grep(\"MemTotal\", meminfo)])) / 1024 / 1024\n",
    "              avail_mem <- as.numeric(gsub(\".*: *([0-9]+) kB\", \"\\\\1\", meminfo[grep(\"MemAvailable\", meminfo)])) / 1024 / 1024\n",
    "              used_mem <- total_mem - avail_mem\n",
    "              sprintf(\"MEM: %.1f/%.1f GB (%.1f%%)\", used_mem, total_mem, (used_mem/total_mem)*100)\n",
    "            } else {\n",
    "              gc_info <- gc()\n",
    "              sprintf(\"MEM: %.1f MB\", sum(gc_info[,2]))\n",
    "            }\n",
    "          }, error = function(e) \"MEM: N/A\")\n",
    "          \n",
    "          # CPU usage\n",
    "          cpu_info <- tryCatch({\n",
    "            if (Sys.which(\"ps\") != \"\") {\n",
    "              ps_out <- system(sprintf(\"ps -p %d -o pcpu= 2>/dev/null || echo 'N/A'\", pid), intern = TRUE)\n",
    "              if (length(ps_out) > 0 && ps_out != \"N/A\") {\n",
    "                sprintf(\"CPU: %s%%\", trimws(ps_out))\n",
    "              } else \"CPU: N/A\"\n",
    "            } else \"CPU: N/A\"\n",
    "          }, error = function(e) \"CPU: N/A\")\n",
    "          \n",
    "          # Format log entry\n",
    "          step_info <- if (!is.null(step)) sprintf(\"[STEP: %s] \", step) else \"\"\n",
    "          log_entry <- sprintf(\"[%s] [%s] %s| %s | %s | %s\", \n",
    "                              timestamp, cohort, step_info, mem_info, cpu_info, message)\n",
    "          \n",
    "          # Write to both console and log file\n",
    "          cat(log_entry, \"\\n\")\n",
    "          cat(log_entry, \"\\n\", file = log_file, append = TRUE)\n",
    "        }\n",
    "        \n",
    "        # Log step start\n",
    "        log_with_resources(sprintf(\"Starting %s\", step_label))\n",
    "\n",
    "        msgs <- character(); wns <- character()\n",
    "        t0 <- proc.time()\n",
    "        \n",
    "        # Capture output and write to log\n",
    "        output_conn <- file(log_file, open = \"a\")\n",
    "        sink(output_conn, split = TRUE)\n",
    "        sink(output_conn, type = \"message\", append = TRUE)\n",
    "        \n",
    "        on.exit({\n",
    "          try(sink(type = \"message\"))\n",
    "          try(sink())\n",
    "          try(close(output_conn))\n",
    "        }, add = TRUE)\n",
    "        \n",
    "        withCallingHandlers(\n",
    "          {\n",
    "            with_envvar(env_vars, {\n",
    "              source(step_script, local = new.env(parent = globalenv()))\n",
    "            })\n",
    "          },\n",
    "          message = function(m) msgs <<- c(msgs, conditionMessage(m)),\n",
    "          warning = function(w) wns  <<- c(wns,  conditionMessage(w))\n",
    "        )\n",
    "        elapsed <- as.numeric((proc.time() - t0)[[\"elapsed\"]])\n",
    "        \n",
    "        # Log completion\n",
    "        log_with_resources(sprintf(\"Completed %s (%.2f seconds)\", step_label, elapsed))\n",
    "\n",
    "        tail_lines <- if (file.exists(log_file)) {\n",
    "          tryCatch(utils::tail(readLines(log_file, warn = FALSE), 10),\n",
    "                   error = function(e) sprintf(\"<could not read log: %s>\", e$message))\n",
    "        } else {\n",
    "          \"<log file not found; run pipeline to generate logs>\"\n",
    "        }\n",
    "\n",
    "        list(\n",
    "          cohort   = cohort,\n",
    "          step     = step_label,\n",
    "          status   = \"ok\",\n",
    "          runtime_s = elapsed,\n",
    "          warnings = wns,\n",
    "          messages = msgs,\n",
    "          log_path = log_file,\n",
    "          log_tail = tail_lines,\n",
    "          error    = NULL\n",
    "        )\n",
    "      }, error = function(e) {\n",
    "        # Log error\n",
    "        tryCatch({\n",
    "          log_with_resources(sprintf(\"ERROR in %s: %s\", step_label, conditionMessage(e)))\n",
    "        }, error = function(e2) {\n",
    "          # Fallback if logging fails\n",
    "          cat(sprintf(\"ERROR in %s: %s\\n\", step_label, conditionMessage(e)), file = log_file, append = TRUE)\n",
    "        })\n",
    "        \n",
    "        list(\n",
    "          cohort   = cohort,\n",
    "          step     = step_label,\n",
    "          status   = \"error\",\n",
    "          runtime_s = NA_real_,\n",
    "          warnings = NULL,\n",
    "          messages = NULL,\n",
    "          log_path = log_file,\n",
    "          log_tail = NULL,\n",
    "          error    = conditionMessage(e)\n",
    "        )\n",
    "      })\n",
    "    },\n",
    "    .options = furrr_options(seed = isTRUE(seed))\n",
    "  )\n",
    "\n",
    "  # Print concise summary and also return a tibble of results\n",
    "  cat(sprintf(\"\\n==== Batch Summary (%s) ====\\n\", step_label))\n",
    "  walk(results, function(r) {\n",
    "    cat(sprintf(\"\\n--- %s ---\\n\", r$cohort))\n",
    "    cat(sprintf(\"Status: %s\\n\", r$status))\n",
    "    if (!is.null(r$error))   cat(sprintf(\"Error: %s\\n\", r$error))\n",
    "    if (!is.na(r$runtime_s)) cat(sprintf(\"Runtime (s): %.2f\\n\", r$runtime_s))\n",
    "    if (length(r$warnings))  cat(sprintf(\"Warnings: %s\\n\", paste(r$warnings, collapse = \" | \")))\n",
    "    if (length(r$messages))  cat(sprintf(\"Messages: %s\\n\", paste(r$messages, collapse = \" | \")))\n",
    "    cat(sprintf(\"Log: %s\\n\", r$log_path))\n",
    "    if (!is.null(r$log_tail)) {\n",
    "      cat(\"--- Last 10 log lines ---\\n\")\n",
    "      cat(paste0(r$log_tail, collapse = \"\\n\"), \"\\n\")\n",
    "    }\n",
    "  })\n",
    "  cat(\"\\n=======================\\n\")\n",
    "\n",
    "  # Return structured data for programmatic checks\n",
    "  as_tibble(map_dfr(results, ~as.list(.x)[c(\"cohort\",\"step\",\"status\",\"runtime_s\",\"error\",\"log_path\")]))\n",
    "}\n",
    "\n",
    "# Now you can use run_step_local in your notebook\n",
    "cat(\"run_step_local function is now available!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25d63ce-0d86-4f1b-9285-1dff0b7fcdc3",
   "metadata": {},
   "source": [
    "### Step 1: Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8610e3e3-43f8-49fc-a949-ae4bf815602c",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Step 1\n",
    "run_step_local(\"STEP 1: Prepare Data\", \"pipeline/01_prepare_data.R\", cohorts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea1fa43-9e84-4bb7-a7e2-71eb4c4483e8",
   "metadata": {},
   "source": [
    "### Step 2: Resampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bd2535-f26a-4a5e-ba4c-8b469a9adbd5",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Step 2\n",
    "run_step_local(\"STEP 2: Resampling\", \"pipeline/02_resampling.R\", cohorts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e31358-1dea-4a66-86a2-2ea38e60fcdd",
   "metadata": {},
   "source": [
    "### Step 3: Prepare Model Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1041eeac-67df-4f90-897e-45a80b5717f7",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Step 3\n",
    "run_step_local(\"STEP 3: Prepare Model Data\", \"pipeline/03_prep_model_data.R\", cohorts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2088c26",
   "metadata": {},
   "source": [
    "Model (Data Setup, Model Fitting, Aggregate Results)\n",
    "\n",
    "Settings (recommended for 3 cohorts)\n",
    "\n",
    "- The model-fitting stage is now split into modular pipeline steps (04â€“08) to improve debuggability and monitoring:\n",
    "  - `pipeline/04_data_setup.R` â€” per-cohort data setup and final dataset preparation\n",
    "  - `pipeline/05_mc_cv_analysis.R` â€” Monte Carlo cross-validation analysis and split execution\n",
    "  - `pipeline/06_parallel_model_fitting.R` â€” parallel model fitting across splits and models\n",
    "  - `pipeline/07_model_saving.R` â€” save final models and create index files\n",
    "  - `pipeline/08_fallback_handling.R` â€” fallback handling and recovery steps\n",
    "\n",
    "Recommended environment settings for per-cohort runs:\n",
    "\n",
    "- MC_PLAN: `multisession`\n",
    "- MC_WORKER_THREADS: `1`\n",
    "- MC_SPLIT_WORKERS per cohort: `floor(available_cores * 0.8 / 3)`\n",
    "\n",
    "Examples (per-cohort background runs):\n",
    "\n",
    "```r\n",
    "# Cohort A (modular pipeline)\n",
    "Sys.setenv(DATASET_COHORT=\"full_with_covid\", MC_PLAN=\"multisession\", MC_SPLIT_WORKERS=\"4\", MC_WORKER_THREADS=\"1\")\n",
    "source(\"pipeline/06_parallel_model_fitting.R\")  # runs modularized fitting step (04->08 can be sourced sequentially inside the wrapper)\n",
    "\n",
    "# Cohort B\n",
    "Sys.setenv(DATASET_COHORT=\"original\", MC_PLAN=\"multisession\", MC_SPLIT_WORKERS=\"4\", MC_WORKER_THREADS=\"1\")\n",
    "source(\"pipeline/06_parallel_model_fitting.R\")\n",
    "\n",
    "# Cohort C\n",
    "Sys.setenv(DATASET_COHORT=\"full_without_covid\", MC_PLAN=\"multisession\", MC_SPLIT_WORKERS=\"4\", MC_WORKER_THREADS=\"1\")\n",
    "source(\"pipeline/06_parallel_model_fitting.R\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce94445-d0f4-4d72-a2b3-7da5cd341348",
   "metadata": {},
   "source": [
    "### Step 4: Data Setup and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6261d2",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Load environment transition utilities\n",
    "source(\"scripts/R/environment_transition.R\")\n",
    "\n",
    "# Updated cohorts with proper environment variables for steps 4-8\n",
    "cohorts_enhanced <- list(\n",
    "  original = list(\n",
    "    env = list(\n",
    "      DATASET_COHORT = \"original\",\n",
    "      MC_CV = \"1\",\n",
    "      MC_TIMES = \"25\", \n",
    "      USE_ENCODED = \"0\",\n",
    "      XGB_FULL = \"0\",\n",
    "      USE_CATBOOST = \"0\",\n",
    "      FINAL_MODEL_WORKERS = \"4\",\n",
    "      FINAL_MODEL_PLAN = \"multisession\",\n",
    "      MC_WORKER_THREADS = \"8\",\n",
    "      OMP_NUM_THREADS = \"1\",\n",
    "      MKL_NUM_THREADS = \"1\",\n",
    "      OPENBLAS_NUM_THREADS = \"1\",\n",
    "      VECLIB_MAXIMUM_THREADS = \"1\",\n",
    "      NUMEXPR_NUM_THREADS = \"1\"\n",
    "    ),\n",
    "    log = file.path(getwd(), \"logs/orch_bg_original_study.log\")\n",
    "  ),\n",
    "  full_with_covid = list(\n",
    "    env = list(\n",
    "      DATASET_COHORT = \"full_with_covid\",\n",
    "      MC_CV = \"1\",\n",
    "      MC_TIMES = \"25\",\n",
    "      USE_ENCODED = \"0\", \n",
    "      XGB_FULL = \"0\",\n",
    "      USE_CATBOOST = \"0\",\n",
    "      FINAL_MODEL_WORKERS = \"4\",\n",
    "      FINAL_MODEL_PLAN = \"multisession\",\n",
    "      MC_WORKER_THREADS = \"8\",\n",
    "      OMP_NUM_THREADS = \"1\",\n",
    "      MKL_NUM_THREADS = \"1\",\n",
    "      OPENBLAS_NUM_THREADS = \"1\",\n",
    "      VECLIB_MAXIMUM_THREADS = \"1\",\n",
    "      NUMEXPR_NUM_THREADS = \"1\"\n",
    "    ),\n",
    "    log = file.path(getwd(), \"logs/orch_bg_full_with_covid.log\")\n",
    "  ),\n",
    "  full_without_covid = list(\n",
    "    env = list(\n",
    "      DATASET_COHORT = \"full_without_covid\",\n",
    "      MC_CV = \"1\",\n",
    "      MC_TIMES = \"25\",\n",
    "      USE_ENCODED = \"0\",\n",
    "      XGB_FULL = \"0\", \n",
    "      USE_CATBOOST = \"0\",\n",
    "      FINAL_MODEL_WORKERS = \"4\",\n",
    "      FINAL_MODEL_PLAN = \"multisession\",\n",
    "      MC_WORKER_THREADS = \"8\",\n",
    "      OMP_NUM_THREADS = \"1\",\n",
    "      MKL_NUM_THREADS = \"1\",\n",
    "      OPENBLAS_NUM_THREADS = \"1\",\n",
    "      VECLIB_MAXIMUM_THREADS = \"1\",\n",
    "      NUMEXPR_NUM_THREADS = \"1\"\n",
    "    ),\n",
    "    log = file.path(getwd(), \"logs/orch_bg_full_without_covid.log\")\n",
    "  )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c8affb",
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "run_step_local(\"STEP 4: Data Setup\", \"pipeline/04_data_setup.R\", cohorts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d8a18a-f9bf-4ecf-9321-30e41e7d6197",
   "metadata": {},
   "source": [
    "### Step 5: MC-CV Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4ce4fa",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "run_step_local(\"STEP 5: MC-CV Analysis\", \"pipeline/05_mc_cv_analysis.R\", cohorts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146b544a-d6f2-45eb-86ad-d56dadd17865",
   "metadata": {},
   "source": [
    "### Step 6: Parallel Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7597bfda",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Step 6: Parallel Model Fitting\n",
    "run_step_local(\"STEP 6: Parallel Model Fitting\", \"pipeline/06_parallel_model_fitting.R\", cohorts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea97856-bdc1-4507-aa41-34e7c71e5288",
   "metadata": {},
   "source": [
    "### Step 7 Generate Outputs/C-Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1ac19d",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Step 7: Generate Outputs (formerly Step 5)\n",
    "run_step_local(\"STEP 7: Generate Outputs\", \"pipeline/07_generate_outputs.R\", cohorts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd601252",
   "metadata": {},
   "source": [
    "### Step 8 ðŸ“ˆ C-Index Results and Summary Visualizations\n",
    "\n",
    "This section summarizes Uno's 1-year C-index across all cohorts and provides a table and plot for model performance comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66823a3a-8bf7-44ce-ac8c-a1eff84c86a6",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "readr::read_csv(\"model_data/model_comparison_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b529557f",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Uno 1-year C-index Summary Table and Plot\n",
    "suppressPackageStartupMessages({\n",
    "  library(readr); library(dplyr); library(ggplot2); library(gt); library(here)\n",
    "})\n",
    "labels <- c(\"full\",\"original\",\"covid\",\"full_no_covid\")\n",
    "paths <- setNames(file.path(here::here(\"data\",\"models\"), sprintf(\"model_mc_summary_%s_uno.csv\", labels)), labels)\n",
    "summaries <- lapply(names(paths)[file.exists(paths)], function(lab){\n",
    "  readr::read_csv(paths[[lab]], show_col_types = FALSE) %>% mutate(label = lab)\n",
    "})\n",
    "res <- bind_rows(summaries) %>%\n",
    "  mutate(mean = coalesce(mean, uno, AppCindex, AppC, AUC)) %>%\n",
    "  mutate(se = ifelse(!is.na(sd) & !is.na(n_splits) & n_splits > 1, sd/sqrt(n_splits), NA_real_),\n",
    "            lwr = ifelse(!is.na(se), mean - 1.96*se, NA_real_),\n",
    "            upr = ifelse(!is.na(se), mean + 1.96*se, NA_real_)) %>%\n",
    "  select(label, n_splits, mean, sd, lwr, upr)\n",
    "\n",
    "# Table\n",
    "res %>% transmute(Cohort = label, Splits = n_splits,\n",
    "                  `Uno C (mean)` = round(mean,3),\n",
    "                  `95% CI` = ifelse(is.na(lwr)|is.na(upr), \"â€”\", sprintf(\"[%.3f, %.3f]\", lwr, upr))) %>%\n",
    "  gt::gt() %>% gt::fmt_missing(everything(), missing_text = \"â€”\") %>%\n",
    "  gt::tab_header(title = gt::md(\"Uno 1-year C-index by cohort\")) %>% print()\n",
    "\n",
    "# Plot\n",
    "if (nrow(res) > 0) {\n",
    "  ggplot(res, aes(x = label, y = mean)) +\n",
    "    geom_point(size = 3) +\n",
    "    geom_errorbar(aes(ymin = lwr, ymax = upr), width = 0.15, na.rm = TRUE) +\n",
    "    coord_cartesian(ylim = c(0.5, 1.0)) +\n",
    "    labs(x = \"Cohort\", y = \"Uno C-index (1 year)\", title = \"Uno C-index by cohort (mean Â± 95% CI)\") +\n",
    "    theme_minimal(base_size = 12)\n",
    "} else {\n",
    "  cat(\"No C-index summary files found. Run the pipeline to generate results.\\n\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79d6da4-3873-42c7-81fe-c7f403ea12ee",
   "metadata": {},
   "source": [
    "## Sync Files to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45551df-e027-4aca-a202-00f38fbb8a7f",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "system(paste(\n",
    "  \"aws s3 sync . s3://uva-private-data-lake/graft-loss-parallel-processing/\",\n",
    "  \"--delete\",\n",
    "  \"--exclude '*checkpoint*'\",\n",
    "  \"--exclude '*.tmp'\",\n",
    "  \"--exclude '.ipynb_checkpoints/*'\"\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682ab843",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
