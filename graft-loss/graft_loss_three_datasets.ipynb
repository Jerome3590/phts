{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graft Loss: Three Dataset Parallel Execution Driver\n",
    "\n",
    "**Enhanced Pipeline Management for AWS Linux 2023 EC2**\n",
    "\n",
    "This notebook provides comprehensive management and monitoring for running the graft-loss pipeline across three datasets in parallel:\n",
    "\n",
    "- **Original Study** (2010-2019) \n",
    "- **Full Dataset with COVID** (2010-2023)\n",
    "- **Full Dataset without COVID** (2010-2019, excluding 2020+)\n",
    "\n",
    "## Key Features:\n",
    "- ðŸš€ Parallel execution with resource optimization\n",
    "- ðŸ“Š Real-time monitoring with progress logging\n",
    "- ðŸ’¾ Memory optimization for large datasets (1TB RAM support)\n",
    "- ðŸŽ¯ Background execution with PID tracking\n",
    "- ðŸ”’ Idempotent design - safe to run multiple times\n",
    "\n",
    "All logs and step summaries are written to `logs/` by enhanced pipeline logger. Use the cells below to execute runs, then review summaries and monitoring outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1612433403.py, line 13)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mmemory_info <- function() {\u001b[39m\n                              ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Enhanced Resource Monitor with Memory Management\n",
    "# Prevents browser crashes during monitoring\n",
    "\n",
    "cat(\"ðŸ–¥ï¸  System Resource Monitor\\n\")\n",
    "cat(\"========================\\n\")\n",
    "flush.console()\n",
    "\n",
    "# Memory management: Clear environment\n",
    "rm(list = ls())\n",
    "gc(verbose = FALSE)\n",
    "\n",
    "# Check system resources\n",
    "memory_info <- function() {\n",
    "  tryCatch({\n",
    "    if (file.exists(\"/proc/meminfo\")) {\n",
    "      meminfo <- readLines(\"/proc/meminfo\")\n",
    "      total <- as.numeric(gsub(\".*: *([0-9]+) kB\", \"\\\\1\", meminfo[grep(\"MemTotal\", meminfo)])) / 1024 / 1024\n",
    "      avail <- as.numeric(gsub(\".*: *([0-9]+) kB\", \"\\\\1\", meminfo[grep(\"MemAvailable\", meminfo)])) / 1024 / 1024  \n",
    "      sprintf(\"Memory: %.1f GB available of %.1f GB total\", avail, total)\n",
    "    } else {\n",
    "      \"Memory info not available\"\n",
    "    }\n",
    "  }, error = function(e) \"Memory detection failed\")\n",
    "}\n",
    "\n",
    "cat(memory_info(), \"\\n\")\n",
    "flush.console()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš™ï¸ EC2 Troubleshooting\n",
    "\n",
    "If experiencing file load errors on EC2, run the diagnostic cell below first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EC2 File Load Error Diagnostics & Fix\n",
    "# Run this first if experiencing file loading issues on EC2\n",
    "\n",
    "cat(\"ðŸ”§ EC2 Diagnostics & Startup Check\\n\")\n",
    "cat(\"==================================\\n\")\n",
    "\n",
    "# Check critical files exist\n",
    "critical_files <- c(\n",
    "  \"scripts/run_three_datasets.R\",\n",
    "  \"scripts/enhanced_pipeline_logger_v2.R\", \n",
    "  \"R/utils/parallel_utils.R\",\n",
    "  \"scripts/run_pipeline.R\"\n",
    ")\n",
    "\n",
    "all_ok <- TRUE\n",
    "for (file in critical_files) {\n",
    "  if (file.exists(file)) {\n",
    "    cat(sprintf(\"âœ… %s\\n\", file))\n",
    "  } else {\n",
    "    cat(sprintf(\"âŒ %s (MISSING)\\n\", file))\n",
    "    all_ok <- FALSE\n",
    "  }\n",
    "}\n",
    "\n",
    "# Check directories\n",
    "required_dirs <- c(\"logs\", \"R/utils\", \"scripts\")\n",
    "for (dir in required_dirs) {\n",
    "  if (!dir.exists(dir)) {\n",
    "    dir.create(dir, recursive = TRUE, showWarnings = FALSE)\n",
    "    cat(sprintf(\"âœ… Created directory: %s\\n\", dir))\n",
    "  }\n",
    "}\n",
    "\n",
    "# Set environment for EC2\n",
    "Sys.setenv(R_MAX_VSIZE = \"950Gb\")\n",
    "Sys.setenv(OMP_NUM_THREADS = \"1\")\n",
    "cat(\"âœ… Environment configured for EC2\\n\")\n",
    "\n",
    "if (all_ok) {\n",
    "  cat(\"\\nðŸŸ¢ All systems ready for pipeline execution!\\n\")\n",
    "} else {\n",
    "  cat(\"\\nðŸ”´ Issues detected - fix missing files before proceeding\\n\")\n",
    "}\n",
    "\n",
    "flush.console()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸš€ Launch Parallel Execution\n",
    "\n",
    "The launcher below is **idempotent** - safe to run multiple times. It will detect existing processes and prevent duplicate launches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idempotent 3-Dataset Pipeline Launcher\n",
    "# Ensures only one instance runs - safe to execute multiple times\n",
    "\n",
    "dir.create(\"logs\", showWarnings = FALSE)\n",
    "\n",
    "# Set R memory environment\n",
    "Sys.setenv(R_MAX_VSIZE = \"950Gb\")\n",
    "\n",
    "# Check if orchestrator exists\n",
    "if (!file.exists(\"scripts/run_three_datasets.R\")) {\n",
    "  cat(\"âŒ Error: scripts/run_three_datasets.R not found\\n\")\n",
    "  cat(\"Available scripts:\\n\")\n",
    "  print(list.files(\"scripts\", pattern = \"\\\\.R$\"))\n",
    "  stop(\"Missing orchestrator script\")\n",
    "}\n",
    "\n",
    "# Idempotent check: Look for running pipeline processes\n",
    "check_running_pipelines <- function() {\n",
    "  # Check for orchestrator process\n",
    "  orch_check <- system(\"pgrep -f 'run_three_datasets.R'\", ignore.stdout = TRUE, ignore.stderr = TRUE)\n",
    "  \n",
    "  # Check for individual dataset processes  \n",
    "  dataset_check <- system(\"pgrep -f 'enhanced_pipeline_logger_v2.R'\", ignore.stdout = TRUE, ignore.stderr = TRUE)\n",
    "  \n",
    "  # Check PID file if it exists\n",
    "  pid_file_exists <- file.exists(\"logs/parallel_config.log\")\n",
    "  \n",
    "  return(list(\n",
    "    orchestrator_running = (orch_check == 0),\n",
    "    datasets_running = (dataset_check == 0), \n",
    "    pid_file_exists = pid_file_exists\n",
    "  ))\n",
    "}\n",
    "\n",
    "# Get current status\n",
    "status <- check_running_pipelines()\n",
    "\n",
    "cat(\"ðŸ” Pipeline Status Check\\n\")\n",
    "cat(\"========================\\n\")\n",
    "cat(sprintf(\"Orchestrator running: %s\\n\", ifelse(status$orchestrator_running, \"âœ… YES\", \"âŒ NO\")))\n",
    "cat(sprintf(\"Dataset processes: %s\\n\", ifelse(status$datasets_running, \"âœ… ACTIVE\", \"âŒ NONE\")))\n",
    "cat(sprintf(\"Config log exists: %s\\n\", ifelse(status$pid_file_exists, \"âœ… YES\", \"âŒ NO\")))\n",
    "flush.console()\n",
    "\n",
    "if (status$orchestrator_running || status$datasets_running) {\n",
    "  cat(\"\\nðŸŸ¡ PIPELINE ALREADY RUNNING\\n\")\n",
    "  cat(\"=========================\\n\")\n",
    "  cat(\"The 3-dataset parallel pipeline is already active.\\n\")\n",
    "  cat(\"Use the monitoring cells below to check progress.\\n\")\n",
    "  cat(\"To restart, first stop the current run in the management cell.\\n\\n\")\n",
    "  flush.console()\n",
    "  \n",
    "  # Show current PIDs if available\n",
    "  if (status$pid_file_exists) {\n",
    "    cat(\"ðŸ“‹ Current process info:\\n\")\n",
    "    tryCatch({\n",
    "      recent_log <- tail(readLines(\"logs/parallel_config.log\"), 3)\n",
    "      cat(paste(recent_log, collapse = \"\\n\"), \"\\n\")\n",
    "    }, error = function(e) cat(\"Could not read recent log entries\\n\"))\n",
    "  }\n",
    "  \n",
    "} else {\n",
    "  cat(\"\\nðŸš€ LAUNCHING NEW PIPELINE\\n\")\n",
    "  cat(\"=========================\\n\")\n",
    "  flush.console()\n",
    "  \n",
    "  # Clean up old logs to start fresh\n",
    "  old_logs <- list.files(\"logs\", pattern = \"(orch_|parallel_config)\", full.names = TRUE)\n",
    "  if (length(old_logs) > 0) {\n",
    "    file.remove(old_logs)\n",
    "    cat(\"ðŸ§¹ Cleared old log files\\n\")\n",
    "  }\n",
    "  \n",
    "  # Launch the pipeline\n",
    "  launch_cmd <- 'nohup Rscript scripts/run_three_datasets.R > logs/orch_parallel.log 2>&1 & echo $!'\n",
    "  \n",
    "  result <- tryCatch({\n",
    "    pid_output <- system(launch_cmd, intern = TRUE)\n",
    "    pid_output\n",
    "  }, error = function(e) {\n",
    "    paste(\"ERROR:\", e$message)\n",
    "  })\n",
    "  \n",
    "  # Process result\n",
    "  if (length(result) > 0 && !grepl(\"ERROR|error|failed\", result[1], ignore.case = TRUE)) {\n",
    "    pid <- result[1]\n",
    "    \n",
    "    if (grepl(\"^[0-9]+$\", pid)) {\n",
    "      cat(\"âœ… Successfully launched parallel orchestrator!\\n\")\n",
    "      cat(sprintf(\"Process ID: %s\\n\", pid))\n",
    "      cat(\"System: AWS Linux 2023 EC2 (1TB RAM)\\n\")\n",
    "      cat(\"Memory: R_MAX_VSIZE=950Gb\\n\")\n",
    "      cat(\"Orchestrator log: logs/orch_parallel.log\\n\\n\")\n",
    "      flush.console()\n",
    "      \n",
    "      cat(\"ðŸ“Š Expected dataset logs:\\n\")\n",
    "      cat(\"  - logs/orch_bg_original_study.log\\n\")\n",
    "      cat(\"  - logs/orch_bg_full_with_covid.log\\n\") \n",
    "      cat(\"  - logs/orch_bg_full_without_covid.log\\n\\n\")\n",
    "      flush.console()\n",
    "      \n",
    "      # Log the successful launch with timestamp\n",
    "      launch_log <- sprintf(\"Pipeline launched: PID %s at %s\\n\", pid, Sys.time())\n",
    "      cat(launch_log, file = \"logs/parallel_config.log\", append = TRUE)\n",
    "      \n",
    "      cat(\"ðŸ” Use monitoring cells below to track progress\\n\")\n",
    "      flush.console()\n",
    "      \n",
    "    } else {\n",
    "      cat(\"âš ï¸  Launch completed but PID format unexpected:\", pid, \"\\n\")\n",
    "      flush.console()\n",
    "    }\n",
    "  } else {\n",
    "    cat(\"âŒ Launch failed\\n\")\n",
    "    cat(\"Output:\", paste(result, collapse = \"\\n\"), \"\\n\")\n",
    "    flush.console()\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline Management - Stop/Restart Control\n",
    "# Idempotent management of pipeline processes\n",
    "\n",
    "cat(\"ðŸŽ›ï¸  Pipeline Management Control\\n\")\n",
    "cat(\"===============================\\n\")\n",
    "\n",
    "# Function to safely stop all pipeline processes\n",
    "stop_pipeline <- function() {\n",
    "  stopped_count <- 0\n",
    "  \n",
    "  # Stop orchestrator processes\n",
    "  orch_pids <- system(\"pgrep -f 'run_three_datasets.R'\", intern = TRUE, ignore.stderr = TRUE)\n",
    "  if (length(orch_pids) > 0 && !any(grepl(\"ERROR\", orch_pids))) {\n",
    "    for (pid in orch_pids) {\n",
    "      if (grepl(\"^[0-9]+$\", pid)) {\n",
    "        system(sprintf(\"kill %s\", pid), ignore.stdout = TRUE, ignore.stderr = TRUE)\n",
    "        stopped_count <- stopped_count + 1\n",
    "        cat(sprintf(\"ðŸ›‘ Stopped orchestrator PID %s\\n\", pid))\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  # Stop dataset logger processes  \n",
    "  logger_pids <- system(\"pgrep -f 'enhanced_pipeline_logger_v2.R'\", intern = TRUE, ignore.stderr = TRUE)\n",
    "  if (length(logger_pids) > 0 && !any(grepl(\"ERROR\", logger_pids))) {\n",
    "    for (pid in logger_pids) {\n",
    "      if (grepl(\"^[0-9]+$\", pid)) {\n",
    "        system(sprintf(\"kill %s\", pid), ignore.stdout = TRUE, ignore.stderr = TRUE)\n",
    "        stopped_count <- stopped_count + 1\n",
    "        cat(sprintf(\"ðŸ›‘ Stopped dataset logger PID %s\\n\", pid))\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  # Stop any remaining R processes running the pipeline\n",
    "  pipeline_pids <- system(\"pgrep -f 'run_pipeline.R'\", intern = TRUE, ignore.stderr = TRUE)\n",
    "  if (length(pipeline_pids) > 0 && !any(grepl(\"ERROR\", pipeline_pids))) {\n",
    "    for (pid in pipeline_pids) {\n",
    "      if (grepl(\"^[0-9]+$\", pid)) {\n",
    "        system(sprintf(\"kill %s\", pid), ignore.stdout = TRUE, ignore.stderr = TRUE)  \n",
    "        stopped_count <- stopped_count + 1\n",
    "        cat(sprintf(\"ðŸ›‘ Stopped pipeline process PID %s\\n\", pid))\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  return(stopped_count)\n",
    "}\n",
    "\n",
    "# Check current status first\n",
    "orch_running <- system(\"pgrep -f 'run_three_datasets.R'\", ignore.stdout = TRUE, ignore.stderr = TRUE) == 0\n",
    "datasets_running <- system(\"pgrep -f 'enhanced_pipeline_logger_v2.R'\", ignore.stdout = TRUE, ignore.stderr = TRUE) == 0\n",
    "\n",
    "cat(sprintf(\"Current status: %s\\n\", \n",
    "    ifelse(orch_running || datasets_running, \"ðŸŸ¢ RUNNING\", \"ðŸ”´ STOPPED\")))\n",
    "\n",
    "if (orch_running || datasets_running) {\n",
    "  cat(\"\\nâš ï¸  STOPPING ALL PIPELINE PROCESSES\\n\")\n",
    "  cat(\"This will gracefully terminate the current run.\\n\")\n",
    "  flush.console()\n",
    "  \n",
    "  stopped <- stop_pipeline()\n",
    "  \n",
    "  if (stopped > 0) {\n",
    "    cat(sprintf(\"\\nâœ… Successfully stopped %d processes\\n\", stopped))\n",
    "    cat(\"Pipeline is now stopped. You can safely restart using the launch cell.\\n\")\n",
    "    \n",
    "    # Log the stop action\n",
    "    stop_log <- sprintf(\"Pipeline stopped: %d processes terminated at %s\\n\", stopped, Sys.time())\n",
    "    cat(stop_log, file = \"logs/parallel_config.log\", append = TRUE)\n",
    "  } else {\n",
    "    cat(\"\\nðŸ¤· No pipeline processes found to stop\\n\")\n",
    "  }\n",
    "} else {\n",
    "  cat(\"\\nâœ… No pipeline processes are currently running\\n\")\n",
    "  cat(\"You can start the pipeline using the launch cell above.\\n\")\n",
    "}\n",
    "\n",
    "# Clean memory after management operations\n",
    "gc(verbose = FALSE)\n",
    "flush.console()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real-time Pipeline Status Monitor\n",
    "# Safe to run multiple times - shows current state\n",
    "\n",
    "cat(\"ðŸ“Š Pipeline Status Monitor\\n\")\n",
    "cat(\"==========================\\n\")\n",
    "\n",
    "# Memory management for browser safety\n",
    "gc(verbose = FALSE)\n",
    "\n",
    "# Check process status\n",
    "check_pipeline_status <- function() {\n",
    "  # Get orchestrator PIDs\n",
    "  orch_pids <- tryCatch({\n",
    "    pids <- system(\"pgrep -f 'run_three_datasets.R'\", intern = TRUE, ignore.stderr = TRUE)\n",
    "    if (length(pids) > 0 && !any(grepl(\"ERROR\", pids)) && all(grepl(\"^[0-9]+$\", pids))) {\n",
    "      pids\n",
    "    } else {\n",
    "      character(0)\n",
    "    }\n",
    "  }, error = function(e) character(0))\n",
    "  \n",
    "  # Get dataset logger PIDs  \n",
    "  logger_pids <- tryCatch({\n",
    "    pids <- system(\"pgrep -f 'enhanced_pipeline_logger_v2.R'\", intern = TRUE, ignore.stderr = TRUE)\n",
    "    if (length(pids) > 0 && !any(grepl(\"ERROR\", pids)) && all(grepl(\"^[0-9]+$\", pids))) {\n",
    "      pids\n",
    "    } else {\n",
    "      character(0)\n",
    "    }\n",
    "  }, error = function(e) character(0))\n",
    "  \n",
    "  return(list(\n",
    "    orchestrator = orch_pids,\n",
    "    loggers = logger_pids,\n",
    "    total_processes = length(orch_pids) + length(logger_pids)\n",
    "  ))\n",
    "}\n",
    "\n",
    "# Get current status\n",
    "status <- check_pipeline_status()\n",
    "\n",
    "# Display status with timestamp\n",
    "cat(sprintf(\"Status at %s\\n\", format(Sys.time(), \"%Y-%m-%d %H:%M:%S\")))\n",
    "cat(\"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\n\")\n",
    "\n",
    "if (status$total_processes == 0) {\n",
    "  cat(\"ðŸ”´ PIPELINE STOPPED\\n\")\n",
    "  cat(\"No active processes found.\\n\")\n",
    "} else {\n",
    "  cat(\"ðŸŸ¢ PIPELINE ACTIVE\\n\")\n",
    "  cat(sprintf(\"Total processes: %d\\n\", status$total_processes))\n",
    "  \n",
    "  if (length(status$orchestrator) > 0) {\n",
    "    cat(sprintf(\"Orchestrator PIDs: %s\\n\", paste(status$orchestrator, collapse = \", \")))\n",
    "  }\n",
    "  \n",
    "  if (length(status$loggers) > 0) {\n",
    "    cat(sprintf(\"Dataset loggers: %d processes\\n\", length(status$loggers)))\n",
    "  }\n",
    "}\n",
    "\n",
    "# Check log files and show recent activity\n",
    "cat(\"\\nðŸ“‹ Log File Status\\n\")\n",
    "cat(\"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\n\")\n",
    "\n",
    "log_files <- c(\n",
    "  \"logs/orch_parallel.log\",\n",
    "  \"logs/orch_bg_original_study.log\", \n",
    "  \"logs/orch_bg_full_with_covid.log\",\n",
    "  \"logs/orch_bg_full_without_covid.log\"\n",
    ")\n",
    "\n",
    "for (log_file in log_files) {\n",
    "  if (file.exists(log_file)) {\n",
    "    info <- file.info(log_file)\n",
    "    age_min <- as.numeric(difftime(Sys.time(), info$mtime, units = \"mins\"))\n",
    "    cat(sprintf(\"âœ… %s (%.1f MB, %.0f min ago)\\n\", \n",
    "               basename(log_file), info$size/1024/1024, age_min))\n",
    "  } else {\n",
    "    cat(sprintf(\"âŒ %s (not found)\\n\", basename(log_file)))\n",
    "  }\n",
    "}\n",
    "\n",
    "# Show system resources if available\n",
    "cat(\"\\nðŸ’» System Resources\\n\")\n",
    "cat(\"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\n\")\n",
    "\n",
    "tryCatch({\n",
    "  if (file.exists(\"/proc/meminfo\")) {\n",
    "    meminfo <- readLines(\"/proc/meminfo\")\n",
    "    total_mem <- as.numeric(gsub(\".*: *([0-9]+) kB\", \"\\\\1\", meminfo[grep(\"MemTotal\", meminfo)])) / 1024 / 1024\n",
    "    avail_mem <- as.numeric(gsub(\".*: *([0-9]+) kB\", \"\\\\1\", meminfo[grep(\"MemAvailable\", meminfo)])) / 1024 / 1024\n",
    "    used_mem <- total_mem - avail_mem\n",
    "    cat(sprintf(\"Memory: %.1f/%.1f GB used (%.1f%% utilization)\\n\", \n",
    "               used_mem, total_mem, (used_mem/total_mem)*100))\n",
    "  }\n",
    "  \n",
    "  # Load average if available\n",
    "  if (file.exists(\"/proc/loadavg\")) {\n",
    "    load_avg <- readLines(\"/proc/loadavg\")[1]\n",
    "    load_vals <- strsplit(load_avg, \" \")[[1]][1:3]\n",
    "    cat(sprintf(\"Load avg: %s (1m, 5m, 15m)\\n\", paste(load_vals, collapse = \", \")))\n",
    "  }\n",
    "}, error = function(e) {\n",
    "  cat(\"System info not available\\n\")\n",
    "})\n",
    "\n",
    "# Flush output and clean memory\n",
    "flush.console()\n",
    "gc(verbose = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline Progress Tracker  \n",
    "# Idempotent monitoring - safe to run repeatedly\n",
    "\n",
    "cat(\"ðŸ“ˆ Pipeline Progress Tracker\\n\")\n",
    "cat(\"============================\\n\")\n",
    "\n",
    "# Memory cleanup for browser safety\n",
    "rm(list = setdiff(ls(), c()))  # Keep only essential variables\n",
    "gc(verbose = FALSE)\n",
    "\n",
    "# Function to safely read recent log lines\n",
    "safe_tail <- function(file_path, lines = 10) {\n",
    "  tryCatch({\n",
    "    if (file.exists(file_path) && file.size(file_path) > 0) {\n",
    "      recent <- tail(readLines(file_path, warn = FALSE), lines)\n",
    "      recent[nzchar(recent)]  # Remove empty lines\n",
    "    } else {\n",
    "      character(0)\n",
    "    }\n",
    "  }, error = function(e) character(0))\n",
    "}\n",
    "\n",
    "# Check if pipeline is active\n",
    "pipeline_active <- function() {\n",
    "  orch_running <- system(\"pgrep -f 'run_three_datasets.R'\", ignore.stdout = TRUE, ignore.stderr = TRUE) == 0\n",
    "  loggers_running <- system(\"pgrep -f 'enhanced_pipeline_logger_v2.R'\", ignore.stdout = TRUE, ignore.stderr = TRUE) == 0\n",
    "  return(orch_running || loggers_running)\n",
    "}\n",
    "\n",
    "is_active <- pipeline_active()\n",
    "cat(sprintf(\"Pipeline Status: %s\\n\", ifelse(is_active, \"ðŸŸ¢ ACTIVE\", \"ðŸ”´ INACTIVE\")))\n",
    "cat(sprintf(\"Check Time: %s\\n\\n\", format(Sys.time(), \"%H:%M:%S\")))\n",
    "\n",
    "if (!is_active) {\n",
    "  cat(\"â„¹ï¸  No active pipeline processes detected.\\n\")\n",
    "  cat(\"Use the launch cell to start the pipeline.\\n\")\n",
    "} else {\n",
    "  cat(\"ðŸ“Š Recent Activity from Dataset Logs\\n\")\n",
    "  cat(\"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\n\")\n",
    "  \n",
    "  datasets <- list(\n",
    "    \"Original Study (2010-2019)\" = \"logs/orch_bg_original_study.log\",\n",
    "    \"Full with COVID\" = \"logs/orch_bg_full_with_covid.log\", \n",
    "    \"Full without COVID\" = \"logs/orch_bg_full_without_covid.log\"\n",
    "  )\n",
    "  \n",
    "  for (dataset_name in names(datasets)) {\n",
    "    log_file <- datasets[[dataset_name]]\n",
    "    recent_lines <- safe_tail(log_file, 3)\n",
    "    \n",
    "    cat(sprintf(\"\\nðŸ”¸ %s:\\n\", dataset_name))\n",
    "    if (length(recent_lines) > 0) {\n",
    "      # Show recent progress with clean formatting\n",
    "      for (line in recent_lines) {\n",
    "        # Extract useful info and clean up formatting\n",
    "        clean_line <- gsub(\"^\\\\s*\\\\[.*?\\\\]\\\\s*\", \"\", line)  # Remove timestamps\n",
    "        clean_line <- gsub(\"^\\\\s*\", \"   \", clean_line)       # Indent\n",
    "        if (nchar(clean_line) > 80) {\n",
    "          clean_line <- paste0(substr(clean_line, 1, 77), \"...\")\n",
    "        }\n",
    "        if (nzchar(clean_line) && !grepl(\"^\\\\s*$\", clean_line)) {\n",
    "          cat(clean_line, \"\\n\")\n",
    "        }\n",
    "      }\n",
    "    } else {\n",
    "      cat(\"   (No recent activity or log not found)\\n\")\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  # Check orchestrator summary\n",
    "  cat(sprintf(\"\\nðŸ“‹ Orchestrator Status:\\n\"))\n",
    "  orch_lines <- safe_tail(\"logs/orch_parallel.log\", 5)\n",
    "  if (length(orch_lines) > 0) {\n",
    "    for (line in tail(orch_lines, 2)) {  # Show last 2 lines only\n",
    "      clean_line <- gsub(\"^\\\\s*\", \"   \", line)\n",
    "      if (nzchar(clean_line)) {\n",
    "        cat(clean_line, \"\\n\")\n",
    "      }\n",
    "    }\n",
    "  } else {\n",
    "    cat(\"   (Orchestrator log not found)\\n\")\n",
    "  }\n",
    "}\n",
    "\n",
    "# Memory management and output flush\n",
    "flush.console()\n",
    "gc(verbose = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”§ System Analysis\n",
    "\n",
    "Complete system diagnostics and resource analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System Analysis & Resource Overview\n",
    "# Idempotent system diagnostics - safe to run anytime\n",
    "\n",
    "cat(\"ðŸ”§ System Analysis & Resource Overview\\n\")\n",
    "cat(\"======================================\\n\")\n",
    "\n",
    "# Memory management\n",
    "gc(verbose = FALSE)\n",
    "\n",
    "# System information gathering\n",
    "system_info <- function() {\n",
    "  info <- list()\n",
    "  \n",
    "  # Get CPU information\n",
    "  tryCatch({\n",
    "    if (file.exists(\"/proc/cpuinfo\")) {\n",
    "      cpuinfo <- readLines(\"/proc/cpuinfo\")\n",
    "      cpu_model <- cpuinfo[grep(\"model name\", cpuinfo)[1]]\n",
    "      if (length(cpu_model) > 0) {\n",
    "        info$cpu <- gsub(\".*: \", \"\", cpu_model)\n",
    "      }\n",
    "      \n",
    "      core_count <- length(grep(\"^processor\", cpuinfo))\n",
    "      info$cores <- core_count\n",
    "    } else {\n",
    "      # Fallback for non-Linux systems\n",
    "      info$cores <- as.numeric(Sys.getenv(\"NUMBER_OF_PROCESSORS\", \"unknown\"))\n",
    "      info$cpu <- \"CPU information not available\"\n",
    "    }\n",
    "  }, error = function(e) {\n",
    "    info$cores <- \"unknown\"\n",
    "    info$cpu <- \"CPU detection failed\"\n",
    "  })\n",
    "  \n",
    "  # Memory information\n",
    "  tryCatch({\n",
    "    if (file.exists(\"/proc/meminfo\")) {\n",
    "      meminfo <- readLines(\"/proc/meminfo\")\n",
    "      total_mem <- as.numeric(gsub(\".*: *([0-9]+) kB\", \"\\\\1\", meminfo[grep(\"MemTotal\", meminfo)])) / 1024 / 1024\n",
    "      avail_mem <- as.numeric(gsub(\".*: *([0-9]+) kB\", \"\\\\1\", meminfo[grep(\"MemAvailable\", meminfo)])) / 1024 / 1024\n",
    "      free_mem <- as.numeric(gsub(\".*: *([0-9]+) kB\", \"\\\\1\", meminfo[grep(\"MemFree\", meminfo)])) / 1024 / 1024\n",
    "      cached_mem <- as.numeric(gsub(\".*: *([0-9]+) kB\", \"\\\\1\", meminfo[grep(\"^Cached\", meminfo)])) / 1024 / 1024\n",
    "      \n",
    "      info$memory <- list(\n",
    "        total = total_mem,\n",
    "        available = avail_mem,\n",
    "        free = free_mem,\n",
    "        cached = cached_mem,\n",
    "        used = total_mem - avail_mem\n",
    "      )\n",
    "    }\n",
    "  }, error = function(e) {\n",
    "    info$memory <- \"Memory info not available\"\n",
    "  })\n",
    "  \n",
    "  # Disk space for current directory\n",
    "  tryCatch({\n",
    "    disk_info <- system(\"df -h . | tail -1\", intern = TRUE)\n",
    "    if (length(disk_info) > 0) {\n",
    "      info$disk <- disk_info\n",
    "    }\n",
    "  }, error = function(e) {\n",
    "    info$disk <- \"Disk info not available\"\n",
    "  })\n",
    "  \n",
    "  return(info)\n",
    "}\n",
    "\n",
    "# Get system info\n",
    "sys_info <- system_info()\n",
    "\n",
    "# Display system configuration\n",
    "cat(\"ðŸ’» System Configuration\\n\")\n",
    "cat(\"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\n\")\n",
    "cat(sprintf(\"CPU: %s\\n\", sys_info$cpu))\n",
    "cat(sprintf(\"Cores: %s\\n\", sys_info$cores))\n",
    "\n",
    "if (is.list(sys_info$memory)) {\n",
    "  mem <- sys_info$memory\n",
    "  cat(sprintf(\"Memory: %.1f GB total, %.1f GB available, %.1f GB used (%.1f%% util)\\n\", \n",
    "             mem$total, mem$available, mem$used, (mem$used/mem$total)*100))\n",
    "  cat(sprintf(\"Cache: %.1f GB, Free: %.1f GB\\n\", mem$cached, mem$free))\n",
    "} else {\n",
    "  cat(sprintf(\"Memory: %s\\n\", sys_info$memory))\n",
    "}\n",
    "\n",
    "if (!is.null(sys_info$disk)) {\n",
    "  cat(sprintf(\"Disk: %s\\n\", sys_info$disk))\n",
    "}\n",
    "\n",
    "# R Environment\n",
    "cat(sprintf(\"R Version: %s\\n\", R.version.string))\n",
    "cat(sprintf(\"R_MAX_VSIZE: %s\\n\", Sys.getenv(\"R_MAX_VSIZE\", \"not set\")))\n",
    "\n",
    "# Pipeline-specific analysis  \n",
    "cat(\"\\nðŸ—ï¸ Pipeline Environment\\n\")\n",
    "cat(\"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\n\")\n",
    "\n",
    "# Check core allocation for pipeline\n",
    "if (is.numeric(sys_info$cores) && sys_info$cores > 0) {\n",
    "  cores_per_dataset <- floor(sys_info$cores * 0.25)\n",
    "  total_pipeline_cores <- cores_per_dataset * 3\n",
    "  cat(sprintf(\"Pipeline cores per dataset: %d (25%% of %d)\\n\", cores_per_dataset, sys_info$cores))\n",
    "  cat(sprintf(\"Total pipeline utilization: %d cores (%.1f%%)\\n\", \n",
    "             total_pipeline_cores, (total_pipeline_cores/sys_info$cores)*100))\n",
    "}\n",
    "\n",
    "# Check critical directories and files\n",
    "cat(\"\\nðŸ“ Project Structure\\n\")\n",
    "cat(\"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\n\")\n",
    "\n",
    "critical_paths <- c(\n",
    "  \"scripts/run_three_datasets.R\",\n",
    "  \"scripts/enhanced_pipeline_logger_v2.R\", \n",
    "  \"R/utils/parallel_utils.R\",\n",
    "  \"logs/\"\n",
    ")\n",
    "\n",
    "for (path in critical_paths) {\n",
    "  if (file.exists(path)) {\n",
    "    if (dir.exists(path)) {\n",
    "      files_count <- length(list.files(path))\n",
    "      cat(sprintf(\"âœ… %s (%d files)\\n\", path, files_count))\n",
    "    } else {\n",
    "      info <- file.info(path)\n",
    "      cat(sprintf(\"âœ… %s (%.1f KB)\\n\", path, info$size/1024))\n",
    "    }\n",
    "  } else {\n",
    "    cat(sprintf(\"âŒ %s (missing)\\n\", path))\n",
    "  }\n",
    "}\n",
    "\n",
    "# Current pipeline status summary\n",
    "cat(sprintf(\"\\nâ° Analysis completed at %s\\n\", format(Sys.time(), \"%Y-%m-%d %H:%M:%S\")))\n",
    "\n",
    "# Clean up and flush\n",
    "flush.console()\n",
    "gc(verbose = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graft Loss: Three Dataset Parallel Execution Driver\n",
    "\n",
    "**Enhanced Pipeline Management for AWS Linux 2023 EC2**\n",
    "\n",
    "This notebook provides comprehensive management and monitoring for running the graft-loss pipeline across three datasets in parallel:\n",
    "\n",
    "- **Original Study** (2010-2019) \n",
    "- **Full Dataset with COVID** (2010-2023)\n",
    "- **Full Dataset without COVID** (2010-2019, excluding 2020+)\n",
    "\n",
    "## Key Features:\n",
    "- ðŸš€ Parallel execution with resource optimization\n",
    "- ðŸ“Š Real-time monitoring with progress logging\n",
    "- ðŸ’¾ Memory optimization for large datasets (1TB RAM support)\n",
    "- ðŸŽ¯ Background execution with PID tracking\n",
    "\n",
    "All logs and step summaries are written to `logs/` by enhanced pipeline logger. Use the cells below to execute runs, then review summaries and monitoring outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Enhanced Resource Monitor with Memory Management\n",
    "# Prevents browser crashes during monitoring\n",
    "\n",
    "cat(\"ðŸ–¥ï¸  System Resource Monitor\\n\")\n",
    "cat(\"========================\\n\")\n",
    "flush.console()\n",
    "\n",
    "# Memory management: Clear environment\n",
    "rm(list = ls())\n",
    "gc(verbose = FALSE)\n",
    "\n",
    "# Check system resources\n",
    "memory_info <- function() {\n",
    "  tryCatch({\n",
    "    if (file.exists(\"/proc/meminfo\")) {\n",
    "      meminfo <- readLines(\"/proc/meminfo\")\n",
    "      total <- as.numeric(gsub(\".*: *([0-9]+) kB\", \"\\\\1\", meminfo[grep(\"MemTotal\", meminfo)])) / 1024 / 1024\n",
    "      avail <- as.numeric(gsub(\".*: *([0-9]+) kB\", \"\\\\1\", meminfo[grep(\"MemAvailable\", meminfo)])) / 1024 / 1024  \n",
    "      sprintf(\"Memory: %.1f GB available of %.1f GB total\", avail, total)\n",
    "    } else {\n",
    "      \"Memory info not available\"\n",
    "    }\n",
    "  }, error = function(e) \"Memory detection failed\")\n",
    "}\n",
    "\n",
    "cat(memory_info(), \"\\n\")\n",
    "flush.console()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸš€ Launch Parallel Execution\n",
    "\n",
    "This section launches all three datasets in parallel using the enhanced pipeline logger with resource monitoring.\n",
    "\n",
    "**Expected Execution Flow:**\n",
    "- **Original Study** (2010-2019) â†’ `logs/orch_bg_original_study.log`\n",
    "- **Full with COVID** (2010-2023) â†’ `logs/orch_bg_full_with_covid.log`  \n",
    "- **Full without COVID** (2010-2019, excl. 2020+) â†’ `logs/orch_bg_full_without_covid.log`\n",
    "\n",
    "**Parallel Configuration:**\n",
    "- Each dataset gets ~25% of available cores for stable execution\n",
    "- Forces inner model threads to 1 to avoid oversubscription\n",
    "- **3 separate PIDs** for true parallel execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš™ï¸ EC2 Troubleshooting\n",
    "\n",
    "If experiencing file load errors on EC2, run the diagnostic tools below first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Idempotent 3-Dataset Pipeline Launcher\n",
    "# Ensures only one instance runs - safe to execute multiple times\n",
    "\n",
    "dir.create(\"logs\", showWarnings = FALSE)\n",
    "\n",
    "# Set R memory environment\n",
    "Sys.setenv(R_MAX_VSIZE = \"950Gb\")\n",
    "\n",
    "# Check if orchestrator exists\n",
    "if (!file.exists(\"scripts/run_three_datasets.R\")) {\n",
    "  cat(\"âŒ Error: scripts/run_three_datasets.R not found\\n\")\n",
    "  cat(\"Available scripts:\\n\")\n",
    "  print(list.files(\"scripts\", pattern = \"\\\\.R$\"))\n",
    "  stop(\"Missing orchestrator script\")\n",
    "}\n",
    "\n",
    "# Idempotent check: Look for running pipeline processes\n",
    "check_running_pipelines <- function() {\n",
    "  # Check for orchestrator process\n",
    "  orch_check <- system(\"pgrep -f 'run_three_datasets.R'\", ignore.stdout = TRUE, ignore.stderr = TRUE)\n",
    "  \n",
    "  # Check for individual dataset processes  \n",
    "  dataset_check <- system(\"pgrep -f 'enhanced_pipeline_logger_v2.R'\", ignore.stdout = TRUE, ignore.stderr = TRUE)\n",
    "  \n",
    "  # Check PID file if it exists\n",
    "  pid_file_exists <- file.exists(\"logs/parallel_config.log\")\n",
    "  \n",
    "  return(list(\n",
    "    orchestrator_running = (orch_check == 0),\n",
    "    datasets_running = (dataset_check == 0), \n",
    "    pid_file_exists = pid_file_exists\n",
    "  ))\n",
    "}\n",
    "\n",
    "# Get current status\n",
    "status <- check_running_pipelines()\n",
    "\n",
    "cat(\"ðŸ” Pipeline Status Check\\n\")\n",
    "cat(\"========================\\n\")\n",
    "cat(sprintf(\"Orchestrator running: %s\\n\", ifelse(status$orchestrator_running, \"âœ… YES\", \"âŒ NO\")))\n",
    "cat(sprintf(\"Dataset processes: %s\\n\", ifelse(status$datasets_running, \"âœ… ACTIVE\", \"âŒ NONE\")))\n",
    "cat(sprintf(\"Config log exists: %s\\n\", ifelse(status$pid_file_exists, \"âœ… YES\", \"âŒ NO\")))\n",
    "flush.console()\n",
    "\n",
    "if (status$orchestrator_running || status$datasets_running) {\n",
    "  cat(\"\\n\udfe1 PIPELINE ALREADY RUNNING\\n\")\n",
    "  cat(\"=========================\\n\")\n",
    "  cat(\"The 3-dataset parallel pipeline is already active.\\n\")\n",
    "  cat(\"Use the monitoring cells below to check progress.\\n\")\n",
    "  cat(\"To restart, first stop the current run in the management cell.\\n\\n\")\n",
    "  flush.console()\n",
    "  \n",
    "  # Show current PIDs if available\n",
    "  if (status$pid_file_exists) {\n",
    "    cat(\"ðŸ“‹ Current process info:\\n\")\n",
    "    tryCatch({\n",
    "      recent_log <- tail(readLines(\"logs/parallel_config.log\"), 3)\n",
    "      cat(paste(recent_log, collapse = \"\\n\"), \"\\n\")\n",
    "    }, error = function(e) cat(\"Could not read recent log entries\\n\"))\n",
    "  }\n",
    "  \n",
    "} else {\n",
    "  cat(\"\\nðŸš€ LAUNCHING NEW PIPELINE\\n\")\n",
    "  cat(\"=========================\\n\")\n",
    "  flush.console()\n",
    "  \n",
    "  # Clean up old logs to start fresh\n",
    "  old_logs <- list.files(\"logs\", pattern = \"(orch_|parallel_config)\", full.names = TRUE)\n",
    "  if (length(old_logs) > 0) {\n",
    "    file.remove(old_logs)\n",
    "    cat(\"ðŸ§¹ Cleared old log files\\n\")\n",
    "  }\n",
    "  \n",
    "  # Launch the pipeline\n",
    "  launch_cmd <- 'nohup Rscript scripts/run_three_datasets.R > logs/orch_parallel.log 2>&1 & echo $!'\n",
    "  \n",
    "  result <- tryCatch({\n",
    "    pid_output <- system(launch_cmd, intern = TRUE)\n",
    "    pid_output\n",
    "  }, error = function(e) {\n",
    "    paste(\"ERROR:\", e$message)\n",
    "  })\n",
    "  \n",
    "  # Process result\n",
    "  if (length(result) > 0 && !grepl(\"ERROR|error|failed\", result[1], ignore.case = TRUE)) {\n",
    "    pid <- result[1]\n",
    "    \n",
    "    if (grepl(\"^[0-9]+$\", pid)) {\n",
    "      cat(\"âœ… Successfully launched parallel orchestrator!\\n\")\n",
    "      cat(sprintf(\"Process ID: %s\\n\", pid))\n",
    "      cat(\"System: AWS Linux 2023 EC2 (1TB RAM)\\n\")\n",
    "      cat(\"Memory: R_MAX_VSIZE=950Gb\\n\")\n",
    "      cat(\"Orchestrator log: logs/orch_parallel.log\\n\\n\")\n",
    "      flush.console()\n",
    "      \n",
    "      cat(\"ðŸ“Š Expected dataset logs:\\n\")\n",
    "      cat(\"  - logs/orch_bg_original_study.log\\n\")\n",
    "      cat(\"  - logs/orch_bg_full_with_covid.log\\n\") \n",
    "      cat(\"  - logs/orch_bg_full_without_covid.log\\n\\n\")\n",
    "      flush.console()\n",
    "      \n",
    "      # Log the successful launch with timestamp\n",
    "      launch_log <- sprintf(\"Pipeline launched: PID %s at %s\\n\", pid, Sys.time())\n",
    "      cat(launch_log, file = \"logs/parallel_config.log\", append = TRUE)\n",
    "      \n",
    "      cat(\"ðŸ” Use monitoring cells below to track progress\\n\")\n",
    "      flush.console()\n",
    "      \n",
    "    } else {\n",
    "      cat(\"âš ï¸  Launch completed but PID format unexpected:\", pid, \"\\n\")\n",
    "      flush.console()\n",
    "    }\n",
    "  } else {\n",
    "    cat(\"âŒ Launch failed\\n\")\n",
    "    cat(\"Output:\", paste(result, collapse = \"\\n\"), \"\\n\")\n",
    "    flush.console()\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Pipeline Management - Stop/Restart Control\n",
    "# Idempotent management of pipeline processes\n",
    "\n",
    "cat(\"ðŸŽ›ï¸  Pipeline Management Control\\n\")\n",
    "cat(\"===============================\\n\")\n",
    "\n",
    "# Function to safely stop all pipeline processes\n",
    "stop_pipeline <- function() {\n",
    "  stopped_count <- 0\n",
    "  \n",
    "  # Stop orchestrator processes\n",
    "  orch_pids <- system(\"pgrep -f 'run_three_datasets.R'\", intern = TRUE, ignore.stderr = TRUE)\n",
    "  if (length(orch_pids) > 0 && !any(grepl(\"ERROR\", orch_pids))) {\n",
    "    for (pid in orch_pids) {\n",
    "      if (grepl(\"^[0-9]+$\", pid)) {\n",
    "        system(sprintf(\"kill %s\", pid), ignore.stdout = TRUE, ignore.stderr = TRUE)\n",
    "        stopped_count <- stopped_count + 1\n",
    "        cat(sprintf(\"ðŸ›‘ Stopped orchestrator PID %s\\n\", pid))\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  # Stop dataset logger processes  \n",
    "  logger_pids <- system(\"pgrep -f 'enhanced_pipeline_logger_v2.R'\", intern = TRUE, ignore.stderr = TRUE)\n",
    "  if (length(logger_pids) > 0 && !any(grepl(\"ERROR\", logger_pids))) {\n",
    "    for (pid in logger_pids) {\n",
    "      if (grepl(\"^[0-9]+$\", pid)) {\n",
    "        system(sprintf(\"kill %s\", pid), ignore.stdout = TRUE, ignore.stderr = TRUE)\n",
    "        stopped_count <- stopped_count + 1\n",
    "        cat(sprintf(\"ðŸ›‘ Stopped dataset logger PID %s\\n\", pid))\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  # Stop any remaining R processes running the pipeline\n",
    "  pipeline_pids <- system(\"pgrep -f 'run_pipeline.R'\", intern = TRUE, ignore.stderr = TRUE)\n",
    "  if (length(pipeline_pids) > 0 && !any(grepl(\"ERROR\", pipeline_pids))) {\n",
    "    for (pid in pipeline_pids) {\n",
    "      if (grepl(\"^[0-9]+$\", pid)) {\n",
    "        system(sprintf(\"kill %s\", pid), ignore.stdout = TRUE, ignore.stderr = TRUE)  \n",
    "        stopped_count <- stopped_count + 1\n",
    "        cat(sprintf(\"ðŸ›‘ Stopped pipeline process PID %s\\n\", pid))\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  return(stopped_count)\n",
    "}\n",
    "\n",
    "# Check current status first\n",
    "orch_running <- system(\"pgrep -f 'run_three_datasets.R'\", ignore.stdout = TRUE, ignore.stderr = TRUE) == 0\n",
    "datasets_running <- system(\"pgrep -f 'enhanced_pipeline_logger_v2.R'\", ignore.stdout = TRUE, ignore.stderr = TRUE) == 0\n",
    "\n",
    "cat(sprintf(\"Current status: %s\\n\", \n",
    "    ifelse(orch_running || datasets_running, \"ðŸŸ¢ RUNNING\", \"ðŸ”´ STOPPED\")))\n",
    "\n",
    "if (orch_running || datasets_running) {\n",
    "  cat(\"\\nâš ï¸  STOPPING ALL PIPELINE PROCESSES\\n\")\n",
    "  cat(\"This will gracefully terminate the current run.\\n\")\n",
    "  flush.console()\n",
    "  \n",
    "  stopped <- stop_pipeline()\n",
    "  \n",
    "  if (stopped > 0) {\n",
    "    cat(sprintf(\"\\nâœ… Successfully stopped %d processes\\n\", stopped))\n",
    "    cat(\"Pipeline is now stopped. You can safely restart using the launch cell.\\n\")\n",
    "    \n",
    "    # Log the stop action\n",
    "    stop_log <- sprintf(\"Pipeline stopped: %d processes terminated at %s\\n\", stopped, Sys.time())\n",
    "    cat(stop_log, file = \"logs/parallel_config.log\", append = TRUE)\n",
    "  } else {\n",
    "    cat(\"\\nðŸ¤· No pipeline processes found to stop\\n\")\n",
    "  }\n",
    "} else {\n",
    "  cat(\"\\nâœ… No pipeline processes are currently running\\n\")\n",
    "  cat(\"You can start the pipeline using the launch cell above.\\n\")\n",
    "}\n",
    "\n",
    "# Clean memory after management operations\n",
    "gc(verbose = FALSE)\n",
    "flush.console()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Real-time Pipeline Status Monitor\n",
    "# Safe to run multiple times - shows current state\n",
    "\n",
    "cat(\"\udcca Pipeline Status Monitor\\n\")\n",
    "cat(\"==========================\\n\")\n",
    "\n",
    "# Memory management for browser safety\n",
    "gc(verbose = FALSE)\n",
    "\n",
    "# Check process status\n",
    "check_pipeline_status <- function() {\n",
    "  # Get orchestrator PIDs\n",
    "  orch_pids <- tryCatch({\n",
    "    pids <- system(\"pgrep -f 'run_three_datasets.R'\", intern = TRUE, ignore.stderr = TRUE)\n",
    "    if (length(pids) > 0 && !any(grepl(\"ERROR\", pids)) && all(grepl(\"^[0-9]+$\", pids))) {\n",
    "      pids\n",
    "    } else {\n",
    "      character(0)\n",
    "    }\n",
    "  }, error = function(e) character(0))\n",
    "  \n",
    "  # Get dataset logger PIDs  \n",
    "  logger_pids <- tryCatch({\n",
    "    pids <- system(\"pgrep -f 'enhanced_pipeline_logger_v2.R'\", intern = TRUE, ignore.stderr = TRUE)\n",
    "    if (length(pids) > 0 && !any(grepl(\"ERROR\", pids)) && all(grepl(\"^[0-9]+$\", pids))) {\n",
    "      pids\n",
    "    } else {\n",
    "      character(0)\n",
    "    }\n",
    "  }, error = function(e) character(0))\n",
    "  \n",
    "  return(list(\n",
    "    orchestrator = orch_pids,\n",
    "    loggers = logger_pids,\n",
    "    total_processes = length(orch_pids) + length(logger_pids)\n",
    "  ))\n",
    "}\n",
    "\n",
    "# Get current status\n",
    "status <- check_pipeline_status()\n",
    "\n",
    "# Display status with timestamp\n",
    "cat(sprintf(\"Status at %s\\n\", format(Sys.time(), \"%Y-%m-%d %H:%M:%S\")))\n",
    "cat(\"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\n\")\n",
    "\n",
    "if (status$total_processes == 0) {\n",
    "  cat(\"ðŸ”´ PIPELINE STOPPED\\n\")\n",
    "  cat(\"No active processes found.\\n\")\n",
    "} else {\n",
    "  cat(\"ðŸŸ¢ PIPELINE ACTIVE\\n\")\n",
    "  cat(sprintf(\"Total processes: %d\\n\", status$total_processes))\n",
    "  \n",
    "  if (length(status$orchestrator) > 0) {\n",
    "    cat(sprintf(\"Orchestrator PIDs: %s\\n\", paste(status$orchestrator, collapse = \", \")))\n",
    "  }\n",
    "  \n",
    "  if (length(status$loggers) > 0) {\n",
    "    cat(sprintf(\"Dataset loggers: %d processes\\n\", length(status$loggers)))\n",
    "  }\n",
    "}\n",
    "\n",
    "# Check log files and show recent activity\n",
    "cat(\"\\nðŸ“‹ Log File Status\\n\")\n",
    "cat(\"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\n\")\n",
    "\n",
    "log_files <- c(\n",
    "  \"logs/orch_parallel.log\",\n",
    "  \"logs/orch_bg_original_study.log\", \n",
    "  \"logs/orch_bg_full_with_covid.log\",\n",
    "  \"logs/orch_bg_full_without_covid.log\"\n",
    ")\n",
    "\n",
    "for (log_file in log_files) {\n",
    "  if (file.exists(log_file)) {\n",
    "    info <- file.info(log_file)\n",
    "    age_min <- as.numeric(difftime(Sys.time(), info$mtime, units = \"mins\"))\n",
    "    cat(sprintf(\"âœ… %s (%.1f MB, %.0f min ago)\\n\", \n",
    "               basename(log_file), info$size/1024/1024, age_min))\n",
    "  } else {\n",
    "    cat(sprintf(\"âŒ %s (not found)\\n\", basename(log_file)))\n",
    "  }\n",
    "}\n",
    "\n",
    "# Show system resources if available\n",
    "cat(\"\\nðŸ’» System Resources\\n\")\n",
    "cat(\"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\n\")\n",
    "\n",
    "tryCatch({\n",
    "  if (file.exists(\"/proc/meminfo\")) {\n",
    "    meminfo <- readLines(\"/proc/meminfo\")\n",
    "    total_mem <- as.numeric(gsub(\".*: *([0-9]+) kB\", \"\\\\1\", meminfo[grep(\"MemTotal\", meminfo)])) / 1024 / 1024\n",
    "    avail_mem <- as.numeric(gsub(\".*: *([0-9]+) kB\", \"\\\\1\", meminfo[grep(\"MemAvailable\", meminfo)])) / 1024 / 1024\n",
    "    used_mem <- total_mem - avail_mem\n",
    "    cat(sprintf(\"Memory: %.1f/%.1f GB used (%.1f%% utilization)\\n\", \n",
    "               used_mem, total_mem, (used_mem/total_mem)*100))\n",
    "  }\n",
    "  \n",
    "  # Load average if available\n",
    "  if (file.exists(\"/proc/loadavg\")) {\n",
    "    load_avg <- readLines(\"/proc/loadavg\")[1]\n",
    "    load_vals <- strsplit(load_avg, \" \")[[1]][1:3]\n",
    "    cat(sprintf(\"Load avg: %s (1m, 5m, 15m)\\n\", paste(load_vals, collapse = \", \")))\n",
    "  }\n",
    "}, error = function(e) {\n",
    "  cat(\"System info not available\\n\")\n",
    "})\n",
    "\n",
    "# Flush output and clean memory\n",
    "flush.console()\n",
    "gc(verbose = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Pipeline Progress Tracker  \n",
    "# Idempotent monitoring - safe to run repeatedly\n",
    "\n",
    "cat(\"ðŸ“ˆ Pipeline Progress Tracker\\n\")\n",
    "cat(\"============================\\n\")\n",
    "\n",
    "# Memory cleanup for browser safety\n",
    "rm(list = setdiff(ls(), c()))  # Keep only essential variables\n",
    "gc(verbose = FALSE)\n",
    "\n",
    "# Function to safely read recent log lines\n",
    "safe_tail <- function(file_path, lines = 10) {\n",
    "  tryCatch({\n",
    "    if (file.exists(file_path) && file.size(file_path) > 0) {\n",
    "      recent <- tail(readLines(file_path, warn = FALSE), lines)\n",
    "      recent[nzchar(recent)]  # Remove empty lines\n",
    "    } else {\n",
    "      character(0)\n",
    "    }\n",
    "  }, error = function(e) character(0))\n",
    "}\n",
    "\n",
    "# Check if pipeline is active\n",
    "pipeline_active <- function() {\n",
    "  orch_running <- system(\"pgrep -f 'run_three_datasets.R'\", ignore.stdout = TRUE, ignore.stderr = TRUE) == 0\n",
    "  loggers_running <- system(\"pgrep -f 'enhanced_pipeline_logger_v2.R'\", ignore.stdout = TRUE, ignore.stderr = TRUE) == 0\n",
    "  return(orch_running || loggers_running)\n",
    "}\n",
    "\n",
    "is_active <- pipeline_active()\n",
    "cat(sprintf(\"Pipeline Status: %s\\n\", ifelse(is_active, \"ðŸŸ¢ ACTIVE\", \"ðŸ”´ INACTIVE\")))\n",
    "cat(sprintf(\"Check Time: %s\\n\\n\", format(Sys.time(), \"%H:%M:%S\")))\n",
    "\n",
    "if (!is_active) {\n",
    "  cat(\"â„¹ï¸  No active pipeline processes detected.\\n\")\n",
    "  cat(\"Use the launch cell to start the pipeline.\\n\")\n",
    "} else {\n",
    "  cat(\"ðŸ“Š Recent Activity from Dataset Logs\\n\")\n",
    "  cat(\"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\n\")\n",
    "  \n",
    "  datasets <- list(\n",
    "    \"Original Study (2010-2019)\" = \"logs/orch_bg_original_study.log\",\n",
    "    \"Full with COVID\" = \"logs/orch_bg_full_with_covid.log\", \n",
    "    \"Full without COVID\" = \"logs/orch_bg_full_without_covid.log\"\n",
    "  )\n",
    "  \n",
    "  for (dataset_name in names(datasets)) {\n",
    "    log_file <- datasets[[dataset_name]]\n",
    "    recent_lines <- safe_tail(log_file, 3)\n",
    "    \n",
    "    cat(sprintf(\"\\n\udd38 %s:\\n\", dataset_name))\n",
    "    if (length(recent_lines) > 0) {\n",
    "      # Show recent progress with clean formatting\n",
    "      for (line in recent_lines) {\n",
    "        # Extract useful info and clean up formatting\n",
    "        clean_line <- gsub(\"^\\\\s*\\\\[.*?\\\\]\\\\s*\", \"\", line)  # Remove timestamps\n",
    "        clean_line <- gsub(\"^\\\\s*\", \"   \", clean_line)       # Indent\n",
    "        if (nchar(clean_line) > 80) {\n",
    "          clean_line <- paste0(substr(clean_line, 1, 77), \"...\")\n",
    "        }\n",
    "        if (nzchar(clean_line) && !grepl(\"^\\\\s*$\", clean_line)) {\n",
    "          cat(clean_line, \"\\n\")\n",
    "        }\n",
    "      }\n",
    "    } else {\n",
    "      cat(\"   (No recent activity or log not found)\\n\")\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  # Check orchestrator summary\n",
    "  cat(sprintf(\"\\nðŸ“‹ Orchestrator Status:\\n\"))\n",
    "  orch_lines <- safe_tail(\"logs/orch_parallel.log\", 5)\n",
    "  if (length(orch_lines) > 0) {\n",
    "    for (line in tail(orch_lines, 2)) {  # Show last 2 lines only\n",
    "      clean_line <- gsub(\"^\\\\s*\", \"   \", line)\n",
    "      if (nzchar(clean_line)) {\n",
    "        cat(clean_line, \"\\n\")\n",
    "      }\n",
    "    }\n",
    "  } else {\n",
    "    cat(\"   (Orchestrator log not found)\\n\")\n",
    "  }\n",
    "}\n",
    "\n",
    "# Memory management and output flush\n",
    "flush.console()\n",
    "gc(verbose = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Comprehensive System Monitoring\n",
    "\n",
    "Advanced system monitoring and process management for long-running parallel executions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# System Analysis & Resource Overview\n",
    "# Idempotent system diagnostics - safe to run anytime\n",
    "\n",
    "cat(\"\udd27 System Analysis & Resource Overview\\n\")\n",
    "cat(\"======================================\\n\")\n",
    "\n",
    "# Memory management\n",
    "gc(verbose = FALSE)\n",
    "\n",
    "# System information gathering\n",
    "system_info <- function() {\n",
    "  info <- list()\n",
    "  \n",
    "  # Get CPU information\n",
    "  tryCatch({\n",
    "    if (file.exists(\"/proc/cpuinfo\")) {\n",
    "      cpuinfo <- readLines(\"/proc/cpuinfo\")\n",
    "      cpu_model <- cpuinfo[grep(\"model name\", cpuinfo)[1]]\n",
    "      if (length(cpu_model) > 0) {\n",
    "        info$cpu <- gsub(\".*: \", \"\", cpu_model)\n",
    "      }\n",
    "      \n",
    "      core_count <- length(grep(\"^processor\", cpuinfo))\n",
    "      info$cores <- core_count\n",
    "    } else {\n",
    "      # Fallback for non-Linux systems\n",
    "      info$cores <- as.numeric(Sys.getenv(\"NUMBER_OF_PROCESSORS\", \"unknown\"))\n",
    "      info$cpu <- \"CPU information not available\"\n",
    "    }\n",
    "  }, error = function(e) {\n",
    "    info$cores <- \"unknown\"\n",
    "    info$cpu <- \"CPU detection failed\"\n",
    "  })\n",
    "  \n",
    "  # Memory information\n",
    "  tryCatch({\n",
    "    if (file.exists(\"/proc/meminfo\")) {\n",
    "      meminfo <- readLines(\"/proc/meminfo\")\n",
    "      total_mem <- as.numeric(gsub(\".*: *([0-9]+) kB\", \"\\\\1\", meminfo[grep(\"MemTotal\", meminfo)])) / 1024 / 1024\n",
    "      avail_mem <- as.numeric(gsub(\".*: *([0-9]+) kB\", \"\\\\1\", meminfo[grep(\"MemAvailable\", meminfo)])) / 1024 / 1024\n",
    "      free_mem <- as.numeric(gsub(\".*: *([0-9]+) kB\", \"\\\\1\", meminfo[grep(\"MemFree\", meminfo)])) / 1024 / 1024\n",
    "      cached_mem <- as.numeric(gsub(\".*: *([0-9]+) kB\", \"\\\\1\", meminfo[grep(\"^Cached\", meminfo)])) / 1024 / 1024\n",
    "      \n",
    "      info$memory <- list(\n",
    "        total = total_mem,\n",
    "        available = avail_mem,\n",
    "        free = free_mem,\n",
    "        cached = cached_mem,\n",
    "        used = total_mem - avail_mem\n",
    "      )\n",
    "    }\n",
    "  }, error = function(e) {\n",
    "    info$memory <- \"Memory info not available\"\n",
    "  })\n",
    "  \n",
    "  # Disk space for current directory\n",
    "  tryCatch({\n",
    "    disk_info <- system(\"df -h . | tail -1\", intern = TRUE)\n",
    "    if (length(disk_info) > 0) {\n",
    "      info$disk <- disk_info\n",
    "    }\n",
    "  }, error = function(e) {\n",
    "    info$disk <- \"Disk info not available\"\n",
    "  })\n",
    "  \n",
    "  return(info)\n",
    "}\n",
    "\n",
    "# Get system info\n",
    "sys_info <- system_info()\n",
    "\n",
    "# Display system configuration\n",
    "cat(\"ðŸ’» System Configuration\\n\")\n",
    "cat(\"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\n\")\n",
    "cat(sprintf(\"CPU: %s\\n\", sys_info$cpu))\n",
    "cat(sprintf(\"Cores: %s\\n\", sys_info$cores))\n",
    "\n",
    "if (is.list(sys_info$memory)) {\n",
    "  mem <- sys_info$memory\n",
    "  cat(sprintf(\"Memory: %.1f GB total, %.1f GB available, %.1f GB used (%.1f%% util)\\n\", \n",
    "             mem$total, mem$available, mem$used, (mem$used/mem$total)*100))\n",
    "  cat(sprintf(\"Cache: %.1f GB, Free: %.1f GB\\n\", mem$cached, mem$free))\n",
    "} else {\n",
    "  cat(sprintf(\"Memory: %s\\n\", sys_info$memory))\n",
    "}\n",
    "\n",
    "if (!is.null(sys_info$disk)) {\n",
    "  cat(sprintf(\"Disk: %s\\n\", sys_info$disk))\n",
    "}\n",
    "\n",
    "# R Environment\n",
    "cat(sprintf(\"R Version: %s\\n\", R.version.string))\n",
    "cat(sprintf(\"R_MAX_VSIZE: %s\\n\", Sys.getenv(\"R_MAX_VSIZE\", \"not set\")))\n",
    "\n",
    "# Pipeline-specific analysis  \n",
    "cat(\"\\nðŸ—ï¸ Pipeline Environment\\n\")\n",
    "cat(\"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\n\")\n",
    "\n",
    "# Check core allocation for pipeline\n",
    "if (is.numeric(sys_info$cores) && sys_info$cores > 0) {\n",
    "  cores_per_dataset <- floor(sys_info$cores * 0.25)\n",
    "  total_pipeline_cores <- cores_per_dataset * 3\n",
    "  cat(sprintf(\"Pipeline cores per dataset: %d (25%% of %d)\\n\", cores_per_dataset, sys_info$cores))\n",
    "  cat(sprintf(\"Total pipeline utilization: %d cores (%.1f%%)\\n\", \n",
    "             total_pipeline_cores, (total_pipeline_cores/sys_info$cores)*100))\n",
    "}\n",
    "\n",
    "# Check critical directories and files\n",
    "cat(\"\\nðŸ“ Project Structure\\n\")\n",
    "cat(\"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\n\")\n",
    "\n",
    "critical_paths <- c(\n",
    "  \"scripts/run_three_datasets.R\",\n",
    "  \"scripts/enhanced_pipeline_logger_v2.R\", \n",
    "  \"R/utils/parallel_utils.R\",\n",
    "  \"logs/\"\n",
    ")\n",
    "\n",
    "for (path in critical_paths) {\n",
    "  if (file.exists(path)) {\n",
    "    if (dir.exists(path)) {\n",
    "      files_count <- length(list.files(path))\n",
    "      cat(sprintf(\"âœ… %s (%d files)\\n\", path, files_count))\n",
    "    } else {\n",
    "      info <- file.info(path)\n",
    "      cat(sprintf(\"âœ… %s (%.1f KB)\\n\", path, info$size/1024))\n",
    "    }\n",
    "  } else {\n",
    "    cat(sprintf(\"âŒ %s (missing)\\n\", path))\n",
    "  }\n",
    "}\n",
    "\n",
    "# Current pipeline status summary\n",
    "cat(sprintf(\"\\nâ° Analysis completed at %s\\n\", format(Sys.time(), \"%Y-%m-%d %H:%M:%S\")))\n",
    "\n",
    "# Clean up and flush\n",
    "flush.console()\n",
    "gc(verbose = FALSE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
