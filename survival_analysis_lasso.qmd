---
title: "Survival Analysis - Model Comparisons"
author: "R. Jerome Dixon"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
format:
  html:
    toc: true
    toc-depth: 5
    code-fold: true
    code-summary: "Show the code"
    df_print: paged
    embed-resources: true
    default-image-extension: svg
    dpi: 600
---

```{r load-libraries}
#| echo: true
#| warning: false
#| message: false
#| results: hide

library(here)
library(dplyr)
library(readr)
library(magrittr)
library(spatstat)
library(tibble)
library(ggplot2)
library(purrr)
library(tidyverse)
library(huxtable)
library(reticulate)
library(caret)
library(glmnet)
library(DataExplorer)
library(DT)

(options)(scipen=999)

```

### Survival Model Dataset

```{r load-dataset}
#| echo: true
#| warning: false
#| message: false
#| eval: true

set.seed(1997)

survival_model <- read_rds(here("data","survival_analysis.rds"))

survival_model %<>%
  mutate_if(is.character, as.factor) 
 
survival_model %>% 
  str()


```

#### Format Dataset

```{r}

na_count <- sum(is.na(survival_model$outcome_final))

na_count

```

```{r format-dataset}
#| echo: true
#| warning: false
#| message: false
#| eval: true

library(dplyr)
library(forcats)

survival_model %<>%
  mutate(INIT_STAT = as.factor(INIT_STAT)) %>%
  mutate(INOTROPES_TCR = as.factor(INOTROPES_TCR)) %>%
  mutate(PGE_TCR = as.factor(PGE_TCR)) %>%
  mutate_if(is.factor, ~fct_na_value_to_level(., "Unknown")) %>% 
  select(-c( days_total, WL_ID_CODE, PT_CODE)) %>% 
  select(-c(BMI, PGE_TCR, WL_OTHER_ORG)) %>% 
  filter(!is.na(outcome_final))

survival_model %>% 
  str()

```

```{r eval=FALSE}
create_report(survival_model)
```

#### Data Preprocessing for Model Inputs

```{r model-dataset}
#| echo: true
#| warning: false
#| message: false
#| eval: true

library(dplyr)
library(forcats)

lr_model <- survival_model %>% 
  mutate(AGE = scale(AGE),
    WEIGHT_KG = scale(WEIGHT_KG),
    HEIGHT_CM = scale(HEIGHT_CM),
    MOST_RCNT_CREAT = scale(MOST_RCNT_CREAT),
    TOT_SERUM_ALBUM = scale(TOT_SERUM_ALBUM)) %>% 
  rename(
    `Blood Type` = ABO,
    `Gender` = GENDER,
    `Race` = RACE,
    `Diabetes` = DIAB,
    `Height` = HEIGHT_CM,
    `Weight` = WEIGHT_KG,
    `ECMO at Reg` = ECMO_CAND_REG,
    `VAD Device TCR` = VAD_DEVICE_TY_TCR,
    `Ventilator at Reg` = VENTILATOR_CAND_REG,
    `Defribilator` = IMPL_DEFIBRIL,
    `Recent Creatine` = MOST_RCNT_CREAT,
    `Inotropes TCR` = INOTROPES_TCR,
    `Functional Status at Registration` = FUNC_STAT_CAND_REG,
    `Total Albumin Level` = TOT_SERUM_ALBUM,
    `Candidate Diagnosis` = CAND_DIAG,
    `Listing Center Average Volume` = LISTING_CTR_TX_AVG,
    `Initial Status` = INIT_STAT,
    `Age` = AGE,
    `Listing Center Code` = LISTING_CTR_CODE,
    `Median Refusals` = median_refusals,
    `Median Wait Days` = median_wait_days,
    `Median Wait Days at Initial Status` = median_wait_days_status
    
  ) %>% 
  na.omit()

```

- Target Label is 'outcome_final'

```{r cache=TRUE}

set.seed(1997)

# Calculate the number of rows to include in the training set (80% of the dataset)
train_size <- floor(0.8 * nrow(lr_model))

# Randomly sample indices for the training data
train_indices <- sample(1:nrow(lr_model), train_size)

# Use the remaining rows as test data
test_indices <- setdiff(1:nrow(lr_model), train_indices)

# Create training and testing datasets using the indices
train_data <- lr_model[train_indices, ]
test_data <- lr_model[test_indices, ]

# Extract the response variable 'y' for both training and testing datasets
y_train <- train_data$outcome_final
y_test <- test_data$outcome_final

# Remove the response variable from both datasets to prepare for modeling
train <- train_data[, !names(train_data) %in% c("outcome_final")]
test <- test_data[, !names(test_data) %in% c("outcome_final")]

# Create design matrices for both train and test datasets
train_matrix <- model.matrix(~ ., data = train)
test_matrix <- model.matrix(~ ., data = test)


```

### Regression

```{r cache=TRUE}

# Train the logistic regression model using matrix syntax
glm_model <- glm(y_train ~ ., data = as.data.frame(train_matrix), family = binomial)

# Summary of the logistic regression model
lr_summary <- summary(glm_model)

# Predict probabilities on test set
lr_proba <- predict(glm_model, newdata = as.data.frame(test_matrix), type = "response")

# Convert probabilities to class predictions
lr_class <- ifelse(lr_proba > 0.2, 1, 0)
names(lr_class) <- "lr_class"

```

#### Regression Feature Importance

```{r cache=TRUE}

# Extract coefficients and corresponding p-values
coefficients <- coef(lr_summary)
p_values <- coefficients[, "Pr(>|z|)"]

# Set significance level
significance_level <- 0.05

# Filter coefficients based on significance level
significant_coefficients <- coefficients[p_values < significance_level, ]

# Output significant coefficients
significant_coefficients

```

### Lasso Penalized Logistic Regression

```{r cache=TRUE}

library(glmnet)

# Perform cross-validation to select lambda
cv_lasso <- cv.glmnet(train_matrix, y_train, family = "binomial", alpha = 1)

# Predict probabilities on test set
lasso_proba <- predict(cv_lasso, newx = test_matrix, 
                       type = "response", s = "lambda.min")
names(lasso_proba) <- "lasso_proba"

# Convert probabilities to class predictions
lasso_class <- ifelse(lasso_proba > 0.2, 1, 0)
names(lasso_class) <- "lasso_class"

```

#### Lasso Feature Importance

```{r}

# Extracting coefficients for the specified lambda value
lasso_coef <- coef(cv_lasso, s = "lambda.min") 

# Filter for positive coefficients
positive_lasso_coef <- lasso_coef[lasso_coef > 0]

# Accessing the coefficients
positive_lasso_coef <- as.matrix(positive_lasso_coef)

# Find non-zero coefficients
non_zero_indices <- which(positive_lasso_coef != 0, arr.ind = TRUE)
non_zero_values <- positive_lasso_coef[non_zero_indices]

# Extract feature names using row indices
feature_names <- lasso_coef@Dimnames[[1]][non_zero_indices[, 1]]

# Create a data frame to store the non-zero coefficients, feature names, and values
non_zero_coef_df <- data.frame(Feature = feature_names, Value = non_zero_values)

# Print the data frame
print(non_zero_coef_df)

```

### Lasso Penalized Logistic Regression - Relaxed Fit

```{r cache=TRUE, eval=TRUE}

# Perform cross-validation to select lambda
cv_lasso_relaxed <- cv.glmnet(train_matrix, y_train, family = "binomial", alpha = 1, relax = TRUE)

# Predict probabilities on test set
lasso_relaxed_proba <- predict(cv_lasso_relaxed, newx = test_matrix, 
                       type = "response", s = "lambda.min", gamma = "gamma.min")

names(lasso_relaxed_proba) <- "lasso_relaxed_proba"

# Convert probabilities to class predictions
lasso_relaxed_class <- ifelse(lasso_relaxed_proba > 0.2, 1, 0)
names(lasso_relaxed_class) <- "lasso_relaxed_class"

```

#### Relaxed Lasso Feature Importance

```{r cache=TRUE, eval=TRUE}

# Extracting coefficients for the specified lambda value
lasso_relaxed_coef <- coef(cv_lasso_relaxed, s = "lambda.min")

# Accessing the coefficients
lasso_relaxed_coef <- as.matrix(lasso_relaxed_coef)

lasso_relaxed_coef


```

### CatBoost

```{r}

library(catboost)

train_pool <- catboost.load_pool(data = train, label = y_train)

test_pool <- catboost.load_pool(test, label = y_test)


fit_params <- list(iterations=1000,
                   loss_function='Logloss',
                   depth=6,
                   class_weights=c(1, 7),
                   boosting_type='Ordered',
                   bootstrap_type='MVS',
                   early_stopping_rounds=100,
                   use_best_model=TRUE,
                   verbose=20,
                   random_seed=1997)

cv_params <- fit_params
cv_params$verbose = 50

# Run cross-validation
cv_result <- catboost.cv(pool = train_pool,
                         params = cv_params,
                         fold_count = 3,
                         type = 'Classical',
                         stratified = TRUE,
                         shuffle = FALSE)

```

```{r}

# Find the iteration with the best average metric
best_iteration <- which.min(cv_result$test.Logloss.mean)

# Update fit_params with the best iteration
fit_params$iterations <- best_iteration

# Train final model on the full training dataset using the identified best iteration
catboost_survival_model <- catboost.train(train_pool, 
                                          test_pool,
                                          params = fit_params)

```


```{r cache=TRUE}

new_pool = catboost.load_pool(data=test_data)

catboost_class <- catboost.predict(catboost_survival_model, new_pool, prediction_type = 'Class')

catboost_proba <- catboost.predict(catboost_survival_model, new_pool, prediction_type = 'Probability')

```

#### CatBoost Feature Importance

##### Gain Feature Importance

```{r cache=TRUE, warning=FALSE, message=FALSE}

library(tibble)
library(ggplot2)
library(catboost)

# Get feature importance and create a tibble
gain_feat_imp <- catboost.get_feature_importance(catboost_survival_model, train_pool, 'FeatureImportance') %>%
  as_tibble() %>% 
  mutate(Feature = colnames(train)) %>% 
  rename(Importance = V1) %>% # Rename columns
  select(2,1) %>% 
  arrange(desc(Importance)) %>% 
  mutate(Feature = factor(Feature, levels = Feature))


gain_feat_imp %>% 
  datatable()

```

##### Loss Function Feature Importance

```{r cache=TRUE, warning=FALSE, message=FALSE}

library(tibble)
library(ggplot2)
library(catboost)

# Get feature importance and create a tibble
loss_function_feat_imp <- catboost.get_feature_importance(catboost_survival_model, train_pool, 'LossFunctionChange') %>%
  as_tibble() %>% 
  mutate(Feature = colnames(train)) %>% 
  rename(Importance = V1) %>% # Rename columns
  select(2,1) %>% 
  arrange(desc(Importance)) %>% 
  mutate(Feature = factor(Feature, levels = Feature))


loss_function_feat_imp %>% 
  datatable()

```

### All Predictions on Validation Set

```{r cache=TRUE, warning=FALSE, message=FALSE}

# Combine the vectors and create a tibble
actuals_predictions <- cbind(y_test, lr_proba, lr_class, lasso_proba, lasso_class, catboost_proba, catboost_class) %>% 
  as_tibble(.name_repair = 'unique') 

# Rename the columns
names(actuals_predictions) <- c("y_test", "lr_proba", "lr_class", "lasso_proba", "lasso_class", "catboost_proba", "catboost_class")

actuals_predictions[, sapply(actuals_predictions, is.numeric)] <- round(actuals_predictions[, sapply(actuals_predictions, is.numeric)], 3)

```


```{r cache=TRUE}

actuals_predictions %>% 
  datatable()

```


### Model Accuracy

```{r}

actual <- factor(y_test, levels = c(0, 1))

table(actual)

```
#### Probability Metrics for Train and Test Combined

```{r}

# Add a 'Type' column to the train dataset
train$Type <- "train"

# Add a 'Type' column to the test dataset
test$Type <- "test"

# Combine the train and test datasets into one dataset
model_df <- rbind(train, test)

model_y <- c(y_train,y_test)

# Create design matrices
model_matrix <- model.matrix(~ ., data = model_df)

actuals = cbind(model_df, model_y)


```

#### Full Logistic Regression Model

```{r}

# Predict probabilities on both train and test datasets
preds_lr_proba <- predict(glm_model, newdata = as.data.frame(model_matrix), type = "response")

# Convert probabilities to class predictions
preds_lr_class <- ifelse(preds_lr_proba > 0.2, 1, 0)
names(preds_lr_class) <- "preds_lr_class"


```

#### Full Lasso Penalized Regression Model

```{r}

# Perform cross-validation to select lambda
cv_lasso_all <- cv.glmnet(model_matrix, model_y, family = "binomial", alpha = 1)


# Predict probabilities on test set
preds_lasso_proba <- predict(cv_lasso_all, newx = model_matrix, 
                       type = "response", s = "lambda.min")
names(preds_lasso_proba) <- "preds_lasso_proba"

# Convert probabilities to class predictions
preds_lasso_class <- ifelse(preds_lasso_proba > 0.2, 1, 0)
names(preds_lasso_class) <- "preds_lasso_class"


```

#### Full Lasso "Relaxed" Penalized Regression Model

```{r}

# Perform cross-validation to select lambda
cv_lasso_all_relaxed <- cv.glmnet(model_matrix, model_y, family = "binomial", alpha = 1, relax = TRUE)


# Predict probabilities on test set
preds_lasso_proba_relaxed <- predict(cv_lasso_all_relaxed, newx = model_matrix, 
                       type = "response", s = "lambda.min")
names(preds_lasso_proba_relaxed) <- "preds_lasso_proba_relaxed"

# Convert probabilities to class predictions
preds_lasso_class_relaxed <- ifelse(preds_lasso_proba_relaxed > 0.2, 1, 0)
names(preds_lasso_class_relaxed) <- "preds_lasso_class_relaxed"


```

#### Full CatBoost Model

```{r}

train_test_pool = catboost.load_pool(data=model_df[, -23])

preds_catboost_class <- catboost.predict(catboost_survival_model, train_test_pool, prediction_type = 'Class')

preds_catboost_proba <- catboost.predict(catboost_survival_model, train_test_pool, prediction_type = 'Probability')


```


```{r, warning=FALSE, message=FALSE}

library(MLmetrics)
library(DescTools)
library(yardstick)

```

#### Brier Score

```{r}

# Convert numeric vector to factor vector
truth <- factor(model_y, levels = c(0, 1), labels = c("Survived", "Did_Not_Survive"))

# Calculate Brier score
brier_lr <- yardstick::brier_class_vec(truth, preds_lr_proba)
brier_lasso <- yardstick::brier_class_vec(truth, preds_lasso_proba[,1])
brier_lasso_relaxed <- yardstick::brier_class_vec(truth, preds_lasso_proba_relaxed[,1])
brier_catboost <- yardstick::brier_class_vec(truth, preds_catboost_proba)

brier_lr
brier_lasso
brier_lasso_relaxed
brier_catboost

```

#### Log-Loss

```{r}

# Log-loss
logloss_lr <- LogLoss(model_y, preds_lr_proba)
logloss_lasso <- LogLoss(model_y, preds_lasso_proba[,1])
logloss_lasso_relaxed <- LogLoss(model_y, preds_lasso_proba_relaxed[,1])
logloss_catboost <- LogLoss(model_y, preds_catboost_proba)

logloss_lr
logloss_lasso
logloss_lasso_relaxed
logloss_catboost
  
```

#### Mean Absolute Error

```{r}

# Mean Absolute Error (MAE)
mae_lr <- MAE(model_y, preds_lr_proba)
mae_lasso <- MAE(model_y, preds_lasso_proba)
mae_lasso_relaxed <- MAE(model_y, preds_lasso_proba_relaxed)
mae_catboost <- MAE(model_y, preds_catboost_proba)

mae_lr
mae_lasso
mae_lasso_relaxed
mae_catboost
  
  
```
#### AUC

```{r}

# Convert numeric vector to factor vector
truth <- factor(model_y, levels = c(0, 1), labels = c("Survived", "Did_Not_Survive"))

# AUC
auc_lr <- roc_auc_vec(truth, preds_lr_proba)
auc_lasso <- roc_auc_vec(truth, preds_lasso_proba[,1])
auc_lasso_relaxed <- roc_auc_vec(truth, preds_lasso_proba_relaxed[,1])
auc_catboost <- roc_auc_vec(truth, preds_catboost_proba)


auc_lr
auc_lasso
auc_lasso_relaxed
auc_catboost

```

#### Logistic Regression Confusion Matrix

```{r cache=TRUE, warning=FALSE, message=FALSE}

library(ConfusionTableR)

```


```{r cache=TRUE}

lr_predicted <- factor(lr_class, levels = c(0, 1))

lr_cm <- ConfusionTableR::binary_class_cm(actual, lr_predicted)

glimpse(lr_cm$record_level_cm)

```

```{r cache=TRUE, eval=FALSE}

ConfusionTableR::binary_visualiseR(train_labels = lr_predicted,
                                   truth_labels= actual,
                                   class_label1 = "Survived", 
                                   class_label2 = "Did Not Survive",
                                   quadrant_col1 = "#28ACB4", 
                                   quadrant_col2 = "#4397D2", 
                                   custom_title = "Logistic Regression Confusion Matrix", 
                                   text_col= "black")


```


![Logistic Regression Confusion Matrix](images/lr_cm.png)


#### Lasso Penalized Regression Confusion Matrix

```{r cache=TRUE}

lasso_predicted <- factor(lasso_class, levels = c(0, 1))

lasso_cm <- ConfusionTableR::binary_class_cm(actual, lasso_predicted)

glimpse(lasso_cm$record_level_cm)


```

```{r cache=TRUE, eval=FALSE}

ConfusionTableR::binary_visualiseR(train_labels = lasso_predicted,
                                   truth_labels= actual,
                                   class_label1 = "Survived", 
                                   class_label2 = "Did Not Survive",
                                   quadrant_col1 = "#28ACB4", 
                                   quadrant_col2 = "#4397D2", 
                                   custom_title = "Lasso Penalized Regression Confusion Matrix", 
                                   text_col= "black")
```

![Lasso Penalized Regression Confusion Matrix](images/lasso_cm.png)


#### Lasso "Relaxed" Penalized Regression Confusion Matrix

```{r cache=TRUE}

lasso_relax_predicted <- factor(lasso_relaxed_class, levels = c(0, 1))

lasso_relaxed_cm <- ConfusionTableR::binary_class_cm(actual, lasso_relax_predicted)

glimpse(lasso_relaxed_cm$record_level_cm)


```

```{r cache=TRUE, eval=FALSE}

ConfusionTableR::binary_visualiseR(train_labels = lasso_relax_predicted,
                                   truth_labels= actual,
                                   class_label1 = "Survived", 
                                   class_label2 = "Did Not Survive",
                                   quadrant_col1 = "#28ACB4", 
                                   quadrant_col2 = "#4397D2", 
                                   custom_title = "Lasso 'Relaxed' Penalized Regression Confusion Matrix", 
                                   text_col= "black")
```

![Lasso 'Relaxed' Penalized Regression Confusion Matrix](images/lasso_relaxed_cm.png)


#### CatBoost Confusion Matrix

```{r cache=TRUE}

catboost_predicted <- factor(catboost_class, levels = c(0, 1))

catboost_cm <- ConfusionTableR::binary_class_cm(actual, catboost_predicted)

glimpse(catboost_cm$record_level_cm)

```

```{r cache=TRUE, eval=FALSE}

ConfusionTableR::binary_visualiseR(train_labels = catboost_predicted,
                                   truth_labels= actual,
                                   class_label1 = "Survived", 
                                   class_label2 = "Did Not Survive",
                                   quadrant_col1 = "#28ACB4", 
                                   quadrant_col2 = "#4397D2", 
                                   custom_title = "CatBoost Confusion Matrix", 
                                   text_col= "black")
```

![CatBoost Confusion Matrix](images/catboost_cm.png)

```{r}

library(probably)

predictions <- actuals_predictions %>% 
  mutate(Class = ifelse(y_test == 0, "survive", "not_survive"),
         .pred_not_survive_lr = lr_proba,
         .pred_not_survive_lasso = lasso_proba,
         .pred_not_survive_lasso_relaxed = lasso_relaxed_proba,
         .pred_not_survive_catboost = catboost_proba
         )

# Define the levels you want
factor_levels <- c("survive", "not_survive")

# Set the levels of the 'actuals' column
predictions$Class <- factor(predictions$Class, levels = rev(factor_levels))

predictions %<>%
  select(8:12)

predictions %>% 
  datatable()


```

### Calibration Plot - Regression

```{r}

predictions_lr <- predictions %>% 
  select(1,2) %>% 
  mutate(.pred_not_survive = .pred_not_survive_lr)

predictions_lr %>% 
  cal_plot_logistic(Class, .pred_not_survive)


```

### Calibration Plot - Lasso Penalized Regression

```{r}

predictions_lasso <- predictions %>% 
  select(1,3) %>% 
  mutate(.pred_not_survive = .pred_not_survive_lasso)

predictions_lasso %>% 
  cal_plot_logistic(Class, .pred_not_survive)

```

### Calibration Plot - Lasso 'Relaxed' Penalized Regression

```{r}

predictions_lasso_relaxed <- predictions %>% 
  select(1,4) %>% 
  mutate(.pred_not_survive = .pred_not_survive_lasso_relaxed)

predictions_lasso_relaxed %>% 
  cal_plot_logistic(Class, .pred_not_survive)

```

### Calibration Plot - CatBoost

```{r}

predictions_catboost <- predictions %>% 
  select(1,5) %>% 
  mutate(.pred_not_survive = .pred_not_survive_catboost)

predictions_catboost %>% 
  cal_plot_logistic(Class, .pred_not_survive)

```

